layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv1"
  top: "conv4"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv4"
  top: "conv7"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv7"
  top: "pool10"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "pool10"
  top: "conv11"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn12"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale12"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu13"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv14"
  type: "Convolution"
  bottom: "conv11"
  top: "conv14"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn15"
  type: "BatchNorm"
  bottom: "conv14"
  top: "conv14"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale15"
  type: "Scale"
  bottom: "conv14"
  top: "conv14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu16"
  type: "ReLU"
  bottom: "conv14"
  top: "conv14"
}
layer {
  name: "slice17"
  type: "Slice"
  bottom: "conv14"
  top: "slice17-0"
  top: "slice17-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "add18"
  type: "Eltwise"
  bottom: "slice17-0"
  bottom: "slice17-1"
  top: "add18"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool19"
  type: "Pooling"
  bottom: "add18"
  top: "pool19"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv20"
  type: "Convolution"
  bottom: "pool19"
  top: "conv20"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn21"
  type: "BatchNorm"
  bottom: "conv20"
  top: "conv20"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale21"
  type: "Scale"
  bottom: "conv20"
  top: "conv20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv20"
  top: "conv20"
}
layer {
  name: "conv23"
  type: "Convolution"
  bottom: "conv20"
  top: "conv23"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape25"
  type: "Reshape"
  bottom: "conv23"
  top: "reshape25"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm26"
  type: "Permute"
  bottom: "reshape25"
  top: "perm26"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax27"
  type: "Softmax"
  bottom: "perm26"
  top: "softmax27"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape29"
  type: "Reshape"
  bottom: "softmax27"
  top: "reshape29"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice30"
  type: "Slice"
  bottom: "reshape29"
  top: "slice30-0"
  top: "slice30-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "mul31"
  type: "Scale"
  bottom: "slice17-0"
  bottom: "slice30-0"
  top: "mul31"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul32"
  type: "Scale"
  bottom: "slice17-1"
  bottom: "slice30-1"
  top: "mul32"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add33"
  type: "Eltwise"
  bottom: "mul31"
  bottom: "mul32"
  top: "add33"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv34"
  type: "Convolution"
  bottom: "add33"
  top: "conv34"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn35"
  type: "BatchNorm"
  bottom: "conv34"
  top: "conv34"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale35"
  type: "Scale"
  bottom: "conv34"
  top: "conv34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "pool36"
  type: "Pooling"
  bottom: "pool10"
  top: "pool36"
  pooling_param {
    pool: AVE
    kernel_size: 1
    stride: 1
    pad: 0
    round_mode: FLOOR
  }
}
layer {
  name: "conv37"
  type: "Convolution"
  bottom: "pool36"
  top: "conv37"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn38"
  type: "BatchNorm"
  bottom: "conv37"
  top: "conv37"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale38"
  type: "Scale"
  bottom: "conv37"
  top: "conv37"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add39"
  type: "Eltwise"
  bottom: "conv34"
  bottom: "conv37"
  top: "add39"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu40"
  type: "ReLU"
  bottom: "add39"
  top: "add39"
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "add39"
  top: "conv41"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn42"
  type: "BatchNorm"
  bottom: "conv41"
  top: "conv41"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale42"
  type: "Scale"
  bottom: "conv41"
  top: "conv41"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu43"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv44"
  type: "Convolution"
  bottom: "conv41"
  top: "conv44"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn45"
  type: "BatchNorm"
  bottom: "conv44"
  top: "conv44"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale45"
  type: "Scale"
  bottom: "conv44"
  top: "conv44"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu46"
  type: "ReLU"
  bottom: "conv44"
  top: "conv44"
}
layer {
  name: "slice47"
  type: "Slice"
  bottom: "conv44"
  top: "slice47-0"
  top: "slice47-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "add48"
  type: "Eltwise"
  bottom: "slice47-0"
  bottom: "slice47-1"
  top: "add48"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool49"
  type: "Pooling"
  bottom: "add48"
  top: "pool49"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv50"
  type: "Convolution"
  bottom: "pool49"
  top: "conv50"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn51"
  type: "BatchNorm"
  bottom: "conv50"
  top: "conv50"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale51"
  type: "Scale"
  bottom: "conv50"
  top: "conv50"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv50"
  top: "conv50"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv50"
  top: "conv53"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape55"
  type: "Reshape"
  bottom: "conv53"
  top: "reshape55"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm56"
  type: "Permute"
  bottom: "reshape55"
  top: "perm56"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax57"
  type: "Softmax"
  bottom: "perm56"
  top: "softmax57"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape59"
  type: "Reshape"
  bottom: "softmax57"
  top: "reshape59"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice60"
  type: "Slice"
  bottom: "reshape59"
  top: "slice60-0"
  top: "slice60-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "mul61"
  type: "Scale"
  bottom: "slice47-0"
  bottom: "slice60-0"
  top: "mul61"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul62"
  type: "Scale"
  bottom: "slice47-1"
  bottom: "slice60-1"
  top: "mul62"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add63"
  type: "Eltwise"
  bottom: "mul61"
  bottom: "mul62"
  top: "add63"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv64"
  type: "Convolution"
  bottom: "add63"
  top: "conv64"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn65"
  type: "BatchNorm"
  bottom: "conv64"
  top: "conv64"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale65"
  type: "Scale"
  bottom: "conv64"
  top: "conv64"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add66"
  type: "Eltwise"
  bottom: "conv64"
  bottom: "add39"
  top: "add66"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu67"
  type: "ReLU"
  bottom: "add66"
  top: "add66"
}
layer {
  name: "conv68"
  type: "Convolution"
  bottom: "add66"
  top: "conv68"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn69"
  type: "BatchNorm"
  bottom: "conv68"
  top: "conv68"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale69"
  type: "Scale"
  bottom: "conv68"
  top: "conv68"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu70"
  type: "ReLU"
  bottom: "conv68"
  top: "conv68"
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "conv68"
  top: "conv71"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn72"
  type: "BatchNorm"
  bottom: "conv71"
  top: "conv71"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale72"
  type: "Scale"
  bottom: "conv71"
  top: "conv71"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu73"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "slice74"
  type: "Slice"
  bottom: "conv71"
  top: "slice74-0"
  top: "slice74-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "add75"
  type: "Eltwise"
  bottom: "slice74-0"
  bottom: "slice74-1"
  top: "add75"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool76"
  type: "Pooling"
  bottom: "add75"
  top: "pool76"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv77"
  type: "Convolution"
  bottom: "pool76"
  top: "conv77"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn78"
  type: "BatchNorm"
  bottom: "conv77"
  top: "conv77"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale78"
  type: "Scale"
  bottom: "conv77"
  top: "conv77"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu79"
  type: "ReLU"
  bottom: "conv77"
  top: "conv77"
}
layer {
  name: "conv80"
  type: "Convolution"
  bottom: "conv77"
  top: "conv80"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape82"
  type: "Reshape"
  bottom: "conv80"
  top: "reshape82"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm83"
  type: "Permute"
  bottom: "reshape82"
  top: "perm83"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax84"
  type: "Softmax"
  bottom: "perm83"
  top: "softmax84"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape86"
  type: "Reshape"
  bottom: "softmax84"
  top: "reshape86"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice87"
  type: "Slice"
  bottom: "reshape86"
  top: "slice87-0"
  top: "slice87-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "mul88"
  type: "Scale"
  bottom: "slice74-0"
  bottom: "slice87-0"
  top: "mul88"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul89"
  type: "Scale"
  bottom: "slice74-1"
  bottom: "slice87-1"
  top: "mul89"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add90"
  type: "Eltwise"
  bottom: "mul88"
  bottom: "mul89"
  top: "add90"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "add90"
  top: "conv91"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn92"
  type: "BatchNorm"
  bottom: "conv91"
  top: "conv91"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale92"
  type: "Scale"
  bottom: "conv91"
  top: "conv91"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add93"
  type: "Eltwise"
  bottom: "conv91"
  bottom: "add66"
  top: "add93"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu94"
  type: "ReLU"
  bottom: "add93"
  top: "add93"
}
layer {
  name: "conv95"
  type: "Convolution"
  bottom: "add93"
  top: "conv95"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn96"
  type: "BatchNorm"
  bottom: "conv95"
  top: "conv95"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale96"
  type: "Scale"
  bottom: "conv95"
  top: "conv95"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu97"
  type: "ReLU"
  bottom: "conv95"
  top: "conv95"
}
layer {
  name: "conv98"
  type: "Convolution"
  bottom: "conv95"
  top: "conv98"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn99"
  type: "BatchNorm"
  bottom: "conv98"
  top: "conv98"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale99"
  type: "Scale"
  bottom: "conv98"
  top: "conv98"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu100"
  type: "ReLU"
  bottom: "conv98"
  top: "conv98"
}
layer {
  name: "slice101"
  type: "Slice"
  bottom: "conv98"
  top: "slice101-0"
  top: "slice101-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add102"
  type: "Eltwise"
  bottom: "slice101-0"
  bottom: "slice101-1"
  top: "add102"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool103"
  type: "Pooling"
  bottom: "add102"
  top: "pool103"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv104"
  type: "Convolution"
  bottom: "pool103"
  top: "conv104"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn105"
  type: "BatchNorm"
  bottom: "conv104"
  top: "conv104"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale105"
  type: "Scale"
  bottom: "conv104"
  top: "conv104"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu106"
  type: "ReLU"
  bottom: "conv104"
  top: "conv104"
}
layer {
  name: "conv107"
  type: "Convolution"
  bottom: "conv104"
  top: "conv107"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape109"
  type: "Reshape"
  bottom: "conv107"
  top: "reshape109"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm110"
  type: "Permute"
  bottom: "reshape109"
  top: "perm110"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax111"
  type: "Softmax"
  bottom: "perm110"
  top: "softmax111"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape113"
  type: "Reshape"
  bottom: "softmax111"
  top: "reshape113"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice114"
  type: "Slice"
  bottom: "reshape113"
  top: "slice114-0"
  top: "slice114-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul115"
  type: "Scale"
  bottom: "slice101-0"
  bottom: "slice114-0"
  top: "mul115"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul116"
  type: "Scale"
  bottom: "slice101-1"
  bottom: "slice114-1"
  top: "mul116"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add117"
  type: "Eltwise"
  bottom: "mul115"
  bottom: "mul116"
  top: "add117"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool118"
  type: "Pooling"
  bottom: "add117"
  top: "pool118"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
    pad: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv119"
  type: "Convolution"
  bottom: "pool118"
  top: "conv119"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn120"
  type: "BatchNorm"
  bottom: "conv119"
  top: "conv119"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale120"
  type: "Scale"
  bottom: "conv119"
  top: "conv119"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "pool121"
  type: "Pooling"
  bottom: "add93"
  top: "pool121"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv122"
  type: "Convolution"
  bottom: "pool121"
  top: "conv122"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn123"
  type: "BatchNorm"
  bottom: "conv122"
  top: "conv122"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale123"
  type: "Scale"
  bottom: "conv122"
  top: "conv122"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add124"
  type: "Eltwise"
  bottom: "conv119"
  bottom: "conv122"
  top: "add124"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu125"
  type: "ReLU"
  bottom: "add124"
  top: "add124"
}
layer {
  name: "conv126"
  type: "Convolution"
  bottom: "add124"
  top: "conv126"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn127"
  type: "BatchNorm"
  bottom: "conv126"
  top: "conv126"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale127"
  type: "Scale"
  bottom: "conv126"
  top: "conv126"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu128"
  type: "ReLU"
  bottom: "conv126"
  top: "conv126"
}
layer {
  name: "conv129"
  type: "Convolution"
  bottom: "conv126"
  top: "conv129"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn130"
  type: "BatchNorm"
  bottom: "conv129"
  top: "conv129"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale130"
  type: "Scale"
  bottom: "conv129"
  top: "conv129"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu131"
  type: "ReLU"
  bottom: "conv129"
  top: "conv129"
}
layer {
  name: "slice132"
  type: "Slice"
  bottom: "conv129"
  top: "slice132-0"
  top: "slice132-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add133"
  type: "Eltwise"
  bottom: "slice132-0"
  bottom: "slice132-1"
  top: "add133"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool134"
  type: "Pooling"
  bottom: "add133"
  top: "pool134"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv135"
  type: "Convolution"
  bottom: "pool134"
  top: "conv135"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn136"
  type: "BatchNorm"
  bottom: "conv135"
  top: "conv135"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale136"
  type: "Scale"
  bottom: "conv135"
  top: "conv135"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu137"
  type: "ReLU"
  bottom: "conv135"
  top: "conv135"
}
layer {
  name: "conv138"
  type: "Convolution"
  bottom: "conv135"
  top: "conv138"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape140"
  type: "Reshape"
  bottom: "conv138"
  top: "reshape140"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm141"
  type: "Permute"
  bottom: "reshape140"
  top: "perm141"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax142"
  type: "Softmax"
  bottom: "perm141"
  top: "softmax142"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape144"
  type: "Reshape"
  bottom: "softmax142"
  top: "reshape144"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice145"
  type: "Slice"
  bottom: "reshape144"
  top: "slice145-0"
  top: "slice145-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul146"
  type: "Scale"
  bottom: "slice132-0"
  bottom: "slice145-0"
  top: "mul146"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul147"
  type: "Scale"
  bottom: "slice132-1"
  bottom: "slice145-1"
  top: "mul147"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add148"
  type: "Eltwise"
  bottom: "mul146"
  bottom: "mul147"
  top: "add148"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv149"
  type: "Convolution"
  bottom: "add148"
  top: "conv149"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn150"
  type: "BatchNorm"
  bottom: "conv149"
  top: "conv149"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale150"
  type: "Scale"
  bottom: "conv149"
  top: "conv149"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add151"
  type: "Eltwise"
  bottom: "conv149"
  bottom: "add124"
  top: "add151"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu152"
  type: "ReLU"
  bottom: "add151"
  top: "add151"
}
layer {
  name: "conv153"
  type: "Convolution"
  bottom: "add151"
  top: "conv153"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn154"
  type: "BatchNorm"
  bottom: "conv153"
  top: "conv153"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale154"
  type: "Scale"
  bottom: "conv153"
  top: "conv153"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu155"
  type: "ReLU"
  bottom: "conv153"
  top: "conv153"
}
layer {
  name: "conv156"
  type: "Convolution"
  bottom: "conv153"
  top: "conv156"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn157"
  type: "BatchNorm"
  bottom: "conv156"
  top: "conv156"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale157"
  type: "Scale"
  bottom: "conv156"
  top: "conv156"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu158"
  type: "ReLU"
  bottom: "conv156"
  top: "conv156"
}
layer {
  name: "slice159"
  type: "Slice"
  bottom: "conv156"
  top: "slice159-0"
  top: "slice159-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add160"
  type: "Eltwise"
  bottom: "slice159-0"
  bottom: "slice159-1"
  top: "add160"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool161"
  type: "Pooling"
  bottom: "add160"
  top: "pool161"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv162"
  type: "Convolution"
  bottom: "pool161"
  top: "conv162"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn163"
  type: "BatchNorm"
  bottom: "conv162"
  top: "conv162"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale163"
  type: "Scale"
  bottom: "conv162"
  top: "conv162"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu164"
  type: "ReLU"
  bottom: "conv162"
  top: "conv162"
}
layer {
  name: "conv165"
  type: "Convolution"
  bottom: "conv162"
  top: "conv165"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape167"
  type: "Reshape"
  bottom: "conv165"
  top: "reshape167"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm168"
  type: "Permute"
  bottom: "reshape167"
  top: "perm168"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax169"
  type: "Softmax"
  bottom: "perm168"
  top: "softmax169"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape171"
  type: "Reshape"
  bottom: "softmax169"
  top: "reshape171"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice172"
  type: "Slice"
  bottom: "reshape171"
  top: "slice172-0"
  top: "slice172-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul173"
  type: "Scale"
  bottom: "slice159-0"
  bottom: "slice172-0"
  top: "mul173"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul174"
  type: "Scale"
  bottom: "slice159-1"
  bottom: "slice172-1"
  top: "mul174"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add175"
  type: "Eltwise"
  bottom: "mul173"
  bottom: "mul174"
  top: "add175"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv176"
  type: "Convolution"
  bottom: "add175"
  top: "conv176"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn177"
  type: "BatchNorm"
  bottom: "conv176"
  top: "conv176"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale177"
  type: "Scale"
  bottom: "conv176"
  top: "conv176"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add178"
  type: "Eltwise"
  bottom: "conv176"
  bottom: "add151"
  top: "add178"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu179"
  type: "ReLU"
  bottom: "add178"
  top: "add178"
}
layer {
  name: "conv180"
  type: "Convolution"
  bottom: "add178"
  top: "conv180"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn181"
  type: "BatchNorm"
  bottom: "conv180"
  top: "conv180"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale181"
  type: "Scale"
  bottom: "conv180"
  top: "conv180"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu182"
  type: "ReLU"
  bottom: "conv180"
  top: "conv180"
}
layer {
  name: "conv183"
  type: "Convolution"
  bottom: "conv180"
  top: "conv183"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn184"
  type: "BatchNorm"
  bottom: "conv183"
  top: "conv183"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale184"
  type: "Scale"
  bottom: "conv183"
  top: "conv183"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu185"
  type: "ReLU"
  bottom: "conv183"
  top: "conv183"
}
layer {
  name: "slice186"
  type: "Slice"
  bottom: "conv183"
  top: "slice186-0"
  top: "slice186-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add187"
  type: "Eltwise"
  bottom: "slice186-0"
  bottom: "slice186-1"
  top: "add187"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool188"
  type: "Pooling"
  bottom: "add187"
  top: "pool188"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv189"
  type: "Convolution"
  bottom: "pool188"
  top: "conv189"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn190"
  type: "BatchNorm"
  bottom: "conv189"
  top: "conv189"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale190"
  type: "Scale"
  bottom: "conv189"
  top: "conv189"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu191"
  type: "ReLU"
  bottom: "conv189"
  top: "conv189"
}
layer {
  name: "conv192"
  type: "Convolution"
  bottom: "conv189"
  top: "conv192"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape194"
  type: "Reshape"
  bottom: "conv192"
  top: "reshape194"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm195"
  type: "Permute"
  bottom: "reshape194"
  top: "perm195"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax196"
  type: "Softmax"
  bottom: "perm195"
  top: "softmax196"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape198"
  type: "Reshape"
  bottom: "softmax196"
  top: "reshape198"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice199"
  type: "Slice"
  bottom: "reshape198"
  top: "slice199-0"
  top: "slice199-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul200"
  type: "Scale"
  bottom: "slice186-0"
  bottom: "slice199-0"
  top: "mul200"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul201"
  type: "Scale"
  bottom: "slice186-1"
  bottom: "slice199-1"
  top: "mul201"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add202"
  type: "Eltwise"
  bottom: "mul200"
  bottom: "mul201"
  top: "add202"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv203"
  type: "Convolution"
  bottom: "add202"
  top: "conv203"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn204"
  type: "BatchNorm"
  bottom: "conv203"
  top: "conv203"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale204"
  type: "Scale"
  bottom: "conv203"
  top: "conv203"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add205"
  type: "Eltwise"
  bottom: "conv203"
  bottom: "add178"
  top: "add205"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu206"
  type: "ReLU"
  bottom: "add205"
  top: "add205"
}
layer {
  name: "conv207"
  type: "Convolution"
  bottom: "add205"
  top: "conv207"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn208"
  type: "BatchNorm"
  bottom: "conv207"
  top: "conv207"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale208"
  type: "Scale"
  bottom: "conv207"
  top: "conv207"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu209"
  type: "ReLU"
  bottom: "conv207"
  top: "conv207"
}
layer {
  name: "conv210"
  type: "Convolution"
  bottom: "conv207"
  top: "conv210"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn211"
  type: "BatchNorm"
  bottom: "conv210"
  top: "conv210"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale211"
  type: "Scale"
  bottom: "conv210"
  top: "conv210"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu212"
  type: "ReLU"
  bottom: "conv210"
  top: "conv210"
}
layer {
  name: "slice213"
  type: "Slice"
  bottom: "conv210"
  top: "slice213-0"
  top: "slice213-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add214"
  type: "Eltwise"
  bottom: "slice213-0"
  bottom: "slice213-1"
  top: "add214"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool215"
  type: "Pooling"
  bottom: "add214"
  top: "pool215"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv216"
  type: "Convolution"
  bottom: "pool215"
  top: "conv216"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn217"
  type: "BatchNorm"
  bottom: "conv216"
  top: "conv216"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale217"
  type: "Scale"
  bottom: "conv216"
  top: "conv216"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu218"
  type: "ReLU"
  bottom: "conv216"
  top: "conv216"
}
layer {
  name: "conv219"
  type: "Convolution"
  bottom: "conv216"
  top: "conv219"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape221"
  type: "Reshape"
  bottom: "conv219"
  top: "reshape221"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm222"
  type: "Permute"
  bottom: "reshape221"
  top: "perm222"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax223"
  type: "Softmax"
  bottom: "perm222"
  top: "softmax223"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape225"
  type: "Reshape"
  bottom: "softmax223"
  top: "reshape225"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice226"
  type: "Slice"
  bottom: "reshape225"
  top: "slice226-0"
  top: "slice226-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul227"
  type: "Scale"
  bottom: "slice213-0"
  bottom: "slice226-0"
  top: "mul227"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul228"
  type: "Scale"
  bottom: "slice213-1"
  bottom: "slice226-1"
  top: "mul228"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add229"
  type: "Eltwise"
  bottom: "mul227"
  bottom: "mul228"
  top: "add229"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool230"
  type: "Pooling"
  bottom: "add229"
  top: "pool230"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
    pad: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv231"
  type: "Convolution"
  bottom: "pool230"
  top: "conv231"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn232"
  type: "BatchNorm"
  bottom: "conv231"
  top: "conv231"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale232"
  type: "Scale"
  bottom: "conv231"
  top: "conv231"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "pool233"
  type: "Pooling"
  bottom: "add205"
  top: "pool233"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv234"
  type: "Convolution"
  bottom: "pool233"
  top: "conv234"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn235"
  type: "BatchNorm"
  bottom: "conv234"
  top: "conv234"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale235"
  type: "Scale"
  bottom: "conv234"
  top: "conv234"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add236"
  type: "Eltwise"
  bottom: "conv231"
  bottom: "conv234"
  top: "add236"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu237"
  type: "ReLU"
  bottom: "add236"
  top: "add236"
}
layer {
  name: "conv238"
  type: "Convolution"
  bottom: "add236"
  top: "conv238"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn239"
  type: "BatchNorm"
  bottom: "conv238"
  top: "conv238"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale239"
  type: "Scale"
  bottom: "conv238"
  top: "conv238"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu240"
  type: "ReLU"
  bottom: "conv238"
  top: "conv238"
}
layer {
  name: "conv241"
  type: "Convolution"
  bottom: "conv238"
  top: "conv241"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn242"
  type: "BatchNorm"
  bottom: "conv241"
  top: "conv241"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale242"
  type: "Scale"
  bottom: "conv241"
  top: "conv241"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu243"
  type: "ReLU"
  bottom: "conv241"
  top: "conv241"
}
layer {
  name: "slice244"
  type: "Slice"
  bottom: "conv241"
  top: "slice244-0"
  top: "slice244-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add245"
  type: "Eltwise"
  bottom: "slice244-0"
  bottom: "slice244-1"
  top: "add245"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool246"
  type: "Pooling"
  bottom: "add245"
  top: "pool246"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv247"
  type: "Convolution"
  bottom: "pool246"
  top: "conv247"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn248"
  type: "BatchNorm"
  bottom: "conv247"
  top: "conv247"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale248"
  type: "Scale"
  bottom: "conv247"
  top: "conv247"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu249"
  type: "ReLU"
  bottom: "conv247"
  top: "conv247"
}
layer {
  name: "conv250"
  type: "Convolution"
  bottom: "conv247"
  top: "conv250"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape252"
  type: "Reshape"
  bottom: "conv250"
  top: "reshape252"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm253"
  type: "Permute"
  bottom: "reshape252"
  top: "perm253"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax254"
  type: "Softmax"
  bottom: "perm253"
  top: "softmax254"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape256"
  type: "Reshape"
  bottom: "softmax254"
  top: "reshape256"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice257"
  type: "Slice"
  bottom: "reshape256"
  top: "slice257-0"
  top: "slice257-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul258"
  type: "Scale"
  bottom: "slice244-0"
  bottom: "slice257-0"
  top: "mul258"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul259"
  type: "Scale"
  bottom: "slice244-1"
  bottom: "slice257-1"
  top: "mul259"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add260"
  type: "Eltwise"
  bottom: "mul258"
  bottom: "mul259"
  top: "add260"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv261"
  type: "Convolution"
  bottom: "add260"
  top: "conv261"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn262"
  type: "BatchNorm"
  bottom: "conv261"
  top: "conv261"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale262"
  type: "Scale"
  bottom: "conv261"
  top: "conv261"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add263"
  type: "Eltwise"
  bottom: "conv261"
  bottom: "add236"
  top: "add263"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu264"
  type: "ReLU"
  bottom: "add263"
  top: "add263"
}
layer {
  name: "conv265"
  type: "Convolution"
  bottom: "add263"
  top: "conv265"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn266"
  type: "BatchNorm"
  bottom: "conv265"
  top: "conv265"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale266"
  type: "Scale"
  bottom: "conv265"
  top: "conv265"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu267"
  type: "ReLU"
  bottom: "conv265"
  top: "conv265"
}
layer {
  name: "conv268"
  type: "Convolution"
  bottom: "conv265"
  top: "conv268"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn269"
  type: "BatchNorm"
  bottom: "conv268"
  top: "conv268"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale269"
  type: "Scale"
  bottom: "conv268"
  top: "conv268"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu270"
  type: "ReLU"
  bottom: "conv268"
  top: "conv268"
}
layer {
  name: "slice271"
  type: "Slice"
  bottom: "conv268"
  top: "slice271-0"
  top: "slice271-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add272"
  type: "Eltwise"
  bottom: "slice271-0"
  bottom: "slice271-1"
  top: "add272"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool273"
  type: "Pooling"
  bottom: "add272"
  top: "pool273"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv274"
  type: "Convolution"
  bottom: "pool273"
  top: "conv274"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn275"
  type: "BatchNorm"
  bottom: "conv274"
  top: "conv274"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale275"
  type: "Scale"
  bottom: "conv274"
  top: "conv274"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu276"
  type: "ReLU"
  bottom: "conv274"
  top: "conv274"
}
layer {
  name: "conv277"
  type: "Convolution"
  bottom: "conv274"
  top: "conv277"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape279"
  type: "Reshape"
  bottom: "conv277"
  top: "reshape279"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm280"
  type: "Permute"
  bottom: "reshape279"
  top: "perm280"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax281"
  type: "Softmax"
  bottom: "perm280"
  top: "softmax281"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape283"
  type: "Reshape"
  bottom: "softmax281"
  top: "reshape283"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice284"
  type: "Slice"
  bottom: "reshape283"
  top: "slice284-0"
  top: "slice284-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul285"
  type: "Scale"
  bottom: "slice271-0"
  bottom: "slice284-0"
  top: "mul285"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul286"
  type: "Scale"
  bottom: "slice271-1"
  bottom: "slice284-1"
  top: "mul286"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add287"
  type: "Eltwise"
  bottom: "mul285"
  bottom: "mul286"
  top: "add287"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv288"
  type: "Convolution"
  bottom: "add287"
  top: "conv288"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn289"
  type: "BatchNorm"
  bottom: "conv288"
  top: "conv288"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale289"
  type: "Scale"
  bottom: "conv288"
  top: "conv288"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add290"
  type: "Eltwise"
  bottom: "conv288"
  bottom: "add263"
  top: "add290"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu291"
  type: "ReLU"
  bottom: "add290"
  top: "add290"
}
layer {
  name: "conv292"
  type: "Convolution"
  bottom: "add290"
  top: "conv292"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn293"
  type: "BatchNorm"
  bottom: "conv292"
  top: "conv292"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale293"
  type: "Scale"
  bottom: "conv292"
  top: "conv292"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu294"
  type: "ReLU"
  bottom: "conv292"
  top: "conv292"
}
layer {
  name: "conv295"
  type: "Convolution"
  bottom: "conv292"
  top: "conv295"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn296"
  type: "BatchNorm"
  bottom: "conv295"
  top: "conv295"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale296"
  type: "Scale"
  bottom: "conv295"
  top: "conv295"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu297"
  type: "ReLU"
  bottom: "conv295"
  top: "conv295"
}
layer {
  name: "slice298"
  type: "Slice"
  bottom: "conv295"
  top: "slice298-0"
  top: "slice298-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add299"
  type: "Eltwise"
  bottom: "slice298-0"
  bottom: "slice298-1"
  top: "add299"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool300"
  type: "Pooling"
  bottom: "add299"
  top: "pool300"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv301"
  type: "Convolution"
  bottom: "pool300"
  top: "conv301"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn302"
  type: "BatchNorm"
  bottom: "conv301"
  top: "conv301"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale302"
  type: "Scale"
  bottom: "conv301"
  top: "conv301"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu303"
  type: "ReLU"
  bottom: "conv301"
  top: "conv301"
}
layer {
  name: "conv304"
  type: "Convolution"
  bottom: "conv301"
  top: "conv304"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape306"
  type: "Reshape"
  bottom: "conv304"
  top: "reshape306"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm307"
  type: "Permute"
  bottom: "reshape306"
  top: "perm307"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax308"
  type: "Softmax"
  bottom: "perm307"
  top: "softmax308"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape310"
  type: "Reshape"
  bottom: "softmax308"
  top: "reshape310"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice311"
  type: "Slice"
  bottom: "reshape310"
  top: "slice311-0"
  top: "slice311-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul312"
  type: "Scale"
  bottom: "slice298-0"
  bottom: "slice311-0"
  top: "mul312"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul313"
  type: "Scale"
  bottom: "slice298-1"
  bottom: "slice311-1"
  top: "mul313"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add314"
  type: "Eltwise"
  bottom: "mul312"
  bottom: "mul313"
  top: "add314"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv315"
  type: "Convolution"
  bottom: "add314"
  top: "conv315"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn316"
  type: "BatchNorm"
  bottom: "conv315"
  top: "conv315"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale316"
  type: "Scale"
  bottom: "conv315"
  top: "conv315"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add317"
  type: "Eltwise"
  bottom: "conv315"
  bottom: "add290"
  top: "add317"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu318"
  type: "ReLU"
  bottom: "add317"
  top: "add317"
}
layer {
  name: "conv319"
  type: "Convolution"
  bottom: "add317"
  top: "conv319"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn320"
  type: "BatchNorm"
  bottom: "conv319"
  top: "conv319"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale320"
  type: "Scale"
  bottom: "conv319"
  top: "conv319"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu321"
  type: "ReLU"
  bottom: "conv319"
  top: "conv319"
}
layer {
  name: "conv322"
  type: "Convolution"
  bottom: "conv319"
  top: "conv322"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn323"
  type: "BatchNorm"
  bottom: "conv322"
  top: "conv322"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale323"
  type: "Scale"
  bottom: "conv322"
  top: "conv322"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu324"
  type: "ReLU"
  bottom: "conv322"
  top: "conv322"
}
layer {
  name: "slice325"
  type: "Slice"
  bottom: "conv322"
  top: "slice325-0"
  top: "slice325-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add326"
  type: "Eltwise"
  bottom: "slice325-0"
  bottom: "slice325-1"
  top: "add326"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool327"
  type: "Pooling"
  bottom: "add326"
  top: "pool327"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv328"
  type: "Convolution"
  bottom: "pool327"
  top: "conv328"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn329"
  type: "BatchNorm"
  bottom: "conv328"
  top: "conv328"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale329"
  type: "Scale"
  bottom: "conv328"
  top: "conv328"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu330"
  type: "ReLU"
  bottom: "conv328"
  top: "conv328"
}
layer {
  name: "conv331"
  type: "Convolution"
  bottom: "conv328"
  top: "conv331"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape333"
  type: "Reshape"
  bottom: "conv331"
  top: "reshape333"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm334"
  type: "Permute"
  bottom: "reshape333"
  top: "perm334"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax335"
  type: "Softmax"
  bottom: "perm334"
  top: "softmax335"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape337"
  type: "Reshape"
  bottom: "softmax335"
  top: "reshape337"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice338"
  type: "Slice"
  bottom: "reshape337"
  top: "slice338-0"
  top: "slice338-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul339"
  type: "Scale"
  bottom: "slice325-0"
  bottom: "slice338-0"
  top: "mul339"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul340"
  type: "Scale"
  bottom: "slice325-1"
  bottom: "slice338-1"
  top: "mul340"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add341"
  type: "Eltwise"
  bottom: "mul339"
  bottom: "mul340"
  top: "add341"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv342"
  type: "Convolution"
  bottom: "add341"
  top: "conv342"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn343"
  type: "BatchNorm"
  bottom: "conv342"
  top: "conv342"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale343"
  type: "Scale"
  bottom: "conv342"
  top: "conv342"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add344"
  type: "Eltwise"
  bottom: "conv342"
  bottom: "add317"
  top: "add344"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu345"
  type: "ReLU"
  bottom: "add344"
  top: "add344"
}
layer {
  name: "conv346"
  type: "Convolution"
  bottom: "add344"
  top: "conv346"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn347"
  type: "BatchNorm"
  bottom: "conv346"
  top: "conv346"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale347"
  type: "Scale"
  bottom: "conv346"
  top: "conv346"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu348"
  type: "ReLU"
  bottom: "conv346"
  top: "conv346"
}
layer {
  name: "conv349"
  type: "Convolution"
  bottom: "conv346"
  top: "conv349"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn350"
  type: "BatchNorm"
  bottom: "conv349"
  top: "conv349"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale350"
  type: "Scale"
  bottom: "conv349"
  top: "conv349"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu351"
  type: "ReLU"
  bottom: "conv349"
  top: "conv349"
}
layer {
  name: "slice352"
  type: "Slice"
  bottom: "conv349"
  top: "slice352-0"
  top: "slice352-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add353"
  type: "Eltwise"
  bottom: "slice352-0"
  bottom: "slice352-1"
  top: "add353"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool354"
  type: "Pooling"
  bottom: "add353"
  top: "pool354"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv355"
  type: "Convolution"
  bottom: "pool354"
  top: "conv355"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn356"
  type: "BatchNorm"
  bottom: "conv355"
  top: "conv355"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale356"
  type: "Scale"
  bottom: "conv355"
  top: "conv355"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu357"
  type: "ReLU"
  bottom: "conv355"
  top: "conv355"
}
layer {
  name: "conv358"
  type: "Convolution"
  bottom: "conv355"
  top: "conv358"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape360"
  type: "Reshape"
  bottom: "conv358"
  top: "reshape360"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm361"
  type: "Permute"
  bottom: "reshape360"
  top: "perm361"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax362"
  type: "Softmax"
  bottom: "perm361"
  top: "softmax362"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape364"
  type: "Reshape"
  bottom: "softmax362"
  top: "reshape364"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice365"
  type: "Slice"
  bottom: "reshape364"
  top: "slice365-0"
  top: "slice365-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul366"
  type: "Scale"
  bottom: "slice352-0"
  bottom: "slice365-0"
  top: "mul366"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul367"
  type: "Scale"
  bottom: "slice352-1"
  bottom: "slice365-1"
  top: "mul367"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add368"
  type: "Eltwise"
  bottom: "mul366"
  bottom: "mul367"
  top: "add368"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv369"
  type: "Convolution"
  bottom: "add368"
  top: "conv369"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn370"
  type: "BatchNorm"
  bottom: "conv369"
  top: "conv369"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale370"
  type: "Scale"
  bottom: "conv369"
  top: "conv369"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add371"
  type: "Eltwise"
  bottom: "conv369"
  bottom: "add344"
  top: "add371"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu372"
  type: "ReLU"
  bottom: "add371"
  top: "add371"
}
layer {
  name: "conv373"
  type: "Convolution"
  bottom: "add371"
  top: "conv373"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn374"
  type: "BatchNorm"
  bottom: "conv373"
  top: "conv373"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale374"
  type: "Scale"
  bottom: "conv373"
  top: "conv373"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu375"
  type: "ReLU"
  bottom: "conv373"
  top: "conv373"
}
layer {
  name: "conv376"
  type: "Convolution"
  bottom: "conv373"
  top: "conv376"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn377"
  type: "BatchNorm"
  bottom: "conv376"
  top: "conv376"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale377"
  type: "Scale"
  bottom: "conv376"
  top: "conv376"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu378"
  type: "ReLU"
  bottom: "conv376"
  top: "conv376"
}
layer {
  name: "slice379"
  type: "Slice"
  bottom: "conv376"
  top: "slice379-0"
  top: "slice379-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add380"
  type: "Eltwise"
  bottom: "slice379-0"
  bottom: "slice379-1"
  top: "add380"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool381"
  type: "Pooling"
  bottom: "add380"
  top: "pool381"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv382"
  type: "Convolution"
  bottom: "pool381"
  top: "conv382"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn383"
  type: "BatchNorm"
  bottom: "conv382"
  top: "conv382"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale383"
  type: "Scale"
  bottom: "conv382"
  top: "conv382"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu384"
  type: "ReLU"
  bottom: "conv382"
  top: "conv382"
}
layer {
  name: "conv385"
  type: "Convolution"
  bottom: "conv382"
  top: "conv385"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape387"
  type: "Reshape"
  bottom: "conv385"
  top: "reshape387"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm388"
  type: "Permute"
  bottom: "reshape387"
  top: "perm388"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax389"
  type: "Softmax"
  bottom: "perm388"
  top: "softmax389"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape391"
  type: "Reshape"
  bottom: "softmax389"
  top: "reshape391"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice392"
  type: "Slice"
  bottom: "reshape391"
  top: "slice392-0"
  top: "slice392-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul393"
  type: "Scale"
  bottom: "slice379-0"
  bottom: "slice392-0"
  top: "mul393"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul394"
  type: "Scale"
  bottom: "slice379-1"
  bottom: "slice392-1"
  top: "mul394"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add395"
  type: "Eltwise"
  bottom: "mul393"
  bottom: "mul394"
  top: "add395"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool396"
  type: "Pooling"
  bottom: "add395"
  top: "pool396"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
    pad: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv397"
  type: "Convolution"
  bottom: "pool396"
  top: "conv397"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn398"
  type: "BatchNorm"
  bottom: "conv397"
  top: "conv397"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale398"
  type: "Scale"
  bottom: "conv397"
  top: "conv397"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "pool399"
  type: "Pooling"
  bottom: "add371"
  top: "pool399"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv400"
  type: "Convolution"
  bottom: "pool399"
  top: "conv400"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn401"
  type: "BatchNorm"
  bottom: "conv400"
  top: "conv400"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale401"
  type: "Scale"
  bottom: "conv400"
  top: "conv400"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add402"
  type: "Eltwise"
  bottom: "conv397"
  bottom: "conv400"
  top: "add402"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu403"
  type: "ReLU"
  bottom: "add402"
  top: "add402"
}
layer {
  name: "conv404"
  type: "Convolution"
  bottom: "add402"
  top: "conv404"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn405"
  type: "BatchNorm"
  bottom: "conv404"
  top: "conv404"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale405"
  type: "Scale"
  bottom: "conv404"
  top: "conv404"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu406"
  type: "ReLU"
  bottom: "conv404"
  top: "conv404"
}
layer {
  name: "conv407"
  type: "Convolution"
  bottom: "conv404"
  top: "conv407"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn408"
  type: "BatchNorm"
  bottom: "conv407"
  top: "conv407"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale408"
  type: "Scale"
  bottom: "conv407"
  top: "conv407"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu409"
  type: "ReLU"
  bottom: "conv407"
  top: "conv407"
}
layer {
  name: "slice410"
  type: "Slice"
  bottom: "conv407"
  top: "slice410-0"
  top: "slice410-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add411"
  type: "Eltwise"
  bottom: "slice410-0"
  bottom: "slice410-1"
  top: "add411"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool412"
  type: "Pooling"
  bottom: "add411"
  top: "pool412"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv413"
  type: "Convolution"
  bottom: "pool412"
  top: "conv413"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn414"
  type: "BatchNorm"
  bottom: "conv413"
  top: "conv413"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale414"
  type: "Scale"
  bottom: "conv413"
  top: "conv413"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu415"
  type: "ReLU"
  bottom: "conv413"
  top: "conv413"
}
layer {
  name: "conv416"
  type: "Convolution"
  bottom: "conv413"
  top: "conv416"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape418"
  type: "Reshape"
  bottom: "conv416"
  top: "reshape418"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm419"
  type: "Permute"
  bottom: "reshape418"
  top: "perm419"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax420"
  type: "Softmax"
  bottom: "perm419"
  top: "softmax420"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape422"
  type: "Reshape"
  bottom: "softmax420"
  top: "reshape422"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice423"
  type: "Slice"
  bottom: "reshape422"
  top: "slice423-0"
  top: "slice423-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul424"
  type: "Scale"
  bottom: "slice410-0"
  bottom: "slice423-0"
  top: "mul424"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul425"
  type: "Scale"
  bottom: "slice410-1"
  bottom: "slice423-1"
  top: "mul425"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add426"
  type: "Eltwise"
  bottom: "mul424"
  bottom: "mul425"
  top: "add426"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv427"
  type: "Convolution"
  bottom: "add426"
  top: "conv427"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn428"
  type: "BatchNorm"
  bottom: "conv427"
  top: "conv427"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale428"
  type: "Scale"
  bottom: "conv427"
  top: "conv427"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add429"
  type: "Eltwise"
  bottom: "conv427"
  bottom: "add402"
  top: "add429"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu430"
  type: "ReLU"
  bottom: "add429"
  top: "add429"
}
layer {
  name: "conv431"
  type: "Convolution"
  bottom: "add429"
  top: "conv431"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn432"
  type: "BatchNorm"
  bottom: "conv431"
  top: "conv431"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale432"
  type: "Scale"
  bottom: "conv431"
  top: "conv431"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu433"
  type: "ReLU"
  bottom: "conv431"
  top: "conv431"
}
layer {
  name: "conv434"
  type: "Convolution"
  bottom: "conv431"
  top: "conv434"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn435"
  type: "BatchNorm"
  bottom: "conv434"
  top: "conv434"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale435"
  type: "Scale"
  bottom: "conv434"
  top: "conv434"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu436"
  type: "ReLU"
  bottom: "conv434"
  top: "conv434"
}
layer {
  name: "slice437"
  type: "Slice"
  bottom: "conv434"
  top: "slice437-0"
  top: "slice437-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add438"
  type: "Eltwise"
  bottom: "slice437-0"
  bottom: "slice437-1"
  top: "add438"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool439"
  type: "Pooling"
  bottom: "add438"
  top: "pool439"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv440"
  type: "Convolution"
  bottom: "pool439"
  top: "conv440"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn441"
  type: "BatchNorm"
  bottom: "conv440"
  top: "conv440"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale441"
  type: "Scale"
  bottom: "conv440"
  top: "conv440"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu442"
  type: "ReLU"
  bottom: "conv440"
  top: "conv440"
}
layer {
  name: "conv443"
  type: "Convolution"
  bottom: "conv440"
  top: "conv443"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape445"
  type: "Reshape"
  bottom: "conv443"
  top: "reshape445"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm446"
  type: "Permute"
  bottom: "reshape445"
  top: "perm446"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax447"
  type: "Softmax"
  bottom: "perm446"
  top: "softmax447"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape449"
  type: "Reshape"
  bottom: "softmax447"
  top: "reshape449"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice450"
  type: "Slice"
  bottom: "reshape449"
  top: "slice450-0"
  top: "slice450-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul451"
  type: "Scale"
  bottom: "slice437-0"
  bottom: "slice450-0"
  top: "mul451"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul452"
  type: "Scale"
  bottom: "slice437-1"
  bottom: "slice450-1"
  top: "mul452"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add453"
  type: "Eltwise"
  bottom: "mul451"
  bottom: "mul452"
  top: "add453"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv454"
  type: "Convolution"
  bottom: "add453"
  top: "conv454"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn455"
  type: "BatchNorm"
  bottom: "conv454"
  top: "conv454"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale455"
  type: "Scale"
  bottom: "conv454"
  top: "conv454"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add456"
  type: "Eltwise"
  bottom: "conv454"
  bottom: "add429"
  top: "add456"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu457"
  type: "ReLU"
  bottom: "add456"
  top: "add456"
}
layer {
  name: "pool458"
  type: "Pooling"
  bottom: "add456"
  top: "pool458"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc463"
  type: "InnerProduct"
  bottom: "pool458"
  top: "fc463"
  inner_product_param {
    num_output: 1000
    bias_term: true
  }
}
