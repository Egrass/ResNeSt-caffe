layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 416
      dim: 416
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv1"
  top: "conv4"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv4"
  top: "conv7"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv7"
  top: "pool10"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "pool10"
  top: "conv11"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn12"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale12"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu13"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv14"
  type: "Convolution"
  bottom: "conv11"
  top: "conv14"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn15"
  type: "BatchNorm"
  bottom: "conv14"
  top: "conv14"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale15"
  type: "Scale"
  bottom: "conv14"
  top: "conv14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu16"
  type: "ReLU"
  bottom: "conv14"
  top: "conv14"
}
layer {
  name: "slice17"
  type: "Slice"
  bottom: "conv14"
  top: "slice17-0"
  top: "slice17-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "add18"
  type: "Eltwise"
  bottom: "slice17-0"
  bottom: "slice17-1"
  top: "add18"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool19"
  type: "Pooling"
  bottom: "add18"
  top: "pool19"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv20"
  type: "Convolution"
  bottom: "pool19"
  top: "conv20"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn21"
  type: "BatchNorm"
  bottom: "conv20"
  top: "conv20"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale21"
  type: "Scale"
  bottom: "conv20"
  top: "conv20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv20"
  top: "conv20"
}
layer {
  name: "conv23"
  type: "Convolution"
  bottom: "conv20"
  top: "conv23"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape25"
  type: "Reshape"
  bottom: "conv23"
  top: "reshape25"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm26"
  type: "Permute"
  bottom: "reshape25"
  top: "perm26"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax27"
  type: "Softmax"
  bottom: "perm26"
  top: "softmax27"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape29"
  type: "Reshape"
  bottom: "softmax27"
  top: "reshape29"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice30"
  type: "Slice"
  bottom: "reshape29"
  top: "slice30-0"
  top: "slice30-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "mul31"
  type: "Scale"
  bottom: "slice17-0"
  bottom: "slice30-0"
  top: "mul31"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul32"
  type: "Scale"
  bottom: "slice17-1"
  bottom: "slice30-1"
  top: "mul32"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add33"
  type: "Eltwise"
  bottom: "mul31"
  bottom: "mul32"
  top: "add33"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv34"
  type: "Convolution"
  bottom: "add33"
  top: "conv34"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn35"
  type: "BatchNorm"
  bottom: "conv34"
  top: "conv34"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale35"
  type: "Scale"
  bottom: "conv34"
  top: "conv34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "pool36"
  type: "Pooling"
  bottom: "pool10"
  top: "pool36"
  pooling_param {
    pool: AVE
    kernel_size: 1
    stride: 1
    pad: 0
    round_mode: FLOOR
  }
}
layer {
  name: "conv37"
  type: "Convolution"
  bottom: "pool36"
  top: "conv37"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn38"
  type: "BatchNorm"
  bottom: "conv37"
  top: "conv37"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale38"
  type: "Scale"
  bottom: "conv37"
  top: "conv37"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add39"
  type: "Eltwise"
  bottom: "conv34"
  bottom: "conv37"
  top: "add39"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu40"
  type: "ReLU"
  bottom: "add39"
  top: "add39"
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "add39"
  top: "conv41"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn42"
  type: "BatchNorm"
  bottom: "conv41"
  top: "conv41"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale42"
  type: "Scale"
  bottom: "conv41"
  top: "conv41"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu43"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv44"
  type: "Convolution"
  bottom: "conv41"
  top: "conv44"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn45"
  type: "BatchNorm"
  bottom: "conv44"
  top: "conv44"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale45"
  type: "Scale"
  bottom: "conv44"
  top: "conv44"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu46"
  type: "ReLU"
  bottom: "conv44"
  top: "conv44"
}
layer {
  name: "slice47"
  type: "Slice"
  bottom: "conv44"
  top: "slice47-0"
  top: "slice47-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "add48"
  type: "Eltwise"
  bottom: "slice47-0"
  bottom: "slice47-1"
  top: "add48"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool49"
  type: "Pooling"
  bottom: "add48"
  top: "pool49"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv50"
  type: "Convolution"
  bottom: "pool49"
  top: "conv50"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn51"
  type: "BatchNorm"
  bottom: "conv50"
  top: "conv50"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale51"
  type: "Scale"
  bottom: "conv50"
  top: "conv50"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu52"
  type: "ReLU"
  bottom: "conv50"
  top: "conv50"
}
layer {
  name: "conv53"
  type: "Convolution"
  bottom: "conv50"
  top: "conv53"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape55"
  type: "Reshape"
  bottom: "conv53"
  top: "reshape55"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm56"
  type: "Permute"
  bottom: "reshape55"
  top: "perm56"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax57"
  type: "Softmax"
  bottom: "perm56"
  top: "softmax57"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape59"
  type: "Reshape"
  bottom: "softmax57"
  top: "reshape59"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice60"
  type: "Slice"
  bottom: "reshape59"
  top: "slice60-0"
  top: "slice60-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "mul61"
  type: "Scale"
  bottom: "slice47-0"
  bottom: "slice60-0"
  top: "mul61"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul62"
  type: "Scale"
  bottom: "slice47-1"
  bottom: "slice60-1"
  top: "mul62"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add63"
  type: "Eltwise"
  bottom: "mul61"
  bottom: "mul62"
  top: "add63"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv64"
  type: "Convolution"
  bottom: "add63"
  top: "conv64"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn65"
  type: "BatchNorm"
  bottom: "conv64"
  top: "conv64"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale65"
  type: "Scale"
  bottom: "conv64"
  top: "conv64"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add66"
  type: "Eltwise"
  bottom: "conv64"
  bottom: "add39"
  top: "add66"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu67"
  type: "ReLU"
  bottom: "add66"
  top: "add66"
}
layer {
  name: "conv68"
  type: "Convolution"
  bottom: "add66"
  top: "conv68"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn69"
  type: "BatchNorm"
  bottom: "conv68"
  top: "conv68"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale69"
  type: "Scale"
  bottom: "conv68"
  top: "conv68"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu70"
  type: "ReLU"
  bottom: "conv68"
  top: "conv68"
}
layer {
  name: "conv71"
  type: "Convolution"
  bottom: "conv68"
  top: "conv71"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn72"
  type: "BatchNorm"
  bottom: "conv71"
  top: "conv71"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale72"
  type: "Scale"
  bottom: "conv71"
  top: "conv71"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu73"
  type: "ReLU"
  bottom: "conv71"
  top: "conv71"
}
layer {
  name: "slice74"
  type: "Slice"
  bottom: "conv71"
  top: "slice74-0"
  top: "slice74-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "add75"
  type: "Eltwise"
  bottom: "slice74-0"
  bottom: "slice74-1"
  top: "add75"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool76"
  type: "Pooling"
  bottom: "add75"
  top: "pool76"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv77"
  type: "Convolution"
  bottom: "pool76"
  top: "conv77"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn78"
  type: "BatchNorm"
  bottom: "conv77"
  top: "conv77"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale78"
  type: "Scale"
  bottom: "conv77"
  top: "conv77"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu79"
  type: "ReLU"
  bottom: "conv77"
  top: "conv77"
}
layer {
  name: "conv80"
  type: "Convolution"
  bottom: "conv77"
  top: "conv80"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape82"
  type: "Reshape"
  bottom: "conv80"
  top: "reshape82"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm83"
  type: "Permute"
  bottom: "reshape82"
  top: "perm83"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax84"
  type: "Softmax"
  bottom: "perm83"
  top: "softmax84"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape86"
  type: "Reshape"
  bottom: "softmax84"
  top: "reshape86"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice87"
  type: "Slice"
  bottom: "reshape86"
  top: "slice87-0"
  top: "slice87-1"
  slice_param {
    slice_point: 64
    axis: 1
  }
}
layer {
  name: "mul88"
  type: "Scale"
  bottom: "slice74-0"
  bottom: "slice87-0"
  top: "mul88"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul89"
  type: "Scale"
  bottom: "slice74-1"
  bottom: "slice87-1"
  top: "mul89"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add90"
  type: "Eltwise"
  bottom: "mul88"
  bottom: "mul89"
  top: "add90"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv91"
  type: "Convolution"
  bottom: "add90"
  top: "conv91"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn92"
  type: "BatchNorm"
  bottom: "conv91"
  top: "conv91"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale92"
  type: "Scale"
  bottom: "conv91"
  top: "conv91"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add93"
  type: "Eltwise"
  bottom: "conv91"
  bottom: "add66"
  top: "add93"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu94"
  type: "ReLU"
  bottom: "add93"
  top: "add93"
}
layer {
  name: "conv95"
  type: "Convolution"
  bottom: "add93"
  top: "conv95"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn96"
  type: "BatchNorm"
  bottom: "conv95"
  top: "conv95"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale96"
  type: "Scale"
  bottom: "conv95"
  top: "conv95"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu97"
  type: "ReLU"
  bottom: "conv95"
  top: "conv95"
}
layer {
  name: "conv98"
  type: "Convolution"
  bottom: "conv95"
  top: "conv98"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn99"
  type: "BatchNorm"
  bottom: "conv98"
  top: "conv98"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale99"
  type: "Scale"
  bottom: "conv98"
  top: "conv98"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu100"
  type: "ReLU"
  bottom: "conv98"
  top: "conv98"
}
layer {
  name: "slice101"
  type: "Slice"
  bottom: "conv98"
  top: "slice101-0"
  top: "slice101-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add102"
  type: "Eltwise"
  bottom: "slice101-0"
  bottom: "slice101-1"
  top: "add102"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool103"
  type: "Pooling"
  bottom: "add102"
  top: "pool103"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv104"
  type: "Convolution"
  bottom: "pool103"
  top: "conv104"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn105"
  type: "BatchNorm"
  bottom: "conv104"
  top: "conv104"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale105"
  type: "Scale"
  bottom: "conv104"
  top: "conv104"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu106"
  type: "ReLU"
  bottom: "conv104"
  top: "conv104"
}
layer {
  name: "conv107"
  type: "Convolution"
  bottom: "conv104"
  top: "conv107"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape109"
  type: "Reshape"
  bottom: "conv107"
  top: "reshape109"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm110"
  type: "Permute"
  bottom: "reshape109"
  top: "perm110"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax111"
  type: "Softmax"
  bottom: "perm110"
  top: "softmax111"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape113"
  type: "Reshape"
  bottom: "softmax111"
  top: "reshape113"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice114"
  type: "Slice"
  bottom: "reshape113"
  top: "slice114-0"
  top: "slice114-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul115"
  type: "Scale"
  bottom: "slice101-0"
  bottom: "slice114-0"
  top: "mul115"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul116"
  type: "Scale"
  bottom: "slice101-1"
  bottom: "slice114-1"
  top: "mul116"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add117"
  type: "Eltwise"
  bottom: "mul115"
  bottom: "mul116"
  top: "add117"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool118"
  type: "Pooling"
  bottom: "add117"
  top: "pool118"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
    pad: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv119"
  type: "Convolution"
  bottom: "pool118"
  top: "conv119"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn120"
  type: "BatchNorm"
  bottom: "conv119"
  top: "conv119"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale120"
  type: "Scale"
  bottom: "conv119"
  top: "conv119"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "pool121"
  type: "Pooling"
  bottom: "add93"
  top: "pool121"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv122"
  type: "Convolution"
  bottom: "pool121"
  top: "conv122"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn123"
  type: "BatchNorm"
  bottom: "conv122"
  top: "conv122"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale123"
  type: "Scale"
  bottom: "conv122"
  top: "conv122"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add124"
  type: "Eltwise"
  bottom: "conv119"
  bottom: "conv122"
  top: "add124"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu125"
  type: "ReLU"
  bottom: "add124"
  top: "add124"
}
layer {
  name: "conv126"
  type: "Convolution"
  bottom: "add124"
  top: "conv126"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn127"
  type: "BatchNorm"
  bottom: "conv126"
  top: "conv126"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale127"
  type: "Scale"
  bottom: "conv126"
  top: "conv126"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu128"
  type: "ReLU"
  bottom: "conv126"
  top: "conv126"
}
layer {
  name: "conv129"
  type: "Convolution"
  bottom: "conv126"
  top: "conv129"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn130"
  type: "BatchNorm"
  bottom: "conv129"
  top: "conv129"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale130"
  type: "Scale"
  bottom: "conv129"
  top: "conv129"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu131"
  type: "ReLU"
  bottom: "conv129"
  top: "conv129"
}
layer {
  name: "slice132"
  type: "Slice"
  bottom: "conv129"
  top: "slice132-0"
  top: "slice132-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add133"
  type: "Eltwise"
  bottom: "slice132-0"
  bottom: "slice132-1"
  top: "add133"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool134"
  type: "Pooling"
  bottom: "add133"
  top: "pool134"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv135"
  type: "Convolution"
  bottom: "pool134"
  top: "conv135"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn136"
  type: "BatchNorm"
  bottom: "conv135"
  top: "conv135"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale136"
  type: "Scale"
  bottom: "conv135"
  top: "conv135"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu137"
  type: "ReLU"
  bottom: "conv135"
  top: "conv135"
}
layer {
  name: "conv138"
  type: "Convolution"
  bottom: "conv135"
  top: "conv138"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape140"
  type: "Reshape"
  bottom: "conv138"
  top: "reshape140"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm141"
  type: "Permute"
  bottom: "reshape140"
  top: "perm141"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax142"
  type: "Softmax"
  bottom: "perm141"
  top: "softmax142"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape144"
  type: "Reshape"
  bottom: "softmax142"
  top: "reshape144"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice145"
  type: "Slice"
  bottom: "reshape144"
  top: "slice145-0"
  top: "slice145-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul146"
  type: "Scale"
  bottom: "slice132-0"
  bottom: "slice145-0"
  top: "mul146"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul147"
  type: "Scale"
  bottom: "slice132-1"
  bottom: "slice145-1"
  top: "mul147"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add148"
  type: "Eltwise"
  bottom: "mul146"
  bottom: "mul147"
  top: "add148"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv149"
  type: "Convolution"
  bottom: "add148"
  top: "conv149"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn150"
  type: "BatchNorm"
  bottom: "conv149"
  top: "conv149"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale150"
  type: "Scale"
  bottom: "conv149"
  top: "conv149"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add151"
  type: "Eltwise"
  bottom: "conv149"
  bottom: "add124"
  top: "add151"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu152"
  type: "ReLU"
  bottom: "add151"
  top: "add151"
}
layer {
  name: "conv153"
  type: "Convolution"
  bottom: "add151"
  top: "conv153"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn154"
  type: "BatchNorm"
  bottom: "conv153"
  top: "conv153"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale154"
  type: "Scale"
  bottom: "conv153"
  top: "conv153"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu155"
  type: "ReLU"
  bottom: "conv153"
  top: "conv153"
}
layer {
  name: "conv156"
  type: "Convolution"
  bottom: "conv153"
  top: "conv156"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn157"
  type: "BatchNorm"
  bottom: "conv156"
  top: "conv156"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale157"
  type: "Scale"
  bottom: "conv156"
  top: "conv156"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu158"
  type: "ReLU"
  bottom: "conv156"
  top: "conv156"
}
layer {
  name: "slice159"
  type: "Slice"
  bottom: "conv156"
  top: "slice159-0"
  top: "slice159-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add160"
  type: "Eltwise"
  bottom: "slice159-0"
  bottom: "slice159-1"
  top: "add160"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool161"
  type: "Pooling"
  bottom: "add160"
  top: "pool161"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv162"
  type: "Convolution"
  bottom: "pool161"
  top: "conv162"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn163"
  type: "BatchNorm"
  bottom: "conv162"
  top: "conv162"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale163"
  type: "Scale"
  bottom: "conv162"
  top: "conv162"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu164"
  type: "ReLU"
  bottom: "conv162"
  top: "conv162"
}
layer {
  name: "conv165"
  type: "Convolution"
  bottom: "conv162"
  top: "conv165"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape167"
  type: "Reshape"
  bottom: "conv165"
  top: "reshape167"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm168"
  type: "Permute"
  bottom: "reshape167"
  top: "perm168"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax169"
  type: "Softmax"
  bottom: "perm168"
  top: "softmax169"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape171"
  type: "Reshape"
  bottom: "softmax169"
  top: "reshape171"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice172"
  type: "Slice"
  bottom: "reshape171"
  top: "slice172-0"
  top: "slice172-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul173"
  type: "Scale"
  bottom: "slice159-0"
  bottom: "slice172-0"
  top: "mul173"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul174"
  type: "Scale"
  bottom: "slice159-1"
  bottom: "slice172-1"
  top: "mul174"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add175"
  type: "Eltwise"
  bottom: "mul173"
  bottom: "mul174"
  top: "add175"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv176"
  type: "Convolution"
  bottom: "add175"
  top: "conv176"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn177"
  type: "BatchNorm"
  bottom: "conv176"
  top: "conv176"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale177"
  type: "Scale"
  bottom: "conv176"
  top: "conv176"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add178"
  type: "Eltwise"
  bottom: "conv176"
  bottom: "add151"
  top: "add178"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu179"
  type: "ReLU"
  bottom: "add178"
  top: "add178"
}
layer {
  name: "conv180"
  type: "Convolution"
  bottom: "add178"
  top: "conv180"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn181"
  type: "BatchNorm"
  bottom: "conv180"
  top: "conv180"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale181"
  type: "Scale"
  bottom: "conv180"
  top: "conv180"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu182"
  type: "ReLU"
  bottom: "conv180"
  top: "conv180"
}
layer {
  name: "conv183"
  type: "Convolution"
  bottom: "conv180"
  top: "conv183"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn184"
  type: "BatchNorm"
  bottom: "conv183"
  top: "conv183"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale184"
  type: "Scale"
  bottom: "conv183"
  top: "conv183"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu185"
  type: "ReLU"
  bottom: "conv183"
  top: "conv183"
}
layer {
  name: "slice186"
  type: "Slice"
  bottom: "conv183"
  top: "slice186-0"
  top: "slice186-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add187"
  type: "Eltwise"
  bottom: "slice186-0"
  bottom: "slice186-1"
  top: "add187"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool188"
  type: "Pooling"
  bottom: "add187"
  top: "pool188"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv189"
  type: "Convolution"
  bottom: "pool188"
  top: "conv189"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn190"
  type: "BatchNorm"
  bottom: "conv189"
  top: "conv189"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale190"
  type: "Scale"
  bottom: "conv189"
  top: "conv189"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu191"
  type: "ReLU"
  bottom: "conv189"
  top: "conv189"
}
layer {
  name: "conv192"
  type: "Convolution"
  bottom: "conv189"
  top: "conv192"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape194"
  type: "Reshape"
  bottom: "conv192"
  top: "reshape194"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm195"
  type: "Permute"
  bottom: "reshape194"
  top: "perm195"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax196"
  type: "Softmax"
  bottom: "perm195"
  top: "softmax196"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape198"
  type: "Reshape"
  bottom: "softmax196"
  top: "reshape198"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice199"
  type: "Slice"
  bottom: "reshape198"
  top: "slice199-0"
  top: "slice199-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul200"
  type: "Scale"
  bottom: "slice186-0"
  bottom: "slice199-0"
  top: "mul200"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul201"
  type: "Scale"
  bottom: "slice186-1"
  bottom: "slice199-1"
  top: "mul201"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add202"
  type: "Eltwise"
  bottom: "mul200"
  bottom: "mul201"
  top: "add202"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv203"
  type: "Convolution"
  bottom: "add202"
  top: "conv203"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn204"
  type: "BatchNorm"
  bottom: "conv203"
  top: "conv203"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale204"
  type: "Scale"
  bottom: "conv203"
  top: "conv203"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add205"
  type: "Eltwise"
  bottom: "conv203"
  bottom: "add178"
  top: "add205"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu206"
  type: "ReLU"
  bottom: "add205"
  top: "add205"
}
layer {
  name: "conv207"
  type: "Convolution"
  bottom: "add205"
  top: "conv207"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn208"
  type: "BatchNorm"
  bottom: "conv207"
  top: "conv207"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale208"
  type: "Scale"
  bottom: "conv207"
  top: "conv207"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu209"
  type: "ReLU"
  bottom: "conv207"
  top: "conv207"
}
layer {
  name: "conv210"
  type: "Convolution"
  bottom: "conv207"
  top: "conv210"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn211"
  type: "BatchNorm"
  bottom: "conv210"
  top: "conv210"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale211"
  type: "Scale"
  bottom: "conv210"
  top: "conv210"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu212"
  type: "ReLU"
  bottom: "conv210"
  top: "conv210"
}
layer {
  name: "slice213"
  type: "Slice"
  bottom: "conv210"
  top: "slice213-0"
  top: "slice213-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add214"
  type: "Eltwise"
  bottom: "slice213-0"
  bottom: "slice213-1"
  top: "add214"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool215"
  type: "Pooling"
  bottom: "add214"
  top: "pool215"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv216"
  type: "Convolution"
  bottom: "pool215"
  top: "conv216"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn217"
  type: "BatchNorm"
  bottom: "conv216"
  top: "conv216"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale217"
  type: "Scale"
  bottom: "conv216"
  top: "conv216"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu218"
  type: "ReLU"
  bottom: "conv216"
  top: "conv216"
}
layer {
  name: "conv219"
  type: "Convolution"
  bottom: "conv216"
  top: "conv219"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape221"
  type: "Reshape"
  bottom: "conv219"
  top: "reshape221"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm222"
  type: "Permute"
  bottom: "reshape221"
  top: "perm222"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax223"
  type: "Softmax"
  bottom: "perm222"
  top: "softmax223"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape225"
  type: "Reshape"
  bottom: "softmax223"
  top: "reshape225"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice226"
  type: "Slice"
  bottom: "reshape225"
  top: "slice226-0"
  top: "slice226-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul227"
  type: "Scale"
  bottom: "slice213-0"
  bottom: "slice226-0"
  top: "mul227"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul228"
  type: "Scale"
  bottom: "slice213-1"
  bottom: "slice226-1"
  top: "mul228"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add229"
  type: "Eltwise"
  bottom: "mul227"
  bottom: "mul228"
  top: "add229"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv230"
  type: "Convolution"
  bottom: "add229"
  top: "conv230"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn231"
  type: "BatchNorm"
  bottom: "conv230"
  top: "conv230"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale231"
  type: "Scale"
  bottom: "conv230"
  top: "conv230"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add232"
  type: "Eltwise"
  bottom: "conv230"
  bottom: "add205"
  top: "add232"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu233"
  type: "ReLU"
  bottom: "add232"
  top: "add232"
}
layer {
  name: "conv234"
  type: "Convolution"
  bottom: "add232"
  top: "conv234"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn235"
  type: "BatchNorm"
  bottom: "conv234"
  top: "conv234"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale235"
  type: "Scale"
  bottom: "conv234"
  top: "conv234"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu236"
  type: "ReLU"
  bottom: "conv234"
  top: "conv234"
}
layer {
  name: "conv237"
  type: "Convolution"
  bottom: "conv234"
  top: "conv237"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn238"
  type: "BatchNorm"
  bottom: "conv237"
  top: "conv237"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale238"
  type: "Scale"
  bottom: "conv237"
  top: "conv237"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu239"
  type: "ReLU"
  bottom: "conv237"
  top: "conv237"
}
layer {
  name: "slice240"
  type: "Slice"
  bottom: "conv237"
  top: "slice240-0"
  top: "slice240-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add241"
  type: "Eltwise"
  bottom: "slice240-0"
  bottom: "slice240-1"
  top: "add241"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool242"
  type: "Pooling"
  bottom: "add241"
  top: "pool242"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv243"
  type: "Convolution"
  bottom: "pool242"
  top: "conv243"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn244"
  type: "BatchNorm"
  bottom: "conv243"
  top: "conv243"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale244"
  type: "Scale"
  bottom: "conv243"
  top: "conv243"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu245"
  type: "ReLU"
  bottom: "conv243"
  top: "conv243"
}
layer {
  name: "conv246"
  type: "Convolution"
  bottom: "conv243"
  top: "conv246"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape248"
  type: "Reshape"
  bottom: "conv246"
  top: "reshape248"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm249"
  type: "Permute"
  bottom: "reshape248"
  top: "perm249"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax250"
  type: "Softmax"
  bottom: "perm249"
  top: "softmax250"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape252"
  type: "Reshape"
  bottom: "softmax250"
  top: "reshape252"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice253"
  type: "Slice"
  bottom: "reshape252"
  top: "slice253-0"
  top: "slice253-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul254"
  type: "Scale"
  bottom: "slice240-0"
  bottom: "slice253-0"
  top: "mul254"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul255"
  type: "Scale"
  bottom: "slice240-1"
  bottom: "slice253-1"
  top: "mul255"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add256"
  type: "Eltwise"
  bottom: "mul254"
  bottom: "mul255"
  top: "add256"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv257"
  type: "Convolution"
  bottom: "add256"
  top: "conv257"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn258"
  type: "BatchNorm"
  bottom: "conv257"
  top: "conv257"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale258"
  type: "Scale"
  bottom: "conv257"
  top: "conv257"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add259"
  type: "Eltwise"
  bottom: "conv257"
  bottom: "add232"
  top: "add259"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu260"
  type: "ReLU"
  bottom: "add259"
  top: "add259"
}
layer {
  name: "conv261"
  type: "Convolution"
  bottom: "add259"
  top: "conv261"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn262"
  type: "BatchNorm"
  bottom: "conv261"
  top: "conv261"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale262"
  type: "Scale"
  bottom: "conv261"
  top: "conv261"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu263"
  type: "ReLU"
  bottom: "conv261"
  top: "conv261"
}
layer {
  name: "conv264"
  type: "Convolution"
  bottom: "conv261"
  top: "conv264"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn265"
  type: "BatchNorm"
  bottom: "conv264"
  top: "conv264"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale265"
  type: "Scale"
  bottom: "conv264"
  top: "conv264"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu266"
  type: "ReLU"
  bottom: "conv264"
  top: "conv264"
}
layer {
  name: "slice267"
  type: "Slice"
  bottom: "conv264"
  top: "slice267-0"
  top: "slice267-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add268"
  type: "Eltwise"
  bottom: "slice267-0"
  bottom: "slice267-1"
  top: "add268"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool269"
  type: "Pooling"
  bottom: "add268"
  top: "pool269"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv270"
  type: "Convolution"
  bottom: "pool269"
  top: "conv270"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn271"
  type: "BatchNorm"
  bottom: "conv270"
  top: "conv270"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale271"
  type: "Scale"
  bottom: "conv270"
  top: "conv270"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu272"
  type: "ReLU"
  bottom: "conv270"
  top: "conv270"
}
layer {
  name: "conv273"
  type: "Convolution"
  bottom: "conv270"
  top: "conv273"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape275"
  type: "Reshape"
  bottom: "conv273"
  top: "reshape275"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm276"
  type: "Permute"
  bottom: "reshape275"
  top: "perm276"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax277"
  type: "Softmax"
  bottom: "perm276"
  top: "softmax277"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape279"
  type: "Reshape"
  bottom: "softmax277"
  top: "reshape279"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice280"
  type: "Slice"
  bottom: "reshape279"
  top: "slice280-0"
  top: "slice280-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul281"
  type: "Scale"
  bottom: "slice267-0"
  bottom: "slice280-0"
  top: "mul281"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul282"
  type: "Scale"
  bottom: "slice267-1"
  bottom: "slice280-1"
  top: "mul282"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add283"
  type: "Eltwise"
  bottom: "mul281"
  bottom: "mul282"
  top: "add283"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv284"
  type: "Convolution"
  bottom: "add283"
  top: "conv284"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn285"
  type: "BatchNorm"
  bottom: "conv284"
  top: "conv284"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale285"
  type: "Scale"
  bottom: "conv284"
  top: "conv284"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add286"
  type: "Eltwise"
  bottom: "conv284"
  bottom: "add259"
  top: "add286"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu287"
  type: "ReLU"
  bottom: "add286"
  top: "add286"
}
layer {
  name: "conv288"
  type: "Convolution"
  bottom: "add286"
  top: "conv288"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn289"
  type: "BatchNorm"
  bottom: "conv288"
  top: "conv288"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale289"
  type: "Scale"
  bottom: "conv288"
  top: "conv288"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu290"
  type: "ReLU"
  bottom: "conv288"
  top: "conv288"
}
layer {
  name: "conv291"
  type: "Convolution"
  bottom: "conv288"
  top: "conv291"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn292"
  type: "BatchNorm"
  bottom: "conv291"
  top: "conv291"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale292"
  type: "Scale"
  bottom: "conv291"
  top: "conv291"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu293"
  type: "ReLU"
  bottom: "conv291"
  top: "conv291"
}
layer {
  name: "slice294"
  type: "Slice"
  bottom: "conv291"
  top: "slice294-0"
  top: "slice294-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add295"
  type: "Eltwise"
  bottom: "slice294-0"
  bottom: "slice294-1"
  top: "add295"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool296"
  type: "Pooling"
  bottom: "add295"
  top: "pool296"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv297"
  type: "Convolution"
  bottom: "pool296"
  top: "conv297"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn298"
  type: "BatchNorm"
  bottom: "conv297"
  top: "conv297"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale298"
  type: "Scale"
  bottom: "conv297"
  top: "conv297"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu299"
  type: "ReLU"
  bottom: "conv297"
  top: "conv297"
}
layer {
  name: "conv300"
  type: "Convolution"
  bottom: "conv297"
  top: "conv300"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape302"
  type: "Reshape"
  bottom: "conv300"
  top: "reshape302"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm303"
  type: "Permute"
  bottom: "reshape302"
  top: "perm303"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax304"
  type: "Softmax"
  bottom: "perm303"
  top: "softmax304"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape306"
  type: "Reshape"
  bottom: "softmax304"
  top: "reshape306"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice307"
  type: "Slice"
  bottom: "reshape306"
  top: "slice307-0"
  top: "slice307-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul308"
  type: "Scale"
  bottom: "slice294-0"
  bottom: "slice307-0"
  top: "mul308"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul309"
  type: "Scale"
  bottom: "slice294-1"
  bottom: "slice307-1"
  top: "mul309"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add310"
  type: "Eltwise"
  bottom: "mul308"
  bottom: "mul309"
  top: "add310"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv311"
  type: "Convolution"
  bottom: "add310"
  top: "conv311"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn312"
  type: "BatchNorm"
  bottom: "conv311"
  top: "conv311"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale312"
  type: "Scale"
  bottom: "conv311"
  top: "conv311"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add313"
  type: "Eltwise"
  bottom: "conv311"
  bottom: "add286"
  top: "add313"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu314"
  type: "ReLU"
  bottom: "add313"
  top: "add313"
}
layer {
  name: "conv315"
  type: "Convolution"
  bottom: "add313"
  top: "conv315"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn316"
  type: "BatchNorm"
  bottom: "conv315"
  top: "conv315"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale316"
  type: "Scale"
  bottom: "conv315"
  top: "conv315"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu317"
  type: "ReLU"
  bottom: "conv315"
  top: "conv315"
}
layer {
  name: "conv318"
  type: "Convolution"
  bottom: "conv315"
  top: "conv318"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn319"
  type: "BatchNorm"
  bottom: "conv318"
  top: "conv318"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale319"
  type: "Scale"
  bottom: "conv318"
  top: "conv318"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu320"
  type: "ReLU"
  bottom: "conv318"
  top: "conv318"
}
layer {
  name: "slice321"
  type: "Slice"
  bottom: "conv318"
  top: "slice321-0"
  top: "slice321-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add322"
  type: "Eltwise"
  bottom: "slice321-0"
  bottom: "slice321-1"
  top: "add322"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool323"
  type: "Pooling"
  bottom: "add322"
  top: "pool323"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv324"
  type: "Convolution"
  bottom: "pool323"
  top: "conv324"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn325"
  type: "BatchNorm"
  bottom: "conv324"
  top: "conv324"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale325"
  type: "Scale"
  bottom: "conv324"
  top: "conv324"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu326"
  type: "ReLU"
  bottom: "conv324"
  top: "conv324"
}
layer {
  name: "conv327"
  type: "Convolution"
  bottom: "conv324"
  top: "conv327"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape329"
  type: "Reshape"
  bottom: "conv327"
  top: "reshape329"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm330"
  type: "Permute"
  bottom: "reshape329"
  top: "perm330"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax331"
  type: "Softmax"
  bottom: "perm330"
  top: "softmax331"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape333"
  type: "Reshape"
  bottom: "softmax331"
  top: "reshape333"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice334"
  type: "Slice"
  bottom: "reshape333"
  top: "slice334-0"
  top: "slice334-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul335"
  type: "Scale"
  bottom: "slice321-0"
  bottom: "slice334-0"
  top: "mul335"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul336"
  type: "Scale"
  bottom: "slice321-1"
  bottom: "slice334-1"
  top: "mul336"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add337"
  type: "Eltwise"
  bottom: "mul335"
  bottom: "mul336"
  top: "add337"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv338"
  type: "Convolution"
  bottom: "add337"
  top: "conv338"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn339"
  type: "BatchNorm"
  bottom: "conv338"
  top: "conv338"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale339"
  type: "Scale"
  bottom: "conv338"
  top: "conv338"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add340"
  type: "Eltwise"
  bottom: "conv338"
  bottom: "add313"
  top: "add340"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu341"
  type: "ReLU"
  bottom: "add340"
  top: "add340"
}
layer {
  name: "conv342"
  type: "Convolution"
  bottom: "add340"
  top: "conv342"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn343"
  type: "BatchNorm"
  bottom: "conv342"
  top: "conv342"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale343"
  type: "Scale"
  bottom: "conv342"
  top: "conv342"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu344"
  type: "ReLU"
  bottom: "conv342"
  top: "conv342"
}
layer {
  name: "conv345"
  type: "Convolution"
  bottom: "conv342"
  top: "conv345"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn346"
  type: "BatchNorm"
  bottom: "conv345"
  top: "conv345"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale346"
  type: "Scale"
  bottom: "conv345"
  top: "conv345"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu347"
  type: "ReLU"
  bottom: "conv345"
  top: "conv345"
}
layer {
  name: "slice348"
  type: "Slice"
  bottom: "conv345"
  top: "slice348-0"
  top: "slice348-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add349"
  type: "Eltwise"
  bottom: "slice348-0"
  bottom: "slice348-1"
  top: "add349"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool350"
  type: "Pooling"
  bottom: "add349"
  top: "pool350"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv351"
  type: "Convolution"
  bottom: "pool350"
  top: "conv351"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn352"
  type: "BatchNorm"
  bottom: "conv351"
  top: "conv351"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale352"
  type: "Scale"
  bottom: "conv351"
  top: "conv351"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu353"
  type: "ReLU"
  bottom: "conv351"
  top: "conv351"
}
layer {
  name: "conv354"
  type: "Convolution"
  bottom: "conv351"
  top: "conv354"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape356"
  type: "Reshape"
  bottom: "conv354"
  top: "reshape356"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm357"
  type: "Permute"
  bottom: "reshape356"
  top: "perm357"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax358"
  type: "Softmax"
  bottom: "perm357"
  top: "softmax358"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape360"
  type: "Reshape"
  bottom: "softmax358"
  top: "reshape360"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice361"
  type: "Slice"
  bottom: "reshape360"
  top: "slice361-0"
  top: "slice361-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul362"
  type: "Scale"
  bottom: "slice348-0"
  bottom: "slice361-0"
  top: "mul362"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul363"
  type: "Scale"
  bottom: "slice348-1"
  bottom: "slice361-1"
  top: "mul363"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add364"
  type: "Eltwise"
  bottom: "mul362"
  bottom: "mul363"
  top: "add364"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv365"
  type: "Convolution"
  bottom: "add364"
  top: "conv365"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn366"
  type: "BatchNorm"
  bottom: "conv365"
  top: "conv365"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale366"
  type: "Scale"
  bottom: "conv365"
  top: "conv365"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add367"
  type: "Eltwise"
  bottom: "conv365"
  bottom: "add340"
  top: "add367"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu368"
  type: "ReLU"
  bottom: "add367"
  top: "add367"
}
layer {
  name: "conv369"
  type: "Convolution"
  bottom: "add367"
  top: "conv369"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn370"
  type: "BatchNorm"
  bottom: "conv369"
  top: "conv369"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale370"
  type: "Scale"
  bottom: "conv369"
  top: "conv369"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu371"
  type: "ReLU"
  bottom: "conv369"
  top: "conv369"
}
layer {
  name: "conv372"
  type: "Convolution"
  bottom: "conv369"
  top: "conv372"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn373"
  type: "BatchNorm"
  bottom: "conv372"
  top: "conv372"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale373"
  type: "Scale"
  bottom: "conv372"
  top: "conv372"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu374"
  type: "ReLU"
  bottom: "conv372"
  top: "conv372"
}
layer {
  name: "slice375"
  type: "Slice"
  bottom: "conv372"
  top: "slice375-0"
  top: "slice375-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add376"
  type: "Eltwise"
  bottom: "slice375-0"
  bottom: "slice375-1"
  top: "add376"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool377"
  type: "Pooling"
  bottom: "add376"
  top: "pool377"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv378"
  type: "Convolution"
  bottom: "pool377"
  top: "conv378"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn379"
  type: "BatchNorm"
  bottom: "conv378"
  top: "conv378"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale379"
  type: "Scale"
  bottom: "conv378"
  top: "conv378"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu380"
  type: "ReLU"
  bottom: "conv378"
  top: "conv378"
}
layer {
  name: "conv381"
  type: "Convolution"
  bottom: "conv378"
  top: "conv381"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape383"
  type: "Reshape"
  bottom: "conv381"
  top: "reshape383"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm384"
  type: "Permute"
  bottom: "reshape383"
  top: "perm384"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax385"
  type: "Softmax"
  bottom: "perm384"
  top: "softmax385"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape387"
  type: "Reshape"
  bottom: "softmax385"
  top: "reshape387"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice388"
  type: "Slice"
  bottom: "reshape387"
  top: "slice388-0"
  top: "slice388-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul389"
  type: "Scale"
  bottom: "slice375-0"
  bottom: "slice388-0"
  top: "mul389"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul390"
  type: "Scale"
  bottom: "slice375-1"
  bottom: "slice388-1"
  top: "mul390"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add391"
  type: "Eltwise"
  bottom: "mul389"
  bottom: "mul390"
  top: "add391"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv392"
  type: "Convolution"
  bottom: "add391"
  top: "conv392"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn393"
  type: "BatchNorm"
  bottom: "conv392"
  top: "conv392"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale393"
  type: "Scale"
  bottom: "conv392"
  top: "conv392"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add394"
  type: "Eltwise"
  bottom: "conv392"
  bottom: "add367"
  top: "add394"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu395"
  type: "ReLU"
  bottom: "add394"
  top: "add394"
}
layer {
  name: "conv396"
  type: "Convolution"
  bottom: "add394"
  top: "conv396"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn397"
  type: "BatchNorm"
  bottom: "conv396"
  top: "conv396"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale397"
  type: "Scale"
  bottom: "conv396"
  top: "conv396"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu398"
  type: "ReLU"
  bottom: "conv396"
  top: "conv396"
}
layer {
  name: "conv399"
  type: "Convolution"
  bottom: "conv396"
  top: "conv399"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn400"
  type: "BatchNorm"
  bottom: "conv399"
  top: "conv399"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale400"
  type: "Scale"
  bottom: "conv399"
  top: "conv399"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu401"
  type: "ReLU"
  bottom: "conv399"
  top: "conv399"
}
layer {
  name: "slice402"
  type: "Slice"
  bottom: "conv399"
  top: "slice402-0"
  top: "slice402-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add403"
  type: "Eltwise"
  bottom: "slice402-0"
  bottom: "slice402-1"
  top: "add403"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool404"
  type: "Pooling"
  bottom: "add403"
  top: "pool404"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv405"
  type: "Convolution"
  bottom: "pool404"
  top: "conv405"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn406"
  type: "BatchNorm"
  bottom: "conv405"
  top: "conv405"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale406"
  type: "Scale"
  bottom: "conv405"
  top: "conv405"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu407"
  type: "ReLU"
  bottom: "conv405"
  top: "conv405"
}
layer {
  name: "conv408"
  type: "Convolution"
  bottom: "conv405"
  top: "conv408"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape410"
  type: "Reshape"
  bottom: "conv408"
  top: "reshape410"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm411"
  type: "Permute"
  bottom: "reshape410"
  top: "perm411"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax412"
  type: "Softmax"
  bottom: "perm411"
  top: "softmax412"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape414"
  type: "Reshape"
  bottom: "softmax412"
  top: "reshape414"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice415"
  type: "Slice"
  bottom: "reshape414"
  top: "slice415-0"
  top: "slice415-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul416"
  type: "Scale"
  bottom: "slice402-0"
  bottom: "slice415-0"
  top: "mul416"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul417"
  type: "Scale"
  bottom: "slice402-1"
  bottom: "slice415-1"
  top: "mul417"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add418"
  type: "Eltwise"
  bottom: "mul416"
  bottom: "mul417"
  top: "add418"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv419"
  type: "Convolution"
  bottom: "add418"
  top: "conv419"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn420"
  type: "BatchNorm"
  bottom: "conv419"
  top: "conv419"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale420"
  type: "Scale"
  bottom: "conv419"
  top: "conv419"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add421"
  type: "Eltwise"
  bottom: "conv419"
  bottom: "add394"
  top: "add421"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu422"
  type: "ReLU"
  bottom: "add421"
  top: "add421"
}
layer {
  name: "conv423"
  type: "Convolution"
  bottom: "add421"
  top: "conv423"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn424"
  type: "BatchNorm"
  bottom: "conv423"
  top: "conv423"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale424"
  type: "Scale"
  bottom: "conv423"
  top: "conv423"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu425"
  type: "ReLU"
  bottom: "conv423"
  top: "conv423"
}
layer {
  name: "conv426"
  type: "Convolution"
  bottom: "conv423"
  top: "conv426"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn427"
  type: "BatchNorm"
  bottom: "conv426"
  top: "conv426"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale427"
  type: "Scale"
  bottom: "conv426"
  top: "conv426"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu428"
  type: "ReLU"
  bottom: "conv426"
  top: "conv426"
}
layer {
  name: "slice429"
  type: "Slice"
  bottom: "conv426"
  top: "slice429-0"
  top: "slice429-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add430"
  type: "Eltwise"
  bottom: "slice429-0"
  bottom: "slice429-1"
  top: "add430"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool431"
  type: "Pooling"
  bottom: "add430"
  top: "pool431"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv432"
  type: "Convolution"
  bottom: "pool431"
  top: "conv432"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn433"
  type: "BatchNorm"
  bottom: "conv432"
  top: "conv432"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale433"
  type: "Scale"
  bottom: "conv432"
  top: "conv432"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu434"
  type: "ReLU"
  bottom: "conv432"
  top: "conv432"
}
layer {
  name: "conv435"
  type: "Convolution"
  bottom: "conv432"
  top: "conv435"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape437"
  type: "Reshape"
  bottom: "conv435"
  top: "reshape437"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm438"
  type: "Permute"
  bottom: "reshape437"
  top: "perm438"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax439"
  type: "Softmax"
  bottom: "perm438"
  top: "softmax439"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape441"
  type: "Reshape"
  bottom: "softmax439"
  top: "reshape441"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice442"
  type: "Slice"
  bottom: "reshape441"
  top: "slice442-0"
  top: "slice442-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul443"
  type: "Scale"
  bottom: "slice429-0"
  bottom: "slice442-0"
  top: "mul443"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul444"
  type: "Scale"
  bottom: "slice429-1"
  bottom: "slice442-1"
  top: "mul444"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add445"
  type: "Eltwise"
  bottom: "mul443"
  bottom: "mul444"
  top: "add445"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv446"
  type: "Convolution"
  bottom: "add445"
  top: "conv446"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn447"
  type: "BatchNorm"
  bottom: "conv446"
  top: "conv446"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale447"
  type: "Scale"
  bottom: "conv446"
  top: "conv446"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add448"
  type: "Eltwise"
  bottom: "conv446"
  bottom: "add421"
  top: "add448"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu449"
  type: "ReLU"
  bottom: "add448"
  top: "add448"
}
layer {
  name: "conv450"
  type: "Convolution"
  bottom: "add448"
  top: "conv450"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn451"
  type: "BatchNorm"
  bottom: "conv450"
  top: "conv450"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale451"
  type: "Scale"
  bottom: "conv450"
  top: "conv450"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu452"
  type: "ReLU"
  bottom: "conv450"
  top: "conv450"
}
layer {
  name: "conv453"
  type: "Convolution"
  bottom: "conv450"
  top: "conv453"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn454"
  type: "BatchNorm"
  bottom: "conv453"
  top: "conv453"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale454"
  type: "Scale"
  bottom: "conv453"
  top: "conv453"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu455"
  type: "ReLU"
  bottom: "conv453"
  top: "conv453"
}
layer {
  name: "slice456"
  type: "Slice"
  bottom: "conv453"
  top: "slice456-0"
  top: "slice456-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add457"
  type: "Eltwise"
  bottom: "slice456-0"
  bottom: "slice456-1"
  top: "add457"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool458"
  type: "Pooling"
  bottom: "add457"
  top: "pool458"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv459"
  type: "Convolution"
  bottom: "pool458"
  top: "conv459"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn460"
  type: "BatchNorm"
  bottom: "conv459"
  top: "conv459"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale460"
  type: "Scale"
  bottom: "conv459"
  top: "conv459"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu461"
  type: "ReLU"
  bottom: "conv459"
  top: "conv459"
}
layer {
  name: "conv462"
  type: "Convolution"
  bottom: "conv459"
  top: "conv462"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape464"
  type: "Reshape"
  bottom: "conv462"
  top: "reshape464"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm465"
  type: "Permute"
  bottom: "reshape464"
  top: "perm465"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax466"
  type: "Softmax"
  bottom: "perm465"
  top: "softmax466"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape468"
  type: "Reshape"
  bottom: "softmax466"
  top: "reshape468"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice469"
  type: "Slice"
  bottom: "reshape468"
  top: "slice469-0"
  top: "slice469-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul470"
  type: "Scale"
  bottom: "slice456-0"
  bottom: "slice469-0"
  top: "mul470"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul471"
  type: "Scale"
  bottom: "slice456-1"
  bottom: "slice469-1"
  top: "mul471"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add472"
  type: "Eltwise"
  bottom: "mul470"
  bottom: "mul471"
  top: "add472"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv473"
  type: "Convolution"
  bottom: "add472"
  top: "conv473"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn474"
  type: "BatchNorm"
  bottom: "conv473"
  top: "conv473"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale474"
  type: "Scale"
  bottom: "conv473"
  top: "conv473"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add475"
  type: "Eltwise"
  bottom: "conv473"
  bottom: "add448"
  top: "add475"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu476"
  type: "ReLU"
  bottom: "add475"
  top: "add475"
}
layer {
  name: "conv477"
  type: "Convolution"
  bottom: "add475"
  top: "conv477"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn478"
  type: "BatchNorm"
  bottom: "conv477"
  top: "conv477"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale478"
  type: "Scale"
  bottom: "conv477"
  top: "conv477"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu479"
  type: "ReLU"
  bottom: "conv477"
  top: "conv477"
}
layer {
  name: "conv480"
  type: "Convolution"
  bottom: "conv477"
  top: "conv480"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn481"
  type: "BatchNorm"
  bottom: "conv480"
  top: "conv480"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale481"
  type: "Scale"
  bottom: "conv480"
  top: "conv480"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu482"
  type: "ReLU"
  bottom: "conv480"
  top: "conv480"
}
layer {
  name: "slice483"
  type: "Slice"
  bottom: "conv480"
  top: "slice483-0"
  top: "slice483-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add484"
  type: "Eltwise"
  bottom: "slice483-0"
  bottom: "slice483-1"
  top: "add484"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool485"
  type: "Pooling"
  bottom: "add484"
  top: "pool485"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv486"
  type: "Convolution"
  bottom: "pool485"
  top: "conv486"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn487"
  type: "BatchNorm"
  bottom: "conv486"
  top: "conv486"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale487"
  type: "Scale"
  bottom: "conv486"
  top: "conv486"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu488"
  type: "ReLU"
  bottom: "conv486"
  top: "conv486"
}
layer {
  name: "conv489"
  type: "Convolution"
  bottom: "conv486"
  top: "conv489"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape491"
  type: "Reshape"
  bottom: "conv489"
  top: "reshape491"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm492"
  type: "Permute"
  bottom: "reshape491"
  top: "perm492"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax493"
  type: "Softmax"
  bottom: "perm492"
  top: "softmax493"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape495"
  type: "Reshape"
  bottom: "softmax493"
  top: "reshape495"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice496"
  type: "Slice"
  bottom: "reshape495"
  top: "slice496-0"
  top: "slice496-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul497"
  type: "Scale"
  bottom: "slice483-0"
  bottom: "slice496-0"
  top: "mul497"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul498"
  type: "Scale"
  bottom: "slice483-1"
  bottom: "slice496-1"
  top: "mul498"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add499"
  type: "Eltwise"
  bottom: "mul497"
  bottom: "mul498"
  top: "add499"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv500"
  type: "Convolution"
  bottom: "add499"
  top: "conv500"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn501"
  type: "BatchNorm"
  bottom: "conv500"
  top: "conv500"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale501"
  type: "Scale"
  bottom: "conv500"
  top: "conv500"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add502"
  type: "Eltwise"
  bottom: "conv500"
  bottom: "add475"
  top: "add502"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu503"
  type: "ReLU"
  bottom: "add502"
  top: "add502"
}
layer {
  name: "conv504"
  type: "Convolution"
  bottom: "add502"
  top: "conv504"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn505"
  type: "BatchNorm"
  bottom: "conv504"
  top: "conv504"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale505"
  type: "Scale"
  bottom: "conv504"
  top: "conv504"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu506"
  type: "ReLU"
  bottom: "conv504"
  top: "conv504"
}
layer {
  name: "conv507"
  type: "Convolution"
  bottom: "conv504"
  top: "conv507"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn508"
  type: "BatchNorm"
  bottom: "conv507"
  top: "conv507"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale508"
  type: "Scale"
  bottom: "conv507"
  top: "conv507"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu509"
  type: "ReLU"
  bottom: "conv507"
  top: "conv507"
}
layer {
  name: "slice510"
  type: "Slice"
  bottom: "conv507"
  top: "slice510-0"
  top: "slice510-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add511"
  type: "Eltwise"
  bottom: "slice510-0"
  bottom: "slice510-1"
  top: "add511"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool512"
  type: "Pooling"
  bottom: "add511"
  top: "pool512"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv513"
  type: "Convolution"
  bottom: "pool512"
  top: "conv513"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn514"
  type: "BatchNorm"
  bottom: "conv513"
  top: "conv513"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale514"
  type: "Scale"
  bottom: "conv513"
  top: "conv513"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu515"
  type: "ReLU"
  bottom: "conv513"
  top: "conv513"
}
layer {
  name: "conv516"
  type: "Convolution"
  bottom: "conv513"
  top: "conv516"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape518"
  type: "Reshape"
  bottom: "conv516"
  top: "reshape518"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm519"
  type: "Permute"
  bottom: "reshape518"
  top: "perm519"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax520"
  type: "Softmax"
  bottom: "perm519"
  top: "softmax520"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape522"
  type: "Reshape"
  bottom: "softmax520"
  top: "reshape522"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice523"
  type: "Slice"
  bottom: "reshape522"
  top: "slice523-0"
  top: "slice523-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul524"
  type: "Scale"
  bottom: "slice510-0"
  bottom: "slice523-0"
  top: "mul524"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul525"
  type: "Scale"
  bottom: "slice510-1"
  bottom: "slice523-1"
  top: "mul525"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add526"
  type: "Eltwise"
  bottom: "mul524"
  bottom: "mul525"
  top: "add526"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv527"
  type: "Convolution"
  bottom: "add526"
  top: "conv527"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn528"
  type: "BatchNorm"
  bottom: "conv527"
  top: "conv527"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale528"
  type: "Scale"
  bottom: "conv527"
  top: "conv527"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add529"
  type: "Eltwise"
  bottom: "conv527"
  bottom: "add502"
  top: "add529"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu530"
  type: "ReLU"
  bottom: "add529"
  top: "add529"
}
layer {
  name: "conv531"
  type: "Convolution"
  bottom: "add529"
  top: "conv531"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn532"
  type: "BatchNorm"
  bottom: "conv531"
  top: "conv531"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale532"
  type: "Scale"
  bottom: "conv531"
  top: "conv531"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu533"
  type: "ReLU"
  bottom: "conv531"
  top: "conv531"
}
layer {
  name: "conv534"
  type: "Convolution"
  bottom: "conv531"
  top: "conv534"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn535"
  type: "BatchNorm"
  bottom: "conv534"
  top: "conv534"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale535"
  type: "Scale"
  bottom: "conv534"
  top: "conv534"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu536"
  type: "ReLU"
  bottom: "conv534"
  top: "conv534"
}
layer {
  name: "slice537"
  type: "Slice"
  bottom: "conv534"
  top: "slice537-0"
  top: "slice537-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add538"
  type: "Eltwise"
  bottom: "slice537-0"
  bottom: "slice537-1"
  top: "add538"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool539"
  type: "Pooling"
  bottom: "add538"
  top: "pool539"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv540"
  type: "Convolution"
  bottom: "pool539"
  top: "conv540"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn541"
  type: "BatchNorm"
  bottom: "conv540"
  top: "conv540"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale541"
  type: "Scale"
  bottom: "conv540"
  top: "conv540"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu542"
  type: "ReLU"
  bottom: "conv540"
  top: "conv540"
}
layer {
  name: "conv543"
  type: "Convolution"
  bottom: "conv540"
  top: "conv543"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape545"
  type: "Reshape"
  bottom: "conv543"
  top: "reshape545"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm546"
  type: "Permute"
  bottom: "reshape545"
  top: "perm546"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax547"
  type: "Softmax"
  bottom: "perm546"
  top: "softmax547"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape549"
  type: "Reshape"
  bottom: "softmax547"
  top: "reshape549"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice550"
  type: "Slice"
  bottom: "reshape549"
  top: "slice550-0"
  top: "slice550-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul551"
  type: "Scale"
  bottom: "slice537-0"
  bottom: "slice550-0"
  top: "mul551"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul552"
  type: "Scale"
  bottom: "slice537-1"
  bottom: "slice550-1"
  top: "mul552"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add553"
  type: "Eltwise"
  bottom: "mul551"
  bottom: "mul552"
  top: "add553"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv554"
  type: "Convolution"
  bottom: "add553"
  top: "conv554"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn555"
  type: "BatchNorm"
  bottom: "conv554"
  top: "conv554"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale555"
  type: "Scale"
  bottom: "conv554"
  top: "conv554"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add556"
  type: "Eltwise"
  bottom: "conv554"
  bottom: "add529"
  top: "add556"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu557"
  type: "ReLU"
  bottom: "add556"
  top: "add556"
}
layer {
  name: "conv558"
  type: "Convolution"
  bottom: "add556"
  top: "conv558"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn559"
  type: "BatchNorm"
  bottom: "conv558"
  top: "conv558"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale559"
  type: "Scale"
  bottom: "conv558"
  top: "conv558"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu560"
  type: "ReLU"
  bottom: "conv558"
  top: "conv558"
}
layer {
  name: "conv561"
  type: "Convolution"
  bottom: "conv558"
  top: "conv561"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn562"
  type: "BatchNorm"
  bottom: "conv561"
  top: "conv561"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale562"
  type: "Scale"
  bottom: "conv561"
  top: "conv561"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu563"
  type: "ReLU"
  bottom: "conv561"
  top: "conv561"
}
layer {
  name: "slice564"
  type: "Slice"
  bottom: "conv561"
  top: "slice564-0"
  top: "slice564-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add565"
  type: "Eltwise"
  bottom: "slice564-0"
  bottom: "slice564-1"
  top: "add565"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool566"
  type: "Pooling"
  bottom: "add565"
  top: "pool566"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv567"
  type: "Convolution"
  bottom: "pool566"
  top: "conv567"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn568"
  type: "BatchNorm"
  bottom: "conv567"
  top: "conv567"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale568"
  type: "Scale"
  bottom: "conv567"
  top: "conv567"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu569"
  type: "ReLU"
  bottom: "conv567"
  top: "conv567"
}
layer {
  name: "conv570"
  type: "Convolution"
  bottom: "conv567"
  top: "conv570"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape572"
  type: "Reshape"
  bottom: "conv570"
  top: "reshape572"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm573"
  type: "Permute"
  bottom: "reshape572"
  top: "perm573"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax574"
  type: "Softmax"
  bottom: "perm573"
  top: "softmax574"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape576"
  type: "Reshape"
  bottom: "softmax574"
  top: "reshape576"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice577"
  type: "Slice"
  bottom: "reshape576"
  top: "slice577-0"
  top: "slice577-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul578"
  type: "Scale"
  bottom: "slice564-0"
  bottom: "slice577-0"
  top: "mul578"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul579"
  type: "Scale"
  bottom: "slice564-1"
  bottom: "slice577-1"
  top: "mul579"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add580"
  type: "Eltwise"
  bottom: "mul578"
  bottom: "mul579"
  top: "add580"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv581"
  type: "Convolution"
  bottom: "add580"
  top: "conv581"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn582"
  type: "BatchNorm"
  bottom: "conv581"
  top: "conv581"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale582"
  type: "Scale"
  bottom: "conv581"
  top: "conv581"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add583"
  type: "Eltwise"
  bottom: "conv581"
  bottom: "add556"
  top: "add583"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu584"
  type: "ReLU"
  bottom: "add583"
  top: "add583"
}
layer {
  name: "conv585"
  type: "Convolution"
  bottom: "add583"
  top: "conv585"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn586"
  type: "BatchNorm"
  bottom: "conv585"
  top: "conv585"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale586"
  type: "Scale"
  bottom: "conv585"
  top: "conv585"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu587"
  type: "ReLU"
  bottom: "conv585"
  top: "conv585"
}
layer {
  name: "conv588"
  type: "Convolution"
  bottom: "conv585"
  top: "conv588"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn589"
  type: "BatchNorm"
  bottom: "conv588"
  top: "conv588"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale589"
  type: "Scale"
  bottom: "conv588"
  top: "conv588"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu590"
  type: "ReLU"
  bottom: "conv588"
  top: "conv588"
}
layer {
  name: "slice591"
  type: "Slice"
  bottom: "conv588"
  top: "slice591-0"
  top: "slice591-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add592"
  type: "Eltwise"
  bottom: "slice591-0"
  bottom: "slice591-1"
  top: "add592"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool593"
  type: "Pooling"
  bottom: "add592"
  top: "pool593"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv594"
  type: "Convolution"
  bottom: "pool593"
  top: "conv594"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn595"
  type: "BatchNorm"
  bottom: "conv594"
  top: "conv594"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale595"
  type: "Scale"
  bottom: "conv594"
  top: "conv594"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu596"
  type: "ReLU"
  bottom: "conv594"
  top: "conv594"
}
layer {
  name: "conv597"
  type: "Convolution"
  bottom: "conv594"
  top: "conv597"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape599"
  type: "Reshape"
  bottom: "conv597"
  top: "reshape599"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm600"
  type: "Permute"
  bottom: "reshape599"
  top: "perm600"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax601"
  type: "Softmax"
  bottom: "perm600"
  top: "softmax601"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape603"
  type: "Reshape"
  bottom: "softmax601"
  top: "reshape603"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice604"
  type: "Slice"
  bottom: "reshape603"
  top: "slice604-0"
  top: "slice604-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul605"
  type: "Scale"
  bottom: "slice591-0"
  bottom: "slice604-0"
  top: "mul605"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul606"
  type: "Scale"
  bottom: "slice591-1"
  bottom: "slice604-1"
  top: "mul606"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add607"
  type: "Eltwise"
  bottom: "mul605"
  bottom: "mul606"
  top: "add607"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv608"
  type: "Convolution"
  bottom: "add607"
  top: "conv608"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn609"
  type: "BatchNorm"
  bottom: "conv608"
  top: "conv608"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale609"
  type: "Scale"
  bottom: "conv608"
  top: "conv608"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add610"
  type: "Eltwise"
  bottom: "conv608"
  bottom: "add583"
  top: "add610"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu611"
  type: "ReLU"
  bottom: "add610"
  top: "add610"
}
layer {
  name: "conv612"
  type: "Convolution"
  bottom: "add610"
  top: "conv612"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn613"
  type: "BatchNorm"
  bottom: "conv612"
  top: "conv612"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale613"
  type: "Scale"
  bottom: "conv612"
  top: "conv612"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu614"
  type: "ReLU"
  bottom: "conv612"
  top: "conv612"
}
layer {
  name: "conv615"
  type: "Convolution"
  bottom: "conv612"
  top: "conv615"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn616"
  type: "BatchNorm"
  bottom: "conv615"
  top: "conv615"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale616"
  type: "Scale"
  bottom: "conv615"
  top: "conv615"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu617"
  type: "ReLU"
  bottom: "conv615"
  top: "conv615"
}
layer {
  name: "slice618"
  type: "Slice"
  bottom: "conv615"
  top: "slice618-0"
  top: "slice618-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add619"
  type: "Eltwise"
  bottom: "slice618-0"
  bottom: "slice618-1"
  top: "add619"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool620"
  type: "Pooling"
  bottom: "add619"
  top: "pool620"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv621"
  type: "Convolution"
  bottom: "pool620"
  top: "conv621"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn622"
  type: "BatchNorm"
  bottom: "conv621"
  top: "conv621"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale622"
  type: "Scale"
  bottom: "conv621"
  top: "conv621"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu623"
  type: "ReLU"
  bottom: "conv621"
  top: "conv621"
}
layer {
  name: "conv624"
  type: "Convolution"
  bottom: "conv621"
  top: "conv624"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape626"
  type: "Reshape"
  bottom: "conv624"
  top: "reshape626"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm627"
  type: "Permute"
  bottom: "reshape626"
  top: "perm627"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax628"
  type: "Softmax"
  bottom: "perm627"
  top: "softmax628"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape630"
  type: "Reshape"
  bottom: "softmax628"
  top: "reshape630"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice631"
  type: "Slice"
  bottom: "reshape630"
  top: "slice631-0"
  top: "slice631-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul632"
  type: "Scale"
  bottom: "slice618-0"
  bottom: "slice631-0"
  top: "mul632"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul633"
  type: "Scale"
  bottom: "slice618-1"
  bottom: "slice631-1"
  top: "mul633"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add634"
  type: "Eltwise"
  bottom: "mul632"
  bottom: "mul633"
  top: "add634"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv635"
  type: "Convolution"
  bottom: "add634"
  top: "conv635"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn636"
  type: "BatchNorm"
  bottom: "conv635"
  top: "conv635"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale636"
  type: "Scale"
  bottom: "conv635"
  top: "conv635"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add637"
  type: "Eltwise"
  bottom: "conv635"
  bottom: "add610"
  top: "add637"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu638"
  type: "ReLU"
  bottom: "add637"
  top: "add637"
}
layer {
  name: "conv639"
  type: "Convolution"
  bottom: "add637"
  top: "conv639"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn640"
  type: "BatchNorm"
  bottom: "conv639"
  top: "conv639"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale640"
  type: "Scale"
  bottom: "conv639"
  top: "conv639"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu641"
  type: "ReLU"
  bottom: "conv639"
  top: "conv639"
}
layer {
  name: "conv642"
  type: "Convolution"
  bottom: "conv639"
  top: "conv642"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn643"
  type: "BatchNorm"
  bottom: "conv642"
  top: "conv642"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale643"
  type: "Scale"
  bottom: "conv642"
  top: "conv642"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu644"
  type: "ReLU"
  bottom: "conv642"
  top: "conv642"
}
layer {
  name: "slice645"
  type: "Slice"
  bottom: "conv642"
  top: "slice645-0"
  top: "slice645-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add646"
  type: "Eltwise"
  bottom: "slice645-0"
  bottom: "slice645-1"
  top: "add646"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool647"
  type: "Pooling"
  bottom: "add646"
  top: "pool647"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv648"
  type: "Convolution"
  bottom: "pool647"
  top: "conv648"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn649"
  type: "BatchNorm"
  bottom: "conv648"
  top: "conv648"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale649"
  type: "Scale"
  bottom: "conv648"
  top: "conv648"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu650"
  type: "ReLU"
  bottom: "conv648"
  top: "conv648"
}
layer {
  name: "conv651"
  type: "Convolution"
  bottom: "conv648"
  top: "conv651"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape653"
  type: "Reshape"
  bottom: "conv651"
  top: "reshape653"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm654"
  type: "Permute"
  bottom: "reshape653"
  top: "perm654"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax655"
  type: "Softmax"
  bottom: "perm654"
  top: "softmax655"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape657"
  type: "Reshape"
  bottom: "softmax655"
  top: "reshape657"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice658"
  type: "Slice"
  bottom: "reshape657"
  top: "slice658-0"
  top: "slice658-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul659"
  type: "Scale"
  bottom: "slice645-0"
  bottom: "slice658-0"
  top: "mul659"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul660"
  type: "Scale"
  bottom: "slice645-1"
  bottom: "slice658-1"
  top: "mul660"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add661"
  type: "Eltwise"
  bottom: "mul659"
  bottom: "mul660"
  top: "add661"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv662"
  type: "Convolution"
  bottom: "add661"
  top: "conv662"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn663"
  type: "BatchNorm"
  bottom: "conv662"
  top: "conv662"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale663"
  type: "Scale"
  bottom: "conv662"
  top: "conv662"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add664"
  type: "Eltwise"
  bottom: "conv662"
  bottom: "add637"
  top: "add664"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu665"
  type: "ReLU"
  bottom: "add664"
  top: "add664"
}
layer {
  name: "conv666"
  type: "Convolution"
  bottom: "add664"
  top: "conv666"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn667"
  type: "BatchNorm"
  bottom: "conv666"
  top: "conv666"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale667"
  type: "Scale"
  bottom: "conv666"
  top: "conv666"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu668"
  type: "ReLU"
  bottom: "conv666"
  top: "conv666"
}
layer {
  name: "conv669"
  type: "Convolution"
  bottom: "conv666"
  top: "conv669"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn670"
  type: "BatchNorm"
  bottom: "conv669"
  top: "conv669"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale670"
  type: "Scale"
  bottom: "conv669"
  top: "conv669"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu671"
  type: "ReLU"
  bottom: "conv669"
  top: "conv669"
}
layer {
  name: "slice672"
  type: "Slice"
  bottom: "conv669"
  top: "slice672-0"
  top: "slice672-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add673"
  type: "Eltwise"
  bottom: "slice672-0"
  bottom: "slice672-1"
  top: "add673"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool674"
  type: "Pooling"
  bottom: "add673"
  top: "pool674"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv675"
  type: "Convolution"
  bottom: "pool674"
  top: "conv675"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn676"
  type: "BatchNorm"
  bottom: "conv675"
  top: "conv675"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale676"
  type: "Scale"
  bottom: "conv675"
  top: "conv675"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu677"
  type: "ReLU"
  bottom: "conv675"
  top: "conv675"
}
layer {
  name: "conv678"
  type: "Convolution"
  bottom: "conv675"
  top: "conv678"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape680"
  type: "Reshape"
  bottom: "conv678"
  top: "reshape680"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm681"
  type: "Permute"
  bottom: "reshape680"
  top: "perm681"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax682"
  type: "Softmax"
  bottom: "perm681"
  top: "softmax682"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape684"
  type: "Reshape"
  bottom: "softmax682"
  top: "reshape684"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice685"
  type: "Slice"
  bottom: "reshape684"
  top: "slice685-0"
  top: "slice685-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul686"
  type: "Scale"
  bottom: "slice672-0"
  bottom: "slice685-0"
  top: "mul686"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul687"
  type: "Scale"
  bottom: "slice672-1"
  bottom: "slice685-1"
  top: "mul687"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add688"
  type: "Eltwise"
  bottom: "mul686"
  bottom: "mul687"
  top: "add688"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv689"
  type: "Convolution"
  bottom: "add688"
  top: "conv689"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn690"
  type: "BatchNorm"
  bottom: "conv689"
  top: "conv689"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale690"
  type: "Scale"
  bottom: "conv689"
  top: "conv689"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add691"
  type: "Eltwise"
  bottom: "conv689"
  bottom: "add664"
  top: "add691"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu692"
  type: "ReLU"
  bottom: "add691"
  top: "add691"
}
layer {
  name: "conv693"
  type: "Convolution"
  bottom: "add691"
  top: "conv693"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn694"
  type: "BatchNorm"
  bottom: "conv693"
  top: "conv693"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale694"
  type: "Scale"
  bottom: "conv693"
  top: "conv693"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu695"
  type: "ReLU"
  bottom: "conv693"
  top: "conv693"
}
layer {
  name: "conv696"
  type: "Convolution"
  bottom: "conv693"
  top: "conv696"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn697"
  type: "BatchNorm"
  bottom: "conv696"
  top: "conv696"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale697"
  type: "Scale"
  bottom: "conv696"
  top: "conv696"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu698"
  type: "ReLU"
  bottom: "conv696"
  top: "conv696"
}
layer {
  name: "slice699"
  type: "Slice"
  bottom: "conv696"
  top: "slice699-0"
  top: "slice699-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add700"
  type: "Eltwise"
  bottom: "slice699-0"
  bottom: "slice699-1"
  top: "add700"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool701"
  type: "Pooling"
  bottom: "add700"
  top: "pool701"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv702"
  type: "Convolution"
  bottom: "pool701"
  top: "conv702"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn703"
  type: "BatchNorm"
  bottom: "conv702"
  top: "conv702"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale703"
  type: "Scale"
  bottom: "conv702"
  top: "conv702"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu704"
  type: "ReLU"
  bottom: "conv702"
  top: "conv702"
}
layer {
  name: "conv705"
  type: "Convolution"
  bottom: "conv702"
  top: "conv705"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape707"
  type: "Reshape"
  bottom: "conv705"
  top: "reshape707"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm708"
  type: "Permute"
  bottom: "reshape707"
  top: "perm708"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax709"
  type: "Softmax"
  bottom: "perm708"
  top: "softmax709"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape711"
  type: "Reshape"
  bottom: "softmax709"
  top: "reshape711"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice712"
  type: "Slice"
  bottom: "reshape711"
  top: "slice712-0"
  top: "slice712-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul713"
  type: "Scale"
  bottom: "slice699-0"
  bottom: "slice712-0"
  top: "mul713"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul714"
  type: "Scale"
  bottom: "slice699-1"
  bottom: "slice712-1"
  top: "mul714"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add715"
  type: "Eltwise"
  bottom: "mul713"
  bottom: "mul714"
  top: "add715"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv716"
  type: "Convolution"
  bottom: "add715"
  top: "conv716"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn717"
  type: "BatchNorm"
  bottom: "conv716"
  top: "conv716"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale717"
  type: "Scale"
  bottom: "conv716"
  top: "conv716"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add718"
  type: "Eltwise"
  bottom: "conv716"
  bottom: "add691"
  top: "add718"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu719"
  type: "ReLU"
  bottom: "add718"
  top: "add718"
}
layer {
  name: "conv720"
  type: "Convolution"
  bottom: "add718"
  top: "conv720"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn721"
  type: "BatchNorm"
  bottom: "conv720"
  top: "conv720"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale721"
  type: "Scale"
  bottom: "conv720"
  top: "conv720"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu722"
  type: "ReLU"
  bottom: "conv720"
  top: "conv720"
}
layer {
  name: "conv723"
  type: "Convolution"
  bottom: "conv720"
  top: "conv723"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn724"
  type: "BatchNorm"
  bottom: "conv723"
  top: "conv723"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale724"
  type: "Scale"
  bottom: "conv723"
  top: "conv723"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu725"
  type: "ReLU"
  bottom: "conv723"
  top: "conv723"
}
layer {
  name: "slice726"
  type: "Slice"
  bottom: "conv723"
  top: "slice726-0"
  top: "slice726-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add727"
  type: "Eltwise"
  bottom: "slice726-0"
  bottom: "slice726-1"
  top: "add727"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool728"
  type: "Pooling"
  bottom: "add727"
  top: "pool728"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv729"
  type: "Convolution"
  bottom: "pool728"
  top: "conv729"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn730"
  type: "BatchNorm"
  bottom: "conv729"
  top: "conv729"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale730"
  type: "Scale"
  bottom: "conv729"
  top: "conv729"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu731"
  type: "ReLU"
  bottom: "conv729"
  top: "conv729"
}
layer {
  name: "conv732"
  type: "Convolution"
  bottom: "conv729"
  top: "conv732"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape734"
  type: "Reshape"
  bottom: "conv732"
  top: "reshape734"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm735"
  type: "Permute"
  bottom: "reshape734"
  top: "perm735"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax736"
  type: "Softmax"
  bottom: "perm735"
  top: "softmax736"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape738"
  type: "Reshape"
  bottom: "softmax736"
  top: "reshape738"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice739"
  type: "Slice"
  bottom: "reshape738"
  top: "slice739-0"
  top: "slice739-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul740"
  type: "Scale"
  bottom: "slice726-0"
  bottom: "slice739-0"
  top: "mul740"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul741"
  type: "Scale"
  bottom: "slice726-1"
  bottom: "slice739-1"
  top: "mul741"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add742"
  type: "Eltwise"
  bottom: "mul740"
  bottom: "mul741"
  top: "add742"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv743"
  type: "Convolution"
  bottom: "add742"
  top: "conv743"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn744"
  type: "BatchNorm"
  bottom: "conv743"
  top: "conv743"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale744"
  type: "Scale"
  bottom: "conv743"
  top: "conv743"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add745"
  type: "Eltwise"
  bottom: "conv743"
  bottom: "add718"
  top: "add745"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu746"
  type: "ReLU"
  bottom: "add745"
  top: "add745"
}
layer {
  name: "conv747"
  type: "Convolution"
  bottom: "add745"
  top: "conv747"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn748"
  type: "BatchNorm"
  bottom: "conv747"
  top: "conv747"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale748"
  type: "Scale"
  bottom: "conv747"
  top: "conv747"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu749"
  type: "ReLU"
  bottom: "conv747"
  top: "conv747"
}
layer {
  name: "conv750"
  type: "Convolution"
  bottom: "conv747"
  top: "conv750"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn751"
  type: "BatchNorm"
  bottom: "conv750"
  top: "conv750"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale751"
  type: "Scale"
  bottom: "conv750"
  top: "conv750"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu752"
  type: "ReLU"
  bottom: "conv750"
  top: "conv750"
}
layer {
  name: "slice753"
  type: "Slice"
  bottom: "conv750"
  top: "slice753-0"
  top: "slice753-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add754"
  type: "Eltwise"
  bottom: "slice753-0"
  bottom: "slice753-1"
  top: "add754"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool755"
  type: "Pooling"
  bottom: "add754"
  top: "pool755"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv756"
  type: "Convolution"
  bottom: "pool755"
  top: "conv756"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn757"
  type: "BatchNorm"
  bottom: "conv756"
  top: "conv756"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale757"
  type: "Scale"
  bottom: "conv756"
  top: "conv756"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu758"
  type: "ReLU"
  bottom: "conv756"
  top: "conv756"
}
layer {
  name: "conv759"
  type: "Convolution"
  bottom: "conv756"
  top: "conv759"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape761"
  type: "Reshape"
  bottom: "conv759"
  top: "reshape761"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm762"
  type: "Permute"
  bottom: "reshape761"
  top: "perm762"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax763"
  type: "Softmax"
  bottom: "perm762"
  top: "softmax763"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape765"
  type: "Reshape"
  bottom: "softmax763"
  top: "reshape765"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice766"
  type: "Slice"
  bottom: "reshape765"
  top: "slice766-0"
  top: "slice766-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul767"
  type: "Scale"
  bottom: "slice753-0"
  bottom: "slice766-0"
  top: "mul767"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul768"
  type: "Scale"
  bottom: "slice753-1"
  bottom: "slice766-1"
  top: "mul768"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add769"
  type: "Eltwise"
  bottom: "mul767"
  bottom: "mul768"
  top: "add769"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv770"
  type: "Convolution"
  bottom: "add769"
  top: "conv770"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn771"
  type: "BatchNorm"
  bottom: "conv770"
  top: "conv770"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale771"
  type: "Scale"
  bottom: "conv770"
  top: "conv770"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add772"
  type: "Eltwise"
  bottom: "conv770"
  bottom: "add745"
  top: "add772"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu773"
  type: "ReLU"
  bottom: "add772"
  top: "add772"
}
layer {
  name: "conv774"
  type: "Convolution"
  bottom: "add772"
  top: "conv774"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn775"
  type: "BatchNorm"
  bottom: "conv774"
  top: "conv774"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale775"
  type: "Scale"
  bottom: "conv774"
  top: "conv774"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu776"
  type: "ReLU"
  bottom: "conv774"
  top: "conv774"
}
layer {
  name: "conv777"
  type: "Convolution"
  bottom: "conv774"
  top: "conv777"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn778"
  type: "BatchNorm"
  bottom: "conv777"
  top: "conv777"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale778"
  type: "Scale"
  bottom: "conv777"
  top: "conv777"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu779"
  type: "ReLU"
  bottom: "conv777"
  top: "conv777"
}
layer {
  name: "slice780"
  type: "Slice"
  bottom: "conv777"
  top: "slice780-0"
  top: "slice780-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add781"
  type: "Eltwise"
  bottom: "slice780-0"
  bottom: "slice780-1"
  top: "add781"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool782"
  type: "Pooling"
  bottom: "add781"
  top: "pool782"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv783"
  type: "Convolution"
  bottom: "pool782"
  top: "conv783"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn784"
  type: "BatchNorm"
  bottom: "conv783"
  top: "conv783"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale784"
  type: "Scale"
  bottom: "conv783"
  top: "conv783"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu785"
  type: "ReLU"
  bottom: "conv783"
  top: "conv783"
}
layer {
  name: "conv786"
  type: "Convolution"
  bottom: "conv783"
  top: "conv786"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape788"
  type: "Reshape"
  bottom: "conv786"
  top: "reshape788"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm789"
  type: "Permute"
  bottom: "reshape788"
  top: "perm789"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax790"
  type: "Softmax"
  bottom: "perm789"
  top: "softmax790"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape792"
  type: "Reshape"
  bottom: "softmax790"
  top: "reshape792"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice793"
  type: "Slice"
  bottom: "reshape792"
  top: "slice793-0"
  top: "slice793-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul794"
  type: "Scale"
  bottom: "slice780-0"
  bottom: "slice793-0"
  top: "mul794"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul795"
  type: "Scale"
  bottom: "slice780-1"
  bottom: "slice793-1"
  top: "mul795"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add796"
  type: "Eltwise"
  bottom: "mul794"
  bottom: "mul795"
  top: "add796"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv797"
  type: "Convolution"
  bottom: "add796"
  top: "conv797"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn798"
  type: "BatchNorm"
  bottom: "conv797"
  top: "conv797"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale798"
  type: "Scale"
  bottom: "conv797"
  top: "conv797"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add799"
  type: "Eltwise"
  bottom: "conv797"
  bottom: "add772"
  top: "add799"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu800"
  type: "ReLU"
  bottom: "add799"
  top: "add799"
}
layer {
  name: "conv801"
  type: "Convolution"
  bottom: "add799"
  top: "conv801"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn802"
  type: "BatchNorm"
  bottom: "conv801"
  top: "conv801"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale802"
  type: "Scale"
  bottom: "conv801"
  top: "conv801"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu803"
  type: "ReLU"
  bottom: "conv801"
  top: "conv801"
}
layer {
  name: "conv804"
  type: "Convolution"
  bottom: "conv801"
  top: "conv804"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn805"
  type: "BatchNorm"
  bottom: "conv804"
  top: "conv804"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale805"
  type: "Scale"
  bottom: "conv804"
  top: "conv804"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu806"
  type: "ReLU"
  bottom: "conv804"
  top: "conv804"
}
layer {
  name: "slice807"
  type: "Slice"
  bottom: "conv804"
  top: "slice807-0"
  top: "slice807-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add808"
  type: "Eltwise"
  bottom: "slice807-0"
  bottom: "slice807-1"
  top: "add808"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool809"
  type: "Pooling"
  bottom: "add808"
  top: "pool809"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv810"
  type: "Convolution"
  bottom: "pool809"
  top: "conv810"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn811"
  type: "BatchNorm"
  bottom: "conv810"
  top: "conv810"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale811"
  type: "Scale"
  bottom: "conv810"
  top: "conv810"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu812"
  type: "ReLU"
  bottom: "conv810"
  top: "conv810"
}
layer {
  name: "conv813"
  type: "Convolution"
  bottom: "conv810"
  top: "conv813"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape815"
  type: "Reshape"
  bottom: "conv813"
  top: "reshape815"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm816"
  type: "Permute"
  bottom: "reshape815"
  top: "perm816"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax817"
  type: "Softmax"
  bottom: "perm816"
  top: "softmax817"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape819"
  type: "Reshape"
  bottom: "softmax817"
  top: "reshape819"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice820"
  type: "Slice"
  bottom: "reshape819"
  top: "slice820-0"
  top: "slice820-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul821"
  type: "Scale"
  bottom: "slice807-0"
  bottom: "slice820-0"
  top: "mul821"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul822"
  type: "Scale"
  bottom: "slice807-1"
  bottom: "slice820-1"
  top: "mul822"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add823"
  type: "Eltwise"
  bottom: "mul821"
  bottom: "mul822"
  top: "add823"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv824"
  type: "Convolution"
  bottom: "add823"
  top: "conv824"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn825"
  type: "BatchNorm"
  bottom: "conv824"
  top: "conv824"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale825"
  type: "Scale"
  bottom: "conv824"
  top: "conv824"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add826"
  type: "Eltwise"
  bottom: "conv824"
  bottom: "add799"
  top: "add826"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu827"
  type: "ReLU"
  bottom: "add826"
  top: "add826"
}
layer {
  name: "conv828"
  type: "Convolution"
  bottom: "add826"
  top: "conv828"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn829"
  type: "BatchNorm"
  bottom: "conv828"
  top: "conv828"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale829"
  type: "Scale"
  bottom: "conv828"
  top: "conv828"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu830"
  type: "ReLU"
  bottom: "conv828"
  top: "conv828"
}
layer {
  name: "conv831"
  type: "Convolution"
  bottom: "conv828"
  top: "conv831"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn832"
  type: "BatchNorm"
  bottom: "conv831"
  top: "conv831"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale832"
  type: "Scale"
  bottom: "conv831"
  top: "conv831"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu833"
  type: "ReLU"
  bottom: "conv831"
  top: "conv831"
}
layer {
  name: "slice834"
  type: "Slice"
  bottom: "conv831"
  top: "slice834-0"
  top: "slice834-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add835"
  type: "Eltwise"
  bottom: "slice834-0"
  bottom: "slice834-1"
  top: "add835"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool836"
  type: "Pooling"
  bottom: "add835"
  top: "pool836"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv837"
  type: "Convolution"
  bottom: "pool836"
  top: "conv837"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn838"
  type: "BatchNorm"
  bottom: "conv837"
  top: "conv837"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale838"
  type: "Scale"
  bottom: "conv837"
  top: "conv837"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu839"
  type: "ReLU"
  bottom: "conv837"
  top: "conv837"
}
layer {
  name: "conv840"
  type: "Convolution"
  bottom: "conv837"
  top: "conv840"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape842"
  type: "Reshape"
  bottom: "conv840"
  top: "reshape842"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm843"
  type: "Permute"
  bottom: "reshape842"
  top: "perm843"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax844"
  type: "Softmax"
  bottom: "perm843"
  top: "softmax844"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape846"
  type: "Reshape"
  bottom: "softmax844"
  top: "reshape846"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice847"
  type: "Slice"
  bottom: "reshape846"
  top: "slice847-0"
  top: "slice847-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul848"
  type: "Scale"
  bottom: "slice834-0"
  bottom: "slice847-0"
  top: "mul848"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul849"
  type: "Scale"
  bottom: "slice834-1"
  bottom: "slice847-1"
  top: "mul849"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add850"
  type: "Eltwise"
  bottom: "mul848"
  bottom: "mul849"
  top: "add850"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv851"
  type: "Convolution"
  bottom: "add850"
  top: "conv851"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn852"
  type: "BatchNorm"
  bottom: "conv851"
  top: "conv851"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale852"
  type: "Scale"
  bottom: "conv851"
  top: "conv851"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add853"
  type: "Eltwise"
  bottom: "conv851"
  bottom: "add826"
  top: "add853"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu854"
  type: "ReLU"
  bottom: "add853"
  top: "add853"
}
layer {
  name: "conv855"
  type: "Convolution"
  bottom: "add853"
  top: "conv855"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn856"
  type: "BatchNorm"
  bottom: "conv855"
  top: "conv855"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale856"
  type: "Scale"
  bottom: "conv855"
  top: "conv855"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu857"
  type: "ReLU"
  bottom: "conv855"
  top: "conv855"
}
layer {
  name: "conv858"
  type: "Convolution"
  bottom: "conv855"
  top: "conv858"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn859"
  type: "BatchNorm"
  bottom: "conv858"
  top: "conv858"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale859"
  type: "Scale"
  bottom: "conv858"
  top: "conv858"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu860"
  type: "ReLU"
  bottom: "conv858"
  top: "conv858"
}
layer {
  name: "slice861"
  type: "Slice"
  bottom: "conv858"
  top: "slice861-0"
  top: "slice861-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add862"
  type: "Eltwise"
  bottom: "slice861-0"
  bottom: "slice861-1"
  top: "add862"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool863"
  type: "Pooling"
  bottom: "add862"
  top: "pool863"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv864"
  type: "Convolution"
  bottom: "pool863"
  top: "conv864"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn865"
  type: "BatchNorm"
  bottom: "conv864"
  top: "conv864"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale865"
  type: "Scale"
  bottom: "conv864"
  top: "conv864"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu866"
  type: "ReLU"
  bottom: "conv864"
  top: "conv864"
}
layer {
  name: "conv867"
  type: "Convolution"
  bottom: "conv864"
  top: "conv867"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape869"
  type: "Reshape"
  bottom: "conv867"
  top: "reshape869"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm870"
  type: "Permute"
  bottom: "reshape869"
  top: "perm870"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax871"
  type: "Softmax"
  bottom: "perm870"
  top: "softmax871"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape873"
  type: "Reshape"
  bottom: "softmax871"
  top: "reshape873"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice874"
  type: "Slice"
  bottom: "reshape873"
  top: "slice874-0"
  top: "slice874-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul875"
  type: "Scale"
  bottom: "slice861-0"
  bottom: "slice874-0"
  top: "mul875"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul876"
  type: "Scale"
  bottom: "slice861-1"
  bottom: "slice874-1"
  top: "mul876"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add877"
  type: "Eltwise"
  bottom: "mul875"
  bottom: "mul876"
  top: "add877"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv878"
  type: "Convolution"
  bottom: "add877"
  top: "conv878"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn879"
  type: "BatchNorm"
  bottom: "conv878"
  top: "conv878"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale879"
  type: "Scale"
  bottom: "conv878"
  top: "conv878"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add880"
  type: "Eltwise"
  bottom: "conv878"
  bottom: "add853"
  top: "add880"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu881"
  type: "ReLU"
  bottom: "add880"
  top: "add880"
}
layer {
  name: "conv882"
  type: "Convolution"
  bottom: "add880"
  top: "conv882"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn883"
  type: "BatchNorm"
  bottom: "conv882"
  top: "conv882"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale883"
  type: "Scale"
  bottom: "conv882"
  top: "conv882"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu884"
  type: "ReLU"
  bottom: "conv882"
  top: "conv882"
}
layer {
  name: "conv885"
  type: "Convolution"
  bottom: "conv882"
  top: "conv885"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn886"
  type: "BatchNorm"
  bottom: "conv885"
  top: "conv885"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale886"
  type: "Scale"
  bottom: "conv885"
  top: "conv885"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu887"
  type: "ReLU"
  bottom: "conv885"
  top: "conv885"
}
layer {
  name: "slice888"
  type: "Slice"
  bottom: "conv885"
  top: "slice888-0"
  top: "slice888-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "add889"
  type: "Eltwise"
  bottom: "slice888-0"
  bottom: "slice888-1"
  top: "add889"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool890"
  type: "Pooling"
  bottom: "add889"
  top: "pool890"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv891"
  type: "Convolution"
  bottom: "pool890"
  top: "conv891"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn892"
  type: "BatchNorm"
  bottom: "conv891"
  top: "conv891"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale892"
  type: "Scale"
  bottom: "conv891"
  top: "conv891"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu893"
  type: "ReLU"
  bottom: "conv891"
  top: "conv891"
}
layer {
  name: "conv894"
  type: "Convolution"
  bottom: "conv891"
  top: "conv894"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape896"
  type: "Reshape"
  bottom: "conv894"
  top: "reshape896"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm897"
  type: "Permute"
  bottom: "reshape896"
  top: "perm897"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax898"
  type: "Softmax"
  bottom: "perm897"
  top: "softmax898"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape900"
  type: "Reshape"
  bottom: "softmax898"
  top: "reshape900"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice901"
  type: "Slice"
  bottom: "reshape900"
  top: "slice901-0"
  top: "slice901-1"
  slice_param {
    slice_point: 128
    axis: 1
  }
}
layer {
  name: "mul902"
  type: "Scale"
  bottom: "slice888-0"
  bottom: "slice901-0"
  top: "mul902"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul903"
  type: "Scale"
  bottom: "slice888-1"
  bottom: "slice901-1"
  top: "mul903"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add904"
  type: "Eltwise"
  bottom: "mul902"
  bottom: "mul903"
  top: "add904"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv905"
  type: "Convolution"
  bottom: "add904"
  top: "conv905"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn906"
  type: "BatchNorm"
  bottom: "conv905"
  top: "conv905"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale906"
  type: "Scale"
  bottom: "conv905"
  top: "conv905"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add907"
  type: "Eltwise"
  bottom: "conv905"
  bottom: "add880"
  top: "add907"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu908"
  type: "ReLU"
  bottom: "add907"
  top: "add907"
}
layer {
  name: "conv909"
  type: "Convolution"
  bottom: "add907"
  top: "conv909"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn910"
  type: "BatchNorm"
  bottom: "conv909"
  top: "conv909"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale910"
  type: "Scale"
  bottom: "conv909"
  top: "conv909"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu911"
  type: "ReLU"
  bottom: "conv909"
  top: "conv909"
}
layer {
  name: "conv912"
  type: "Convolution"
  bottom: "conv909"
  top: "conv912"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn913"
  type: "BatchNorm"
  bottom: "conv912"
  top: "conv912"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale913"
  type: "Scale"
  bottom: "conv912"
  top: "conv912"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu914"
  type: "ReLU"
  bottom: "conv912"
  top: "conv912"
}
layer {
  name: "slice915"
  type: "Slice"
  bottom: "conv912"
  top: "slice915-0"
  top: "slice915-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add916"
  type: "Eltwise"
  bottom: "slice915-0"
  bottom: "slice915-1"
  top: "add916"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool917"
  type: "Pooling"
  bottom: "add916"
  top: "pool917"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv918"
  type: "Convolution"
  bottom: "pool917"
  top: "conv918"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn919"
  type: "BatchNorm"
  bottom: "conv918"
  top: "conv918"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale919"
  type: "Scale"
  bottom: "conv918"
  top: "conv918"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu920"
  type: "ReLU"
  bottom: "conv918"
  top: "conv918"
}
layer {
  name: "conv921"
  type: "Convolution"
  bottom: "conv918"
  top: "conv921"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape923"
  type: "Reshape"
  bottom: "conv921"
  top: "reshape923"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm924"
  type: "Permute"
  bottom: "reshape923"
  top: "perm924"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax925"
  type: "Softmax"
  bottom: "perm924"
  top: "softmax925"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape927"
  type: "Reshape"
  bottom: "softmax925"
  top: "reshape927"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice928"
  type: "Slice"
  bottom: "reshape927"
  top: "slice928-0"
  top: "slice928-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul929"
  type: "Scale"
  bottom: "slice915-0"
  bottom: "slice928-0"
  top: "mul929"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul930"
  type: "Scale"
  bottom: "slice915-1"
  bottom: "slice928-1"
  top: "mul930"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add931"
  type: "Eltwise"
  bottom: "mul929"
  bottom: "mul930"
  top: "add931"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool932"
  type: "Pooling"
  bottom: "add931"
  top: "pool932"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
    pad: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv933"
  type: "Convolution"
  bottom: "pool932"
  top: "conv933"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn934"
  type: "BatchNorm"
  bottom: "conv933"
  top: "conv933"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale934"
  type: "Scale"
  bottom: "conv933"
  top: "conv933"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "pool935"
  type: "Pooling"
  bottom: "add907"
  top: "pool935"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv936"
  type: "Convolution"
  bottom: "pool935"
  top: "conv936"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn937"
  type: "BatchNorm"
  bottom: "conv936"
  top: "conv936"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale937"
  type: "Scale"
  bottom: "conv936"
  top: "conv936"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add938"
  type: "Eltwise"
  bottom: "conv933"
  bottom: "conv936"
  top: "add938"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu939"
  type: "ReLU"
  bottom: "add938"
  top: "add938"
}
layer {
  name: "conv940"
  type: "Convolution"
  bottom: "add938"
  top: "conv940"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn941"
  type: "BatchNorm"
  bottom: "conv940"
  top: "conv940"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale941"
  type: "Scale"
  bottom: "conv940"
  top: "conv940"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu942"
  type: "ReLU"
  bottom: "conv940"
  top: "conv940"
}
layer {
  name: "conv943"
  type: "Convolution"
  bottom: "conv940"
  top: "conv943"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn944"
  type: "BatchNorm"
  bottom: "conv943"
  top: "conv943"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale944"
  type: "Scale"
  bottom: "conv943"
  top: "conv943"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu945"
  type: "ReLU"
  bottom: "conv943"
  top: "conv943"
}
layer {
  name: "slice946"
  type: "Slice"
  bottom: "conv943"
  top: "slice946-0"
  top: "slice946-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add947"
  type: "Eltwise"
  bottom: "slice946-0"
  bottom: "slice946-1"
  top: "add947"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool948"
  type: "Pooling"
  bottom: "add947"
  top: "pool948"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv949"
  type: "Convolution"
  bottom: "pool948"
  top: "conv949"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn950"
  type: "BatchNorm"
  bottom: "conv949"
  top: "conv949"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale950"
  type: "Scale"
  bottom: "conv949"
  top: "conv949"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu951"
  type: "ReLU"
  bottom: "conv949"
  top: "conv949"
}
layer {
  name: "conv952"
  type: "Convolution"
  bottom: "conv949"
  top: "conv952"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape954"
  type: "Reshape"
  bottom: "conv952"
  top: "reshape954"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm955"
  type: "Permute"
  bottom: "reshape954"
  top: "perm955"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax956"
  type: "Softmax"
  bottom: "perm955"
  top: "softmax956"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape958"
  type: "Reshape"
  bottom: "softmax956"
  top: "reshape958"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice959"
  type: "Slice"
  bottom: "reshape958"
  top: "slice959-0"
  top: "slice959-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul960"
  type: "Scale"
  bottom: "slice946-0"
  bottom: "slice959-0"
  top: "mul960"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul961"
  type: "Scale"
  bottom: "slice946-1"
  bottom: "slice959-1"
  top: "mul961"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add962"
  type: "Eltwise"
  bottom: "mul960"
  bottom: "mul961"
  top: "add962"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv963"
  type: "Convolution"
  bottom: "add962"
  top: "conv963"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn964"
  type: "BatchNorm"
  bottom: "conv963"
  top: "conv963"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale964"
  type: "Scale"
  bottom: "conv963"
  top: "conv963"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add965"
  type: "Eltwise"
  bottom: "conv963"
  bottom: "add938"
  top: "add965"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu966"
  type: "ReLU"
  bottom: "add965"
  top: "add965"
}
layer {
  name: "conv967"
  type: "Convolution"
  bottom: "add965"
  top: "conv967"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn968"
  type: "BatchNorm"
  bottom: "conv967"
  top: "conv967"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale968"
  type: "Scale"
  bottom: "conv967"
  top: "conv967"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu969"
  type: "ReLU"
  bottom: "conv967"
  top: "conv967"
}
layer {
  name: "conv970"
  type: "Convolution"
  bottom: "conv967"
  top: "conv970"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn971"
  type: "BatchNorm"
  bottom: "conv970"
  top: "conv970"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale971"
  type: "Scale"
  bottom: "conv970"
  top: "conv970"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu972"
  type: "ReLU"
  bottom: "conv970"
  top: "conv970"
}
layer {
  name: "slice973"
  type: "Slice"
  bottom: "conv970"
  top: "slice973-0"
  top: "slice973-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add974"
  type: "Eltwise"
  bottom: "slice973-0"
  bottom: "slice973-1"
  top: "add974"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool975"
  type: "Pooling"
  bottom: "add974"
  top: "pool975"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv976"
  type: "Convolution"
  bottom: "pool975"
  top: "conv976"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn977"
  type: "BatchNorm"
  bottom: "conv976"
  top: "conv976"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale977"
  type: "Scale"
  bottom: "conv976"
  top: "conv976"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu978"
  type: "ReLU"
  bottom: "conv976"
  top: "conv976"
}
layer {
  name: "conv979"
  type: "Convolution"
  bottom: "conv976"
  top: "conv979"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape981"
  type: "Reshape"
  bottom: "conv979"
  top: "reshape981"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm982"
  type: "Permute"
  bottom: "reshape981"
  top: "perm982"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax983"
  type: "Softmax"
  bottom: "perm982"
  top: "softmax983"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape985"
  type: "Reshape"
  bottom: "softmax983"
  top: "reshape985"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice986"
  type: "Slice"
  bottom: "reshape985"
  top: "slice986-0"
  top: "slice986-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul987"
  type: "Scale"
  bottom: "slice973-0"
  bottom: "slice986-0"
  top: "mul987"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul988"
  type: "Scale"
  bottom: "slice973-1"
  bottom: "slice986-1"
  top: "mul988"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add989"
  type: "Eltwise"
  bottom: "mul987"
  bottom: "mul988"
  top: "add989"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv990"
  type: "Convolution"
  bottom: "add989"
  top: "conv990"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn991"
  type: "BatchNorm"
  bottom: "conv990"
  top: "conv990"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale991"
  type: "Scale"
  bottom: "conv990"
  top: "conv990"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add992"
  type: "Eltwise"
  bottom: "conv990"
  bottom: "add965"
  top: "add992"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu993"
  type: "ReLU"
  bottom: "add992"
  top: "add992"
}
layer {
  name: "conv994"
  type: "Convolution"
  bottom: "add992"
  top: "conv994"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn995"
  type: "BatchNorm"
  bottom: "conv994"
  top: "conv994"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale995"
  type: "Scale"
  bottom: "conv994"
  top: "conv994"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu996"
  type: "ReLU"
  bottom: "conv994"
  top: "conv994"
}
layer {
  name: "conv997"
  type: "Convolution"
  bottom: "conv994"
  top: "conv997"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn998"
  type: "BatchNorm"
  bottom: "conv997"
  top: "conv997"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale998"
  type: "Scale"
  bottom: "conv997"
  top: "conv997"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu999"
  type: "ReLU"
  bottom: "conv997"
  top: "conv997"
}
layer {
  name: "slice1000"
  type: "Slice"
  bottom: "conv997"
  top: "slice1000-0"
  top: "slice1000-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1001"
  type: "Eltwise"
  bottom: "slice1000-0"
  bottom: "slice1000-1"
  top: "add1001"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1002"
  type: "Pooling"
  bottom: "add1001"
  top: "pool1002"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1003"
  type: "Convolution"
  bottom: "pool1002"
  top: "conv1003"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1004"
  type: "BatchNorm"
  bottom: "conv1003"
  top: "conv1003"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1004"
  type: "Scale"
  bottom: "conv1003"
  top: "conv1003"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1005"
  type: "ReLU"
  bottom: "conv1003"
  top: "conv1003"
}
layer {
  name: "conv1006"
  type: "Convolution"
  bottom: "conv1003"
  top: "conv1006"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1008"
  type: "Reshape"
  bottom: "conv1006"
  top: "reshape1008"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1009"
  type: "Permute"
  bottom: "reshape1008"
  top: "perm1009"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1010"
  type: "Softmax"
  bottom: "perm1009"
  top: "softmax1010"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1012"
  type: "Reshape"
  bottom: "softmax1010"
  top: "reshape1012"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1013"
  type: "Slice"
  bottom: "reshape1012"
  top: "slice1013-0"
  top: "slice1013-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1014"
  type: "Scale"
  bottom: "slice1000-0"
  bottom: "slice1013-0"
  top: "mul1014"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1015"
  type: "Scale"
  bottom: "slice1000-1"
  bottom: "slice1013-1"
  top: "mul1015"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1016"
  type: "Eltwise"
  bottom: "mul1014"
  bottom: "mul1015"
  top: "add1016"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1017"
  type: "Convolution"
  bottom: "add1016"
  top: "conv1017"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1018"
  type: "BatchNorm"
  bottom: "conv1017"
  top: "conv1017"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1018"
  type: "Scale"
  bottom: "conv1017"
  top: "conv1017"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1019"
  type: "Eltwise"
  bottom: "conv1017"
  bottom: "add992"
  top: "add1019"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1020"
  type: "ReLU"
  bottom: "add1019"
  top: "add1019"
}
layer {
  name: "conv1021"
  type: "Convolution"
  bottom: "add1019"
  top: "conv1021"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1022"
  type: "BatchNorm"
  bottom: "conv1021"
  top: "conv1021"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1022"
  type: "Scale"
  bottom: "conv1021"
  top: "conv1021"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1023"
  type: "ReLU"
  bottom: "conv1021"
  top: "conv1021"
}
layer {
  name: "conv1024"
  type: "Convolution"
  bottom: "conv1021"
  top: "conv1024"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1025"
  type: "BatchNorm"
  bottom: "conv1024"
  top: "conv1024"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1025"
  type: "Scale"
  bottom: "conv1024"
  top: "conv1024"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1026"
  type: "ReLU"
  bottom: "conv1024"
  top: "conv1024"
}
layer {
  name: "slice1027"
  type: "Slice"
  bottom: "conv1024"
  top: "slice1027-0"
  top: "slice1027-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1028"
  type: "Eltwise"
  bottom: "slice1027-0"
  bottom: "slice1027-1"
  top: "add1028"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1029"
  type: "Pooling"
  bottom: "add1028"
  top: "pool1029"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1030"
  type: "Convolution"
  bottom: "pool1029"
  top: "conv1030"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1031"
  type: "BatchNorm"
  bottom: "conv1030"
  top: "conv1030"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1031"
  type: "Scale"
  bottom: "conv1030"
  top: "conv1030"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1032"
  type: "ReLU"
  bottom: "conv1030"
  top: "conv1030"
}
layer {
  name: "conv1033"
  type: "Convolution"
  bottom: "conv1030"
  top: "conv1033"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1035"
  type: "Reshape"
  bottom: "conv1033"
  top: "reshape1035"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1036"
  type: "Permute"
  bottom: "reshape1035"
  top: "perm1036"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1037"
  type: "Softmax"
  bottom: "perm1036"
  top: "softmax1037"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1039"
  type: "Reshape"
  bottom: "softmax1037"
  top: "reshape1039"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1040"
  type: "Slice"
  bottom: "reshape1039"
  top: "slice1040-0"
  top: "slice1040-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1041"
  type: "Scale"
  bottom: "slice1027-0"
  bottom: "slice1040-0"
  top: "mul1041"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1042"
  type: "Scale"
  bottom: "slice1027-1"
  bottom: "slice1040-1"
  top: "mul1042"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1043"
  type: "Eltwise"
  bottom: "mul1041"
  bottom: "mul1042"
  top: "add1043"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1044"
  type: "Convolution"
  bottom: "add1043"
  top: "conv1044"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1045"
  type: "BatchNorm"
  bottom: "conv1044"
  top: "conv1044"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1045"
  type: "Scale"
  bottom: "conv1044"
  top: "conv1044"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1046"
  type: "Eltwise"
  bottom: "conv1044"
  bottom: "add1019"
  top: "add1046"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1047"
  type: "ReLU"
  bottom: "add1046"
  top: "add1046"
}
layer {
  name: "conv1048"
  type: "Convolution"
  bottom: "add1046"
  top: "conv1048"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1049"
  type: "BatchNorm"
  bottom: "conv1048"
  top: "conv1048"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1049"
  type: "Scale"
  bottom: "conv1048"
  top: "conv1048"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1050"
  type: "ReLU"
  bottom: "conv1048"
  top: "conv1048"
}
layer {
  name: "conv1051"
  type: "Convolution"
  bottom: "conv1048"
  top: "conv1051"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1052"
  type: "BatchNorm"
  bottom: "conv1051"
  top: "conv1051"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1052"
  type: "Scale"
  bottom: "conv1051"
  top: "conv1051"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1053"
  type: "ReLU"
  bottom: "conv1051"
  top: "conv1051"
}
layer {
  name: "slice1054"
  type: "Slice"
  bottom: "conv1051"
  top: "slice1054-0"
  top: "slice1054-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1055"
  type: "Eltwise"
  bottom: "slice1054-0"
  bottom: "slice1054-1"
  top: "add1055"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1056"
  type: "Pooling"
  bottom: "add1055"
  top: "pool1056"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1057"
  type: "Convolution"
  bottom: "pool1056"
  top: "conv1057"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1058"
  type: "BatchNorm"
  bottom: "conv1057"
  top: "conv1057"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1058"
  type: "Scale"
  bottom: "conv1057"
  top: "conv1057"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1059"
  type: "ReLU"
  bottom: "conv1057"
  top: "conv1057"
}
layer {
  name: "conv1060"
  type: "Convolution"
  bottom: "conv1057"
  top: "conv1060"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1062"
  type: "Reshape"
  bottom: "conv1060"
  top: "reshape1062"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1063"
  type: "Permute"
  bottom: "reshape1062"
  top: "perm1063"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1064"
  type: "Softmax"
  bottom: "perm1063"
  top: "softmax1064"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1066"
  type: "Reshape"
  bottom: "softmax1064"
  top: "reshape1066"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1067"
  type: "Slice"
  bottom: "reshape1066"
  top: "slice1067-0"
  top: "slice1067-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1068"
  type: "Scale"
  bottom: "slice1054-0"
  bottom: "slice1067-0"
  top: "mul1068"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1069"
  type: "Scale"
  bottom: "slice1054-1"
  bottom: "slice1067-1"
  top: "mul1069"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1070"
  type: "Eltwise"
  bottom: "mul1068"
  bottom: "mul1069"
  top: "add1070"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1071"
  type: "Convolution"
  bottom: "add1070"
  top: "conv1071"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1072"
  type: "BatchNorm"
  bottom: "conv1071"
  top: "conv1071"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1072"
  type: "Scale"
  bottom: "conv1071"
  top: "conv1071"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1073"
  type: "Eltwise"
  bottom: "conv1071"
  bottom: "add1046"
  top: "add1073"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1074"
  type: "ReLU"
  bottom: "add1073"
  top: "add1073"
}
layer {
  name: "conv1075"
  type: "Convolution"
  bottom: "add1073"
  top: "conv1075"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1076"
  type: "BatchNorm"
  bottom: "conv1075"
  top: "conv1075"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1076"
  type: "Scale"
  bottom: "conv1075"
  top: "conv1075"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1077"
  type: "ReLU"
  bottom: "conv1075"
  top: "conv1075"
}
layer {
  name: "conv1078"
  type: "Convolution"
  bottom: "conv1075"
  top: "conv1078"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1079"
  type: "BatchNorm"
  bottom: "conv1078"
  top: "conv1078"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1079"
  type: "Scale"
  bottom: "conv1078"
  top: "conv1078"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1080"
  type: "ReLU"
  bottom: "conv1078"
  top: "conv1078"
}
layer {
  name: "slice1081"
  type: "Slice"
  bottom: "conv1078"
  top: "slice1081-0"
  top: "slice1081-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1082"
  type: "Eltwise"
  bottom: "slice1081-0"
  bottom: "slice1081-1"
  top: "add1082"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1083"
  type: "Pooling"
  bottom: "add1082"
  top: "pool1083"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1084"
  type: "Convolution"
  bottom: "pool1083"
  top: "conv1084"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1085"
  type: "BatchNorm"
  bottom: "conv1084"
  top: "conv1084"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1085"
  type: "Scale"
  bottom: "conv1084"
  top: "conv1084"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1086"
  type: "ReLU"
  bottom: "conv1084"
  top: "conv1084"
}
layer {
  name: "conv1087"
  type: "Convolution"
  bottom: "conv1084"
  top: "conv1087"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1089"
  type: "Reshape"
  bottom: "conv1087"
  top: "reshape1089"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1090"
  type: "Permute"
  bottom: "reshape1089"
  top: "perm1090"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1091"
  type: "Softmax"
  bottom: "perm1090"
  top: "softmax1091"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1093"
  type: "Reshape"
  bottom: "softmax1091"
  top: "reshape1093"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1094"
  type: "Slice"
  bottom: "reshape1093"
  top: "slice1094-0"
  top: "slice1094-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1095"
  type: "Scale"
  bottom: "slice1081-0"
  bottom: "slice1094-0"
  top: "mul1095"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1096"
  type: "Scale"
  bottom: "slice1081-1"
  bottom: "slice1094-1"
  top: "mul1096"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1097"
  type: "Eltwise"
  bottom: "mul1095"
  bottom: "mul1096"
  top: "add1097"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1098"
  type: "Convolution"
  bottom: "add1097"
  top: "conv1098"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1099"
  type: "BatchNorm"
  bottom: "conv1098"
  top: "conv1098"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1099"
  type: "Scale"
  bottom: "conv1098"
  top: "conv1098"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1100"
  type: "Eltwise"
  bottom: "conv1098"
  bottom: "add1073"
  top: "add1100"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1101"
  type: "ReLU"
  bottom: "add1100"
  top: "add1100"
}
layer {
  name: "conv1102"
  type: "Convolution"
  bottom: "add1100"
  top: "conv1102"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1103"
  type: "BatchNorm"
  bottom: "conv1102"
  top: "conv1102"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1103"
  type: "Scale"
  bottom: "conv1102"
  top: "conv1102"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1104"
  type: "ReLU"
  bottom: "conv1102"
  top: "conv1102"
}
layer {
  name: "conv1105"
  type: "Convolution"
  bottom: "conv1102"
  top: "conv1105"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1106"
  type: "BatchNorm"
  bottom: "conv1105"
  top: "conv1105"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1106"
  type: "Scale"
  bottom: "conv1105"
  top: "conv1105"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1107"
  type: "ReLU"
  bottom: "conv1105"
  top: "conv1105"
}
layer {
  name: "slice1108"
  type: "Slice"
  bottom: "conv1105"
  top: "slice1108-0"
  top: "slice1108-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1109"
  type: "Eltwise"
  bottom: "slice1108-0"
  bottom: "slice1108-1"
  top: "add1109"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1110"
  type: "Pooling"
  bottom: "add1109"
  top: "pool1110"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1111"
  type: "Convolution"
  bottom: "pool1110"
  top: "conv1111"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1112"
  type: "BatchNorm"
  bottom: "conv1111"
  top: "conv1111"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1112"
  type: "Scale"
  bottom: "conv1111"
  top: "conv1111"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1113"
  type: "ReLU"
  bottom: "conv1111"
  top: "conv1111"
}
layer {
  name: "conv1114"
  type: "Convolution"
  bottom: "conv1111"
  top: "conv1114"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1116"
  type: "Reshape"
  bottom: "conv1114"
  top: "reshape1116"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1117"
  type: "Permute"
  bottom: "reshape1116"
  top: "perm1117"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1118"
  type: "Softmax"
  bottom: "perm1117"
  top: "softmax1118"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1120"
  type: "Reshape"
  bottom: "softmax1118"
  top: "reshape1120"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1121"
  type: "Slice"
  bottom: "reshape1120"
  top: "slice1121-0"
  top: "slice1121-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1122"
  type: "Scale"
  bottom: "slice1108-0"
  bottom: "slice1121-0"
  top: "mul1122"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1123"
  type: "Scale"
  bottom: "slice1108-1"
  bottom: "slice1121-1"
  top: "mul1123"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1124"
  type: "Eltwise"
  bottom: "mul1122"
  bottom: "mul1123"
  top: "add1124"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1125"
  type: "Convolution"
  bottom: "add1124"
  top: "conv1125"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1126"
  type: "BatchNorm"
  bottom: "conv1125"
  top: "conv1125"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1126"
  type: "Scale"
  bottom: "conv1125"
  top: "conv1125"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1127"
  type: "Eltwise"
  bottom: "conv1125"
  bottom: "add1100"
  top: "add1127"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1128"
  type: "ReLU"
  bottom: "add1127"
  top: "add1127"
}
layer {
  name: "conv1129"
  type: "Convolution"
  bottom: "add1127"
  top: "conv1129"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1130"
  type: "BatchNorm"
  bottom: "conv1129"
  top: "conv1129"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1130"
  type: "Scale"
  bottom: "conv1129"
  top: "conv1129"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1131"
  type: "ReLU"
  bottom: "conv1129"
  top: "conv1129"
}
layer {
  name: "conv1132"
  type: "Convolution"
  bottom: "conv1129"
  top: "conv1132"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1133"
  type: "BatchNorm"
  bottom: "conv1132"
  top: "conv1132"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1133"
  type: "Scale"
  bottom: "conv1132"
  top: "conv1132"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1134"
  type: "ReLU"
  bottom: "conv1132"
  top: "conv1132"
}
layer {
  name: "slice1135"
  type: "Slice"
  bottom: "conv1132"
  top: "slice1135-0"
  top: "slice1135-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1136"
  type: "Eltwise"
  bottom: "slice1135-0"
  bottom: "slice1135-1"
  top: "add1136"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1137"
  type: "Pooling"
  bottom: "add1136"
  top: "pool1137"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1138"
  type: "Convolution"
  bottom: "pool1137"
  top: "conv1138"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1139"
  type: "BatchNorm"
  bottom: "conv1138"
  top: "conv1138"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1139"
  type: "Scale"
  bottom: "conv1138"
  top: "conv1138"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1140"
  type: "ReLU"
  bottom: "conv1138"
  top: "conv1138"
}
layer {
  name: "conv1141"
  type: "Convolution"
  bottom: "conv1138"
  top: "conv1141"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1143"
  type: "Reshape"
  bottom: "conv1141"
  top: "reshape1143"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1144"
  type: "Permute"
  bottom: "reshape1143"
  top: "perm1144"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1145"
  type: "Softmax"
  bottom: "perm1144"
  top: "softmax1145"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1147"
  type: "Reshape"
  bottom: "softmax1145"
  top: "reshape1147"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1148"
  type: "Slice"
  bottom: "reshape1147"
  top: "slice1148-0"
  top: "slice1148-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1149"
  type: "Scale"
  bottom: "slice1135-0"
  bottom: "slice1148-0"
  top: "mul1149"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1150"
  type: "Scale"
  bottom: "slice1135-1"
  bottom: "slice1148-1"
  top: "mul1150"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1151"
  type: "Eltwise"
  bottom: "mul1149"
  bottom: "mul1150"
  top: "add1151"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1152"
  type: "Convolution"
  bottom: "add1151"
  top: "conv1152"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1153"
  type: "BatchNorm"
  bottom: "conv1152"
  top: "conv1152"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1153"
  type: "Scale"
  bottom: "conv1152"
  top: "conv1152"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1154"
  type: "Eltwise"
  bottom: "conv1152"
  bottom: "add1127"
  top: "add1154"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1155"
  type: "ReLU"
  bottom: "add1154"
  top: "add1154"
}
layer {
  name: "conv1156"
  type: "Convolution"
  bottom: "add1154"
  top: "conv1156"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1157"
  type: "BatchNorm"
  bottom: "conv1156"
  top: "conv1156"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1157"
  type: "Scale"
  bottom: "conv1156"
  top: "conv1156"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1158"
  type: "ReLU"
  bottom: "conv1156"
  top: "conv1156"
}
layer {
  name: "conv1159"
  type: "Convolution"
  bottom: "conv1156"
  top: "conv1159"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1160"
  type: "BatchNorm"
  bottom: "conv1159"
  top: "conv1159"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1160"
  type: "Scale"
  bottom: "conv1159"
  top: "conv1159"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1161"
  type: "ReLU"
  bottom: "conv1159"
  top: "conv1159"
}
layer {
  name: "slice1162"
  type: "Slice"
  bottom: "conv1159"
  top: "slice1162-0"
  top: "slice1162-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1163"
  type: "Eltwise"
  bottom: "slice1162-0"
  bottom: "slice1162-1"
  top: "add1163"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1164"
  type: "Pooling"
  bottom: "add1163"
  top: "pool1164"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1165"
  type: "Convolution"
  bottom: "pool1164"
  top: "conv1165"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1166"
  type: "BatchNorm"
  bottom: "conv1165"
  top: "conv1165"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1166"
  type: "Scale"
  bottom: "conv1165"
  top: "conv1165"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1167"
  type: "ReLU"
  bottom: "conv1165"
  top: "conv1165"
}
layer {
  name: "conv1168"
  type: "Convolution"
  bottom: "conv1165"
  top: "conv1168"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1170"
  type: "Reshape"
  bottom: "conv1168"
  top: "reshape1170"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1171"
  type: "Permute"
  bottom: "reshape1170"
  top: "perm1171"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1172"
  type: "Softmax"
  bottom: "perm1171"
  top: "softmax1172"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1174"
  type: "Reshape"
  bottom: "softmax1172"
  top: "reshape1174"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1175"
  type: "Slice"
  bottom: "reshape1174"
  top: "slice1175-0"
  top: "slice1175-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1176"
  type: "Scale"
  bottom: "slice1162-0"
  bottom: "slice1175-0"
  top: "mul1176"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1177"
  type: "Scale"
  bottom: "slice1162-1"
  bottom: "slice1175-1"
  top: "mul1177"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1178"
  type: "Eltwise"
  bottom: "mul1176"
  bottom: "mul1177"
  top: "add1178"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1179"
  type: "Convolution"
  bottom: "add1178"
  top: "conv1179"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1180"
  type: "BatchNorm"
  bottom: "conv1179"
  top: "conv1179"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1180"
  type: "Scale"
  bottom: "conv1179"
  top: "conv1179"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1181"
  type: "Eltwise"
  bottom: "conv1179"
  bottom: "add1154"
  top: "add1181"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1182"
  type: "ReLU"
  bottom: "add1181"
  top: "add1181"
}
layer {
  name: "conv1183"
  type: "Convolution"
  bottom: "add1181"
  top: "conv1183"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1184"
  type: "BatchNorm"
  bottom: "conv1183"
  top: "conv1183"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1184"
  type: "Scale"
  bottom: "conv1183"
  top: "conv1183"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1185"
  type: "ReLU"
  bottom: "conv1183"
  top: "conv1183"
}
layer {
  name: "conv1186"
  type: "Convolution"
  bottom: "conv1183"
  top: "conv1186"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1187"
  type: "BatchNorm"
  bottom: "conv1186"
  top: "conv1186"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1187"
  type: "Scale"
  bottom: "conv1186"
  top: "conv1186"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1188"
  type: "ReLU"
  bottom: "conv1186"
  top: "conv1186"
}
layer {
  name: "slice1189"
  type: "Slice"
  bottom: "conv1186"
  top: "slice1189-0"
  top: "slice1189-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1190"
  type: "Eltwise"
  bottom: "slice1189-0"
  bottom: "slice1189-1"
  top: "add1190"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1191"
  type: "Pooling"
  bottom: "add1190"
  top: "pool1191"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1192"
  type: "Convolution"
  bottom: "pool1191"
  top: "conv1192"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1193"
  type: "BatchNorm"
  bottom: "conv1192"
  top: "conv1192"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1193"
  type: "Scale"
  bottom: "conv1192"
  top: "conv1192"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1194"
  type: "ReLU"
  bottom: "conv1192"
  top: "conv1192"
}
layer {
  name: "conv1195"
  type: "Convolution"
  bottom: "conv1192"
  top: "conv1195"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1197"
  type: "Reshape"
  bottom: "conv1195"
  top: "reshape1197"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1198"
  type: "Permute"
  bottom: "reshape1197"
  top: "perm1198"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1199"
  type: "Softmax"
  bottom: "perm1198"
  top: "softmax1199"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1201"
  type: "Reshape"
  bottom: "softmax1199"
  top: "reshape1201"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1202"
  type: "Slice"
  bottom: "reshape1201"
  top: "slice1202-0"
  top: "slice1202-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1203"
  type: "Scale"
  bottom: "slice1189-0"
  bottom: "slice1202-0"
  top: "mul1203"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1204"
  type: "Scale"
  bottom: "slice1189-1"
  bottom: "slice1202-1"
  top: "mul1204"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1205"
  type: "Eltwise"
  bottom: "mul1203"
  bottom: "mul1204"
  top: "add1205"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1206"
  type: "Convolution"
  bottom: "add1205"
  top: "conv1206"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1207"
  type: "BatchNorm"
  bottom: "conv1206"
  top: "conv1206"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1207"
  type: "Scale"
  bottom: "conv1206"
  top: "conv1206"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1208"
  type: "Eltwise"
  bottom: "conv1206"
  bottom: "add1181"
  top: "add1208"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1209"
  type: "ReLU"
  bottom: "add1208"
  top: "add1208"
}
layer {
  name: "conv1210"
  type: "Convolution"
  bottom: "add1208"
  top: "conv1210"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1211"
  type: "BatchNorm"
  bottom: "conv1210"
  top: "conv1210"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1211"
  type: "Scale"
  bottom: "conv1210"
  top: "conv1210"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1212"
  type: "ReLU"
  bottom: "conv1210"
  top: "conv1210"
}
layer {
  name: "conv1213"
  type: "Convolution"
  bottom: "conv1210"
  top: "conv1213"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1214"
  type: "BatchNorm"
  bottom: "conv1213"
  top: "conv1213"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1214"
  type: "Scale"
  bottom: "conv1213"
  top: "conv1213"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1215"
  type: "ReLU"
  bottom: "conv1213"
  top: "conv1213"
}
layer {
  name: "slice1216"
  type: "Slice"
  bottom: "conv1213"
  top: "slice1216-0"
  top: "slice1216-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1217"
  type: "Eltwise"
  bottom: "slice1216-0"
  bottom: "slice1216-1"
  top: "add1217"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1218"
  type: "Pooling"
  bottom: "add1217"
  top: "pool1218"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1219"
  type: "Convolution"
  bottom: "pool1218"
  top: "conv1219"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1220"
  type: "BatchNorm"
  bottom: "conv1219"
  top: "conv1219"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1220"
  type: "Scale"
  bottom: "conv1219"
  top: "conv1219"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1221"
  type: "ReLU"
  bottom: "conv1219"
  top: "conv1219"
}
layer {
  name: "conv1222"
  type: "Convolution"
  bottom: "conv1219"
  top: "conv1222"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1224"
  type: "Reshape"
  bottom: "conv1222"
  top: "reshape1224"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1225"
  type: "Permute"
  bottom: "reshape1224"
  top: "perm1225"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1226"
  type: "Softmax"
  bottom: "perm1225"
  top: "softmax1226"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1228"
  type: "Reshape"
  bottom: "softmax1226"
  top: "reshape1228"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1229"
  type: "Slice"
  bottom: "reshape1228"
  top: "slice1229-0"
  top: "slice1229-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1230"
  type: "Scale"
  bottom: "slice1216-0"
  bottom: "slice1229-0"
  top: "mul1230"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1231"
  type: "Scale"
  bottom: "slice1216-1"
  bottom: "slice1229-1"
  top: "mul1231"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1232"
  type: "Eltwise"
  bottom: "mul1230"
  bottom: "mul1231"
  top: "add1232"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1233"
  type: "Convolution"
  bottom: "add1232"
  top: "conv1233"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1234"
  type: "BatchNorm"
  bottom: "conv1233"
  top: "conv1233"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1234"
  type: "Scale"
  bottom: "conv1233"
  top: "conv1233"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1235"
  type: "Eltwise"
  bottom: "conv1233"
  bottom: "add1208"
  top: "add1235"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1236"
  type: "ReLU"
  bottom: "add1235"
  top: "add1235"
}
layer {
  name: "conv1237"
  type: "Convolution"
  bottom: "add1235"
  top: "conv1237"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1238"
  type: "BatchNorm"
  bottom: "conv1237"
  top: "conv1237"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1238"
  type: "Scale"
  bottom: "conv1237"
  top: "conv1237"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1239"
  type: "ReLU"
  bottom: "conv1237"
  top: "conv1237"
}
layer {
  name: "conv1240"
  type: "Convolution"
  bottom: "conv1237"
  top: "conv1240"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1241"
  type: "BatchNorm"
  bottom: "conv1240"
  top: "conv1240"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1241"
  type: "Scale"
  bottom: "conv1240"
  top: "conv1240"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1242"
  type: "ReLU"
  bottom: "conv1240"
  top: "conv1240"
}
layer {
  name: "slice1243"
  type: "Slice"
  bottom: "conv1240"
  top: "slice1243-0"
  top: "slice1243-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1244"
  type: "Eltwise"
  bottom: "slice1243-0"
  bottom: "slice1243-1"
  top: "add1244"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1245"
  type: "Pooling"
  bottom: "add1244"
  top: "pool1245"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1246"
  type: "Convolution"
  bottom: "pool1245"
  top: "conv1246"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1247"
  type: "BatchNorm"
  bottom: "conv1246"
  top: "conv1246"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1247"
  type: "Scale"
  bottom: "conv1246"
  top: "conv1246"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1248"
  type: "ReLU"
  bottom: "conv1246"
  top: "conv1246"
}
layer {
  name: "conv1249"
  type: "Convolution"
  bottom: "conv1246"
  top: "conv1249"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1251"
  type: "Reshape"
  bottom: "conv1249"
  top: "reshape1251"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1252"
  type: "Permute"
  bottom: "reshape1251"
  top: "perm1252"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1253"
  type: "Softmax"
  bottom: "perm1252"
  top: "softmax1253"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1255"
  type: "Reshape"
  bottom: "softmax1253"
  top: "reshape1255"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1256"
  type: "Slice"
  bottom: "reshape1255"
  top: "slice1256-0"
  top: "slice1256-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1257"
  type: "Scale"
  bottom: "slice1243-0"
  bottom: "slice1256-0"
  top: "mul1257"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1258"
  type: "Scale"
  bottom: "slice1243-1"
  bottom: "slice1256-1"
  top: "mul1258"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1259"
  type: "Eltwise"
  bottom: "mul1257"
  bottom: "mul1258"
  top: "add1259"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1260"
  type: "Convolution"
  bottom: "add1259"
  top: "conv1260"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1261"
  type: "BatchNorm"
  bottom: "conv1260"
  top: "conv1260"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1261"
  type: "Scale"
  bottom: "conv1260"
  top: "conv1260"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1262"
  type: "Eltwise"
  bottom: "conv1260"
  bottom: "add1235"
  top: "add1262"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1263"
  type: "ReLU"
  bottom: "add1262"
  top: "add1262"
}
layer {
  name: "conv1264"
  type: "Convolution"
  bottom: "add1262"
  top: "conv1264"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1265"
  type: "BatchNorm"
  bottom: "conv1264"
  top: "conv1264"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1265"
  type: "Scale"
  bottom: "conv1264"
  top: "conv1264"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1266"
  type: "ReLU"
  bottom: "conv1264"
  top: "conv1264"
}
layer {
  name: "conv1267"
  type: "Convolution"
  bottom: "conv1264"
  top: "conv1267"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1268"
  type: "BatchNorm"
  bottom: "conv1267"
  top: "conv1267"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1268"
  type: "Scale"
  bottom: "conv1267"
  top: "conv1267"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1269"
  type: "ReLU"
  bottom: "conv1267"
  top: "conv1267"
}
layer {
  name: "slice1270"
  type: "Slice"
  bottom: "conv1267"
  top: "slice1270-0"
  top: "slice1270-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1271"
  type: "Eltwise"
  bottom: "slice1270-0"
  bottom: "slice1270-1"
  top: "add1271"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1272"
  type: "Pooling"
  bottom: "add1271"
  top: "pool1272"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1273"
  type: "Convolution"
  bottom: "pool1272"
  top: "conv1273"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1274"
  type: "BatchNorm"
  bottom: "conv1273"
  top: "conv1273"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1274"
  type: "Scale"
  bottom: "conv1273"
  top: "conv1273"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1275"
  type: "ReLU"
  bottom: "conv1273"
  top: "conv1273"
}
layer {
  name: "conv1276"
  type: "Convolution"
  bottom: "conv1273"
  top: "conv1276"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1278"
  type: "Reshape"
  bottom: "conv1276"
  top: "reshape1278"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1279"
  type: "Permute"
  bottom: "reshape1278"
  top: "perm1279"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1280"
  type: "Softmax"
  bottom: "perm1279"
  top: "softmax1280"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1282"
  type: "Reshape"
  bottom: "softmax1280"
  top: "reshape1282"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1283"
  type: "Slice"
  bottom: "reshape1282"
  top: "slice1283-0"
  top: "slice1283-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1284"
  type: "Scale"
  bottom: "slice1270-0"
  bottom: "slice1283-0"
  top: "mul1284"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1285"
  type: "Scale"
  bottom: "slice1270-1"
  bottom: "slice1283-1"
  top: "mul1285"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1286"
  type: "Eltwise"
  bottom: "mul1284"
  bottom: "mul1285"
  top: "add1286"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1287"
  type: "Convolution"
  bottom: "add1286"
  top: "conv1287"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1288"
  type: "BatchNorm"
  bottom: "conv1287"
  top: "conv1287"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1288"
  type: "Scale"
  bottom: "conv1287"
  top: "conv1287"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1289"
  type: "Eltwise"
  bottom: "conv1287"
  bottom: "add1262"
  top: "add1289"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1290"
  type: "ReLU"
  bottom: "add1289"
  top: "add1289"
}
layer {
  name: "conv1291"
  type: "Convolution"
  bottom: "add1289"
  top: "conv1291"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1292"
  type: "BatchNorm"
  bottom: "conv1291"
  top: "conv1291"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1292"
  type: "Scale"
  bottom: "conv1291"
  top: "conv1291"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1293"
  type: "ReLU"
  bottom: "conv1291"
  top: "conv1291"
}
layer {
  name: "conv1294"
  type: "Convolution"
  bottom: "conv1291"
  top: "conv1294"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1295"
  type: "BatchNorm"
  bottom: "conv1294"
  top: "conv1294"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1295"
  type: "Scale"
  bottom: "conv1294"
  top: "conv1294"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1296"
  type: "ReLU"
  bottom: "conv1294"
  top: "conv1294"
}
layer {
  name: "slice1297"
  type: "Slice"
  bottom: "conv1294"
  top: "slice1297-0"
  top: "slice1297-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1298"
  type: "Eltwise"
  bottom: "slice1297-0"
  bottom: "slice1297-1"
  top: "add1298"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1299"
  type: "Pooling"
  bottom: "add1298"
  top: "pool1299"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1300"
  type: "Convolution"
  bottom: "pool1299"
  top: "conv1300"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1301"
  type: "BatchNorm"
  bottom: "conv1300"
  top: "conv1300"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1301"
  type: "Scale"
  bottom: "conv1300"
  top: "conv1300"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1302"
  type: "ReLU"
  bottom: "conv1300"
  top: "conv1300"
}
layer {
  name: "conv1303"
  type: "Convolution"
  bottom: "conv1300"
  top: "conv1303"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1305"
  type: "Reshape"
  bottom: "conv1303"
  top: "reshape1305"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1306"
  type: "Permute"
  bottom: "reshape1305"
  top: "perm1306"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1307"
  type: "Softmax"
  bottom: "perm1306"
  top: "softmax1307"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1309"
  type: "Reshape"
  bottom: "softmax1307"
  top: "reshape1309"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1310"
  type: "Slice"
  bottom: "reshape1309"
  top: "slice1310-0"
  top: "slice1310-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1311"
  type: "Scale"
  bottom: "slice1297-0"
  bottom: "slice1310-0"
  top: "mul1311"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1312"
  type: "Scale"
  bottom: "slice1297-1"
  bottom: "slice1310-1"
  top: "mul1312"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1313"
  type: "Eltwise"
  bottom: "mul1311"
  bottom: "mul1312"
  top: "add1313"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1314"
  type: "Convolution"
  bottom: "add1313"
  top: "conv1314"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1315"
  type: "BatchNorm"
  bottom: "conv1314"
  top: "conv1314"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1315"
  type: "Scale"
  bottom: "conv1314"
  top: "conv1314"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1316"
  type: "Eltwise"
  bottom: "conv1314"
  bottom: "add1289"
  top: "add1316"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1317"
  type: "ReLU"
  bottom: "add1316"
  top: "add1316"
}
layer {
  name: "conv1318"
  type: "Convolution"
  bottom: "add1316"
  top: "conv1318"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1319"
  type: "BatchNorm"
  bottom: "conv1318"
  top: "conv1318"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1319"
  type: "Scale"
  bottom: "conv1318"
  top: "conv1318"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1320"
  type: "ReLU"
  bottom: "conv1318"
  top: "conv1318"
}
layer {
  name: "conv1321"
  type: "Convolution"
  bottom: "conv1318"
  top: "conv1321"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1322"
  type: "BatchNorm"
  bottom: "conv1321"
  top: "conv1321"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1322"
  type: "Scale"
  bottom: "conv1321"
  top: "conv1321"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1323"
  type: "ReLU"
  bottom: "conv1321"
  top: "conv1321"
}
layer {
  name: "slice1324"
  type: "Slice"
  bottom: "conv1321"
  top: "slice1324-0"
  top: "slice1324-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1325"
  type: "Eltwise"
  bottom: "slice1324-0"
  bottom: "slice1324-1"
  top: "add1325"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1326"
  type: "Pooling"
  bottom: "add1325"
  top: "pool1326"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1327"
  type: "Convolution"
  bottom: "pool1326"
  top: "conv1327"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1328"
  type: "BatchNorm"
  bottom: "conv1327"
  top: "conv1327"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1328"
  type: "Scale"
  bottom: "conv1327"
  top: "conv1327"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1329"
  type: "ReLU"
  bottom: "conv1327"
  top: "conv1327"
}
layer {
  name: "conv1330"
  type: "Convolution"
  bottom: "conv1327"
  top: "conv1330"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1332"
  type: "Reshape"
  bottom: "conv1330"
  top: "reshape1332"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1333"
  type: "Permute"
  bottom: "reshape1332"
  top: "perm1333"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1334"
  type: "Softmax"
  bottom: "perm1333"
  top: "softmax1334"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1336"
  type: "Reshape"
  bottom: "softmax1334"
  top: "reshape1336"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1337"
  type: "Slice"
  bottom: "reshape1336"
  top: "slice1337-0"
  top: "slice1337-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1338"
  type: "Scale"
  bottom: "slice1324-0"
  bottom: "slice1337-0"
  top: "mul1338"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1339"
  type: "Scale"
  bottom: "slice1324-1"
  bottom: "slice1337-1"
  top: "mul1339"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1340"
  type: "Eltwise"
  bottom: "mul1338"
  bottom: "mul1339"
  top: "add1340"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1341"
  type: "Convolution"
  bottom: "add1340"
  top: "conv1341"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1342"
  type: "BatchNorm"
  bottom: "conv1341"
  top: "conv1341"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1342"
  type: "Scale"
  bottom: "conv1341"
  top: "conv1341"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1343"
  type: "Eltwise"
  bottom: "conv1341"
  bottom: "add1316"
  top: "add1343"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1344"
  type: "ReLU"
  bottom: "add1343"
  top: "add1343"
}
layer {
  name: "conv1345"
  type: "Convolution"
  bottom: "add1343"
  top: "conv1345"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1346"
  type: "BatchNorm"
  bottom: "conv1345"
  top: "conv1345"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1346"
  type: "Scale"
  bottom: "conv1345"
  top: "conv1345"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1347"
  type: "ReLU"
  bottom: "conv1345"
  top: "conv1345"
}
layer {
  name: "conv1348"
  type: "Convolution"
  bottom: "conv1345"
  top: "conv1348"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1349"
  type: "BatchNorm"
  bottom: "conv1348"
  top: "conv1348"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1349"
  type: "Scale"
  bottom: "conv1348"
  top: "conv1348"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1350"
  type: "ReLU"
  bottom: "conv1348"
  top: "conv1348"
}
layer {
  name: "slice1351"
  type: "Slice"
  bottom: "conv1348"
  top: "slice1351-0"
  top: "slice1351-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1352"
  type: "Eltwise"
  bottom: "slice1351-0"
  bottom: "slice1351-1"
  top: "add1352"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1353"
  type: "Pooling"
  bottom: "add1352"
  top: "pool1353"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1354"
  type: "Convolution"
  bottom: "pool1353"
  top: "conv1354"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1355"
  type: "BatchNorm"
  bottom: "conv1354"
  top: "conv1354"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1355"
  type: "Scale"
  bottom: "conv1354"
  top: "conv1354"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1356"
  type: "ReLU"
  bottom: "conv1354"
  top: "conv1354"
}
layer {
  name: "conv1357"
  type: "Convolution"
  bottom: "conv1354"
  top: "conv1357"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1359"
  type: "Reshape"
  bottom: "conv1357"
  top: "reshape1359"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1360"
  type: "Permute"
  bottom: "reshape1359"
  top: "perm1360"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1361"
  type: "Softmax"
  bottom: "perm1360"
  top: "softmax1361"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1363"
  type: "Reshape"
  bottom: "softmax1361"
  top: "reshape1363"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1364"
  type: "Slice"
  bottom: "reshape1363"
  top: "slice1364-0"
  top: "slice1364-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1365"
  type: "Scale"
  bottom: "slice1351-0"
  bottom: "slice1364-0"
  top: "mul1365"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1366"
  type: "Scale"
  bottom: "slice1351-1"
  bottom: "slice1364-1"
  top: "mul1366"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1367"
  type: "Eltwise"
  bottom: "mul1365"
  bottom: "mul1366"
  top: "add1367"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1368"
  type: "Convolution"
  bottom: "add1367"
  top: "conv1368"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1369"
  type: "BatchNorm"
  bottom: "conv1368"
  top: "conv1368"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1369"
  type: "Scale"
  bottom: "conv1368"
  top: "conv1368"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1370"
  type: "Eltwise"
  bottom: "conv1368"
  bottom: "add1343"
  top: "add1370"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1371"
  type: "ReLU"
  bottom: "add1370"
  top: "add1370"
}
layer {
  name: "conv1372"
  type: "Convolution"
  bottom: "add1370"
  top: "conv1372"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1373"
  type: "BatchNorm"
  bottom: "conv1372"
  top: "conv1372"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1373"
  type: "Scale"
  bottom: "conv1372"
  top: "conv1372"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1374"
  type: "ReLU"
  bottom: "conv1372"
  top: "conv1372"
}
layer {
  name: "conv1375"
  type: "Convolution"
  bottom: "conv1372"
  top: "conv1375"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1376"
  type: "BatchNorm"
  bottom: "conv1375"
  top: "conv1375"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1376"
  type: "Scale"
  bottom: "conv1375"
  top: "conv1375"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1377"
  type: "ReLU"
  bottom: "conv1375"
  top: "conv1375"
}
layer {
  name: "slice1378"
  type: "Slice"
  bottom: "conv1375"
  top: "slice1378-0"
  top: "slice1378-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1379"
  type: "Eltwise"
  bottom: "slice1378-0"
  bottom: "slice1378-1"
  top: "add1379"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1380"
  type: "Pooling"
  bottom: "add1379"
  top: "pool1380"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1381"
  type: "Convolution"
  bottom: "pool1380"
  top: "conv1381"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1382"
  type: "BatchNorm"
  bottom: "conv1381"
  top: "conv1381"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1382"
  type: "Scale"
  bottom: "conv1381"
  top: "conv1381"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1383"
  type: "ReLU"
  bottom: "conv1381"
  top: "conv1381"
}
layer {
  name: "conv1384"
  type: "Convolution"
  bottom: "conv1381"
  top: "conv1384"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1386"
  type: "Reshape"
  bottom: "conv1384"
  top: "reshape1386"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1387"
  type: "Permute"
  bottom: "reshape1386"
  top: "perm1387"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1388"
  type: "Softmax"
  bottom: "perm1387"
  top: "softmax1388"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1390"
  type: "Reshape"
  bottom: "softmax1388"
  top: "reshape1390"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1391"
  type: "Slice"
  bottom: "reshape1390"
  top: "slice1391-0"
  top: "slice1391-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1392"
  type: "Scale"
  bottom: "slice1378-0"
  bottom: "slice1391-0"
  top: "mul1392"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1393"
  type: "Scale"
  bottom: "slice1378-1"
  bottom: "slice1391-1"
  top: "mul1393"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1394"
  type: "Eltwise"
  bottom: "mul1392"
  bottom: "mul1393"
  top: "add1394"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1395"
  type: "Convolution"
  bottom: "add1394"
  top: "conv1395"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1396"
  type: "BatchNorm"
  bottom: "conv1395"
  top: "conv1395"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1396"
  type: "Scale"
  bottom: "conv1395"
  top: "conv1395"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1397"
  type: "Eltwise"
  bottom: "conv1395"
  bottom: "add1370"
  top: "add1397"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1398"
  type: "ReLU"
  bottom: "add1397"
  top: "add1397"
}
layer {
  name: "conv1399"
  type: "Convolution"
  bottom: "add1397"
  top: "conv1399"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1400"
  type: "BatchNorm"
  bottom: "conv1399"
  top: "conv1399"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1400"
  type: "Scale"
  bottom: "conv1399"
  top: "conv1399"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1401"
  type: "ReLU"
  bottom: "conv1399"
  top: "conv1399"
}
layer {
  name: "conv1402"
  type: "Convolution"
  bottom: "conv1399"
  top: "conv1402"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1403"
  type: "BatchNorm"
  bottom: "conv1402"
  top: "conv1402"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1403"
  type: "Scale"
  bottom: "conv1402"
  top: "conv1402"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1404"
  type: "ReLU"
  bottom: "conv1402"
  top: "conv1402"
}
layer {
  name: "slice1405"
  type: "Slice"
  bottom: "conv1402"
  top: "slice1405-0"
  top: "slice1405-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1406"
  type: "Eltwise"
  bottom: "slice1405-0"
  bottom: "slice1405-1"
  top: "add1406"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1407"
  type: "Pooling"
  bottom: "add1406"
  top: "pool1407"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1408"
  type: "Convolution"
  bottom: "pool1407"
  top: "conv1408"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1409"
  type: "BatchNorm"
  bottom: "conv1408"
  top: "conv1408"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1409"
  type: "Scale"
  bottom: "conv1408"
  top: "conv1408"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1410"
  type: "ReLU"
  bottom: "conv1408"
  top: "conv1408"
}
layer {
  name: "conv1411"
  type: "Convolution"
  bottom: "conv1408"
  top: "conv1411"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1413"
  type: "Reshape"
  bottom: "conv1411"
  top: "reshape1413"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1414"
  type: "Permute"
  bottom: "reshape1413"
  top: "perm1414"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1415"
  type: "Softmax"
  bottom: "perm1414"
  top: "softmax1415"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1417"
  type: "Reshape"
  bottom: "softmax1415"
  top: "reshape1417"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1418"
  type: "Slice"
  bottom: "reshape1417"
  top: "slice1418-0"
  top: "slice1418-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1419"
  type: "Scale"
  bottom: "slice1405-0"
  bottom: "slice1418-0"
  top: "mul1419"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1420"
  type: "Scale"
  bottom: "slice1405-1"
  bottom: "slice1418-1"
  top: "mul1420"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1421"
  type: "Eltwise"
  bottom: "mul1419"
  bottom: "mul1420"
  top: "add1421"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1422"
  type: "Convolution"
  bottom: "add1421"
  top: "conv1422"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1423"
  type: "BatchNorm"
  bottom: "conv1422"
  top: "conv1422"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1423"
  type: "Scale"
  bottom: "conv1422"
  top: "conv1422"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1424"
  type: "Eltwise"
  bottom: "conv1422"
  bottom: "add1397"
  top: "add1424"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1425"
  type: "ReLU"
  bottom: "add1424"
  top: "add1424"
}
layer {
  name: "conv1426"
  type: "Convolution"
  bottom: "add1424"
  top: "conv1426"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1427"
  type: "BatchNorm"
  bottom: "conv1426"
  top: "conv1426"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1427"
  type: "Scale"
  bottom: "conv1426"
  top: "conv1426"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1428"
  type: "ReLU"
  bottom: "conv1426"
  top: "conv1426"
}
layer {
  name: "conv1429"
  type: "Convolution"
  bottom: "conv1426"
  top: "conv1429"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1430"
  type: "BatchNorm"
  bottom: "conv1429"
  top: "conv1429"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1430"
  type: "Scale"
  bottom: "conv1429"
  top: "conv1429"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1431"
  type: "ReLU"
  bottom: "conv1429"
  top: "conv1429"
}
layer {
  name: "slice1432"
  type: "Slice"
  bottom: "conv1429"
  top: "slice1432-0"
  top: "slice1432-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1433"
  type: "Eltwise"
  bottom: "slice1432-0"
  bottom: "slice1432-1"
  top: "add1433"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1434"
  type: "Pooling"
  bottom: "add1433"
  top: "pool1434"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1435"
  type: "Convolution"
  bottom: "pool1434"
  top: "conv1435"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1436"
  type: "BatchNorm"
  bottom: "conv1435"
  top: "conv1435"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1436"
  type: "Scale"
  bottom: "conv1435"
  top: "conv1435"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1437"
  type: "ReLU"
  bottom: "conv1435"
  top: "conv1435"
}
layer {
  name: "conv1438"
  type: "Convolution"
  bottom: "conv1435"
  top: "conv1438"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1440"
  type: "Reshape"
  bottom: "conv1438"
  top: "reshape1440"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1441"
  type: "Permute"
  bottom: "reshape1440"
  top: "perm1441"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1442"
  type: "Softmax"
  bottom: "perm1441"
  top: "softmax1442"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1444"
  type: "Reshape"
  bottom: "softmax1442"
  top: "reshape1444"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1445"
  type: "Slice"
  bottom: "reshape1444"
  top: "slice1445-0"
  top: "slice1445-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1446"
  type: "Scale"
  bottom: "slice1432-0"
  bottom: "slice1445-0"
  top: "mul1446"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1447"
  type: "Scale"
  bottom: "slice1432-1"
  bottom: "slice1445-1"
  top: "mul1447"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1448"
  type: "Eltwise"
  bottom: "mul1446"
  bottom: "mul1447"
  top: "add1448"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1449"
  type: "Convolution"
  bottom: "add1448"
  top: "conv1449"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1450"
  type: "BatchNorm"
  bottom: "conv1449"
  top: "conv1449"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1450"
  type: "Scale"
  bottom: "conv1449"
  top: "conv1449"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1451"
  type: "Eltwise"
  bottom: "conv1449"
  bottom: "add1424"
  top: "add1451"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1452"
  type: "ReLU"
  bottom: "add1451"
  top: "add1451"
}
layer {
  name: "conv1453"
  type: "Convolution"
  bottom: "add1451"
  top: "conv1453"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1454"
  type: "BatchNorm"
  bottom: "conv1453"
  top: "conv1453"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1454"
  type: "Scale"
  bottom: "conv1453"
  top: "conv1453"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1455"
  type: "ReLU"
  bottom: "conv1453"
  top: "conv1453"
}
layer {
  name: "conv1456"
  type: "Convolution"
  bottom: "conv1453"
  top: "conv1456"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1457"
  type: "BatchNorm"
  bottom: "conv1456"
  top: "conv1456"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1457"
  type: "Scale"
  bottom: "conv1456"
  top: "conv1456"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1458"
  type: "ReLU"
  bottom: "conv1456"
  top: "conv1456"
}
layer {
  name: "slice1459"
  type: "Slice"
  bottom: "conv1456"
  top: "slice1459-0"
  top: "slice1459-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1460"
  type: "Eltwise"
  bottom: "slice1459-0"
  bottom: "slice1459-1"
  top: "add1460"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1461"
  type: "Pooling"
  bottom: "add1460"
  top: "pool1461"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1462"
  type: "Convolution"
  bottom: "pool1461"
  top: "conv1462"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1463"
  type: "BatchNorm"
  bottom: "conv1462"
  top: "conv1462"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1463"
  type: "Scale"
  bottom: "conv1462"
  top: "conv1462"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1464"
  type: "ReLU"
  bottom: "conv1462"
  top: "conv1462"
}
layer {
  name: "conv1465"
  type: "Convolution"
  bottom: "conv1462"
  top: "conv1465"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1467"
  type: "Reshape"
  bottom: "conv1465"
  top: "reshape1467"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1468"
  type: "Permute"
  bottom: "reshape1467"
  top: "perm1468"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1469"
  type: "Softmax"
  bottom: "perm1468"
  top: "softmax1469"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1471"
  type: "Reshape"
  bottom: "softmax1469"
  top: "reshape1471"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1472"
  type: "Slice"
  bottom: "reshape1471"
  top: "slice1472-0"
  top: "slice1472-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1473"
  type: "Scale"
  bottom: "slice1459-0"
  bottom: "slice1472-0"
  top: "mul1473"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1474"
  type: "Scale"
  bottom: "slice1459-1"
  bottom: "slice1472-1"
  top: "mul1474"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1475"
  type: "Eltwise"
  bottom: "mul1473"
  bottom: "mul1474"
  top: "add1475"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1476"
  type: "Convolution"
  bottom: "add1475"
  top: "conv1476"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1477"
  type: "BatchNorm"
  bottom: "conv1476"
  top: "conv1476"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1477"
  type: "Scale"
  bottom: "conv1476"
  top: "conv1476"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1478"
  type: "Eltwise"
  bottom: "conv1476"
  bottom: "add1451"
  top: "add1478"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1479"
  type: "ReLU"
  bottom: "add1478"
  top: "add1478"
}
layer {
  name: "conv1480"
  type: "Convolution"
  bottom: "add1478"
  top: "conv1480"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1481"
  type: "BatchNorm"
  bottom: "conv1480"
  top: "conv1480"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1481"
  type: "Scale"
  bottom: "conv1480"
  top: "conv1480"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1482"
  type: "ReLU"
  bottom: "conv1480"
  top: "conv1480"
}
layer {
  name: "conv1483"
  type: "Convolution"
  bottom: "conv1480"
  top: "conv1483"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1484"
  type: "BatchNorm"
  bottom: "conv1483"
  top: "conv1483"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1484"
  type: "Scale"
  bottom: "conv1483"
  top: "conv1483"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1485"
  type: "ReLU"
  bottom: "conv1483"
  top: "conv1483"
}
layer {
  name: "slice1486"
  type: "Slice"
  bottom: "conv1483"
  top: "slice1486-0"
  top: "slice1486-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1487"
  type: "Eltwise"
  bottom: "slice1486-0"
  bottom: "slice1486-1"
  top: "add1487"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1488"
  type: "Pooling"
  bottom: "add1487"
  top: "pool1488"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1489"
  type: "Convolution"
  bottom: "pool1488"
  top: "conv1489"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1490"
  type: "BatchNorm"
  bottom: "conv1489"
  top: "conv1489"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1490"
  type: "Scale"
  bottom: "conv1489"
  top: "conv1489"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1491"
  type: "ReLU"
  bottom: "conv1489"
  top: "conv1489"
}
layer {
  name: "conv1492"
  type: "Convolution"
  bottom: "conv1489"
  top: "conv1492"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1494"
  type: "Reshape"
  bottom: "conv1492"
  top: "reshape1494"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1495"
  type: "Permute"
  bottom: "reshape1494"
  top: "perm1495"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1496"
  type: "Softmax"
  bottom: "perm1495"
  top: "softmax1496"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1498"
  type: "Reshape"
  bottom: "softmax1496"
  top: "reshape1498"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1499"
  type: "Slice"
  bottom: "reshape1498"
  top: "slice1499-0"
  top: "slice1499-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1500"
  type: "Scale"
  bottom: "slice1486-0"
  bottom: "slice1499-0"
  top: "mul1500"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1501"
  type: "Scale"
  bottom: "slice1486-1"
  bottom: "slice1499-1"
  top: "mul1501"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1502"
  type: "Eltwise"
  bottom: "mul1500"
  bottom: "mul1501"
  top: "add1502"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1503"
  type: "Convolution"
  bottom: "add1502"
  top: "conv1503"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1504"
  type: "BatchNorm"
  bottom: "conv1503"
  top: "conv1503"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1504"
  type: "Scale"
  bottom: "conv1503"
  top: "conv1503"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1505"
  type: "Eltwise"
  bottom: "conv1503"
  bottom: "add1478"
  top: "add1505"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1506"
  type: "ReLU"
  bottom: "add1505"
  top: "add1505"
}
layer {
  name: "conv1507"
  type: "Convolution"
  bottom: "add1505"
  top: "conv1507"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1508"
  type: "BatchNorm"
  bottom: "conv1507"
  top: "conv1507"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1508"
  type: "Scale"
  bottom: "conv1507"
  top: "conv1507"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1509"
  type: "ReLU"
  bottom: "conv1507"
  top: "conv1507"
}
layer {
  name: "conv1510"
  type: "Convolution"
  bottom: "conv1507"
  top: "conv1510"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1511"
  type: "BatchNorm"
  bottom: "conv1510"
  top: "conv1510"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1511"
  type: "Scale"
  bottom: "conv1510"
  top: "conv1510"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1512"
  type: "ReLU"
  bottom: "conv1510"
  top: "conv1510"
}
layer {
  name: "slice1513"
  type: "Slice"
  bottom: "conv1510"
  top: "slice1513-0"
  top: "slice1513-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1514"
  type: "Eltwise"
  bottom: "slice1513-0"
  bottom: "slice1513-1"
  top: "add1514"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1515"
  type: "Pooling"
  bottom: "add1514"
  top: "pool1515"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1516"
  type: "Convolution"
  bottom: "pool1515"
  top: "conv1516"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1517"
  type: "BatchNorm"
  bottom: "conv1516"
  top: "conv1516"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1517"
  type: "Scale"
  bottom: "conv1516"
  top: "conv1516"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1518"
  type: "ReLU"
  bottom: "conv1516"
  top: "conv1516"
}
layer {
  name: "conv1519"
  type: "Convolution"
  bottom: "conv1516"
  top: "conv1519"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1521"
  type: "Reshape"
  bottom: "conv1519"
  top: "reshape1521"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1522"
  type: "Permute"
  bottom: "reshape1521"
  top: "perm1522"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1523"
  type: "Softmax"
  bottom: "perm1522"
  top: "softmax1523"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1525"
  type: "Reshape"
  bottom: "softmax1523"
  top: "reshape1525"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1526"
  type: "Slice"
  bottom: "reshape1525"
  top: "slice1526-0"
  top: "slice1526-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1527"
  type: "Scale"
  bottom: "slice1513-0"
  bottom: "slice1526-0"
  top: "mul1527"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1528"
  type: "Scale"
  bottom: "slice1513-1"
  bottom: "slice1526-1"
  top: "mul1528"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1529"
  type: "Eltwise"
  bottom: "mul1527"
  bottom: "mul1528"
  top: "add1529"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1530"
  type: "Convolution"
  bottom: "add1529"
  top: "conv1530"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1531"
  type: "BatchNorm"
  bottom: "conv1530"
  top: "conv1530"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1531"
  type: "Scale"
  bottom: "conv1530"
  top: "conv1530"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1532"
  type: "Eltwise"
  bottom: "conv1530"
  bottom: "add1505"
  top: "add1532"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1533"
  type: "ReLU"
  bottom: "add1532"
  top: "add1532"
}
layer {
  name: "conv1534"
  type: "Convolution"
  bottom: "add1532"
  top: "conv1534"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1535"
  type: "BatchNorm"
  bottom: "conv1534"
  top: "conv1534"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1535"
  type: "Scale"
  bottom: "conv1534"
  top: "conv1534"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1536"
  type: "ReLU"
  bottom: "conv1534"
  top: "conv1534"
}
layer {
  name: "conv1537"
  type: "Convolution"
  bottom: "conv1534"
  top: "conv1537"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1538"
  type: "BatchNorm"
  bottom: "conv1537"
  top: "conv1537"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1538"
  type: "Scale"
  bottom: "conv1537"
  top: "conv1537"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1539"
  type: "ReLU"
  bottom: "conv1537"
  top: "conv1537"
}
layer {
  name: "slice1540"
  type: "Slice"
  bottom: "conv1537"
  top: "slice1540-0"
  top: "slice1540-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1541"
  type: "Eltwise"
  bottom: "slice1540-0"
  bottom: "slice1540-1"
  top: "add1541"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1542"
  type: "Pooling"
  bottom: "add1541"
  top: "pool1542"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1543"
  type: "Convolution"
  bottom: "pool1542"
  top: "conv1543"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1544"
  type: "BatchNorm"
  bottom: "conv1543"
  top: "conv1543"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1544"
  type: "Scale"
  bottom: "conv1543"
  top: "conv1543"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1545"
  type: "ReLU"
  bottom: "conv1543"
  top: "conv1543"
}
layer {
  name: "conv1546"
  type: "Convolution"
  bottom: "conv1543"
  top: "conv1546"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1548"
  type: "Reshape"
  bottom: "conv1546"
  top: "reshape1548"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1549"
  type: "Permute"
  bottom: "reshape1548"
  top: "perm1549"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1550"
  type: "Softmax"
  bottom: "perm1549"
  top: "softmax1550"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1552"
  type: "Reshape"
  bottom: "softmax1550"
  top: "reshape1552"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1553"
  type: "Slice"
  bottom: "reshape1552"
  top: "slice1553-0"
  top: "slice1553-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1554"
  type: "Scale"
  bottom: "slice1540-0"
  bottom: "slice1553-0"
  top: "mul1554"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1555"
  type: "Scale"
  bottom: "slice1540-1"
  bottom: "slice1553-1"
  top: "mul1555"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1556"
  type: "Eltwise"
  bottom: "mul1554"
  bottom: "mul1555"
  top: "add1556"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1557"
  type: "Convolution"
  bottom: "add1556"
  top: "conv1557"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1558"
  type: "BatchNorm"
  bottom: "conv1557"
  top: "conv1557"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1558"
  type: "Scale"
  bottom: "conv1557"
  top: "conv1557"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1559"
  type: "Eltwise"
  bottom: "conv1557"
  bottom: "add1532"
  top: "add1559"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1560"
  type: "ReLU"
  bottom: "add1559"
  top: "add1559"
}
layer {
  name: "conv1561"
  type: "Convolution"
  bottom: "add1559"
  top: "conv1561"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1562"
  type: "BatchNorm"
  bottom: "conv1561"
  top: "conv1561"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1562"
  type: "Scale"
  bottom: "conv1561"
  top: "conv1561"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1563"
  type: "ReLU"
  bottom: "conv1561"
  top: "conv1561"
}
layer {
  name: "conv1564"
  type: "Convolution"
  bottom: "conv1561"
  top: "conv1564"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1565"
  type: "BatchNorm"
  bottom: "conv1564"
  top: "conv1564"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1565"
  type: "Scale"
  bottom: "conv1564"
  top: "conv1564"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1566"
  type: "ReLU"
  bottom: "conv1564"
  top: "conv1564"
}
layer {
  name: "slice1567"
  type: "Slice"
  bottom: "conv1564"
  top: "slice1567-0"
  top: "slice1567-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1568"
  type: "Eltwise"
  bottom: "slice1567-0"
  bottom: "slice1567-1"
  top: "add1568"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1569"
  type: "Pooling"
  bottom: "add1568"
  top: "pool1569"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1570"
  type: "Convolution"
  bottom: "pool1569"
  top: "conv1570"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1571"
  type: "BatchNorm"
  bottom: "conv1570"
  top: "conv1570"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1571"
  type: "Scale"
  bottom: "conv1570"
  top: "conv1570"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1572"
  type: "ReLU"
  bottom: "conv1570"
  top: "conv1570"
}
layer {
  name: "conv1573"
  type: "Convolution"
  bottom: "conv1570"
  top: "conv1573"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1575"
  type: "Reshape"
  bottom: "conv1573"
  top: "reshape1575"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1576"
  type: "Permute"
  bottom: "reshape1575"
  top: "perm1576"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1577"
  type: "Softmax"
  bottom: "perm1576"
  top: "softmax1577"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1579"
  type: "Reshape"
  bottom: "softmax1577"
  top: "reshape1579"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1580"
  type: "Slice"
  bottom: "reshape1579"
  top: "slice1580-0"
  top: "slice1580-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1581"
  type: "Scale"
  bottom: "slice1567-0"
  bottom: "slice1580-0"
  top: "mul1581"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1582"
  type: "Scale"
  bottom: "slice1567-1"
  bottom: "slice1580-1"
  top: "mul1582"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1583"
  type: "Eltwise"
  bottom: "mul1581"
  bottom: "mul1582"
  top: "add1583"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1584"
  type: "Convolution"
  bottom: "add1583"
  top: "conv1584"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1585"
  type: "BatchNorm"
  bottom: "conv1584"
  top: "conv1584"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1585"
  type: "Scale"
  bottom: "conv1584"
  top: "conv1584"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1586"
  type: "Eltwise"
  bottom: "conv1584"
  bottom: "add1559"
  top: "add1586"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1587"
  type: "ReLU"
  bottom: "add1586"
  top: "add1586"
}
layer {
  name: "conv1588"
  type: "Convolution"
  bottom: "add1586"
  top: "conv1588"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1589"
  type: "BatchNorm"
  bottom: "conv1588"
  top: "conv1588"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1589"
  type: "Scale"
  bottom: "conv1588"
  top: "conv1588"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1590"
  type: "ReLU"
  bottom: "conv1588"
  top: "conv1588"
}
layer {
  name: "conv1591"
  type: "Convolution"
  bottom: "conv1588"
  top: "conv1591"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1592"
  type: "BatchNorm"
  bottom: "conv1591"
  top: "conv1591"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1592"
  type: "Scale"
  bottom: "conv1591"
  top: "conv1591"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1593"
  type: "ReLU"
  bottom: "conv1591"
  top: "conv1591"
}
layer {
  name: "slice1594"
  type: "Slice"
  bottom: "conv1591"
  top: "slice1594-0"
  top: "slice1594-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1595"
  type: "Eltwise"
  bottom: "slice1594-0"
  bottom: "slice1594-1"
  top: "add1595"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1596"
  type: "Pooling"
  bottom: "add1595"
  top: "pool1596"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1597"
  type: "Convolution"
  bottom: "pool1596"
  top: "conv1597"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1598"
  type: "BatchNorm"
  bottom: "conv1597"
  top: "conv1597"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1598"
  type: "Scale"
  bottom: "conv1597"
  top: "conv1597"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1599"
  type: "ReLU"
  bottom: "conv1597"
  top: "conv1597"
}
layer {
  name: "conv1600"
  type: "Convolution"
  bottom: "conv1597"
  top: "conv1600"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1602"
  type: "Reshape"
  bottom: "conv1600"
  top: "reshape1602"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1603"
  type: "Permute"
  bottom: "reshape1602"
  top: "perm1603"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1604"
  type: "Softmax"
  bottom: "perm1603"
  top: "softmax1604"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1606"
  type: "Reshape"
  bottom: "softmax1604"
  top: "reshape1606"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1607"
  type: "Slice"
  bottom: "reshape1606"
  top: "slice1607-0"
  top: "slice1607-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1608"
  type: "Scale"
  bottom: "slice1594-0"
  bottom: "slice1607-0"
  top: "mul1608"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1609"
  type: "Scale"
  bottom: "slice1594-1"
  bottom: "slice1607-1"
  top: "mul1609"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1610"
  type: "Eltwise"
  bottom: "mul1608"
  bottom: "mul1609"
  top: "add1610"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1611"
  type: "Convolution"
  bottom: "add1610"
  top: "conv1611"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1612"
  type: "BatchNorm"
  bottom: "conv1611"
  top: "conv1611"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1612"
  type: "Scale"
  bottom: "conv1611"
  top: "conv1611"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1613"
  type: "Eltwise"
  bottom: "conv1611"
  bottom: "add1586"
  top: "add1613"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1614"
  type: "ReLU"
  bottom: "add1613"
  top: "add1613"
}
layer {
  name: "conv1615"
  type: "Convolution"
  bottom: "add1613"
  top: "conv1615"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1616"
  type: "BatchNorm"
  bottom: "conv1615"
  top: "conv1615"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1616"
  type: "Scale"
  bottom: "conv1615"
  top: "conv1615"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1617"
  type: "ReLU"
  bottom: "conv1615"
  top: "conv1615"
}
layer {
  name: "conv1618"
  type: "Convolution"
  bottom: "conv1615"
  top: "conv1618"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1619"
  type: "BatchNorm"
  bottom: "conv1618"
  top: "conv1618"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1619"
  type: "Scale"
  bottom: "conv1618"
  top: "conv1618"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1620"
  type: "ReLU"
  bottom: "conv1618"
  top: "conv1618"
}
layer {
  name: "slice1621"
  type: "Slice"
  bottom: "conv1618"
  top: "slice1621-0"
  top: "slice1621-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1622"
  type: "Eltwise"
  bottom: "slice1621-0"
  bottom: "slice1621-1"
  top: "add1622"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1623"
  type: "Pooling"
  bottom: "add1622"
  top: "pool1623"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1624"
  type: "Convolution"
  bottom: "pool1623"
  top: "conv1624"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1625"
  type: "BatchNorm"
  bottom: "conv1624"
  top: "conv1624"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1625"
  type: "Scale"
  bottom: "conv1624"
  top: "conv1624"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1626"
  type: "ReLU"
  bottom: "conv1624"
  top: "conv1624"
}
layer {
  name: "conv1627"
  type: "Convolution"
  bottom: "conv1624"
  top: "conv1627"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1629"
  type: "Reshape"
  bottom: "conv1627"
  top: "reshape1629"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1630"
  type: "Permute"
  bottom: "reshape1629"
  top: "perm1630"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1631"
  type: "Softmax"
  bottom: "perm1630"
  top: "softmax1631"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1633"
  type: "Reshape"
  bottom: "softmax1631"
  top: "reshape1633"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1634"
  type: "Slice"
  bottom: "reshape1633"
  top: "slice1634-0"
  top: "slice1634-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1635"
  type: "Scale"
  bottom: "slice1621-0"
  bottom: "slice1634-0"
  top: "mul1635"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1636"
  type: "Scale"
  bottom: "slice1621-1"
  bottom: "slice1634-1"
  top: "mul1636"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1637"
  type: "Eltwise"
  bottom: "mul1635"
  bottom: "mul1636"
  top: "add1637"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1638"
  type: "Convolution"
  bottom: "add1637"
  top: "conv1638"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1639"
  type: "BatchNorm"
  bottom: "conv1638"
  top: "conv1638"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1639"
  type: "Scale"
  bottom: "conv1638"
  top: "conv1638"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1640"
  type: "Eltwise"
  bottom: "conv1638"
  bottom: "add1613"
  top: "add1640"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1641"
  type: "ReLU"
  bottom: "add1640"
  top: "add1640"
}
layer {
  name: "conv1642"
  type: "Convolution"
  bottom: "add1640"
  top: "conv1642"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1643"
  type: "BatchNorm"
  bottom: "conv1642"
  top: "conv1642"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1643"
  type: "Scale"
  bottom: "conv1642"
  top: "conv1642"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1644"
  type: "ReLU"
  bottom: "conv1642"
  top: "conv1642"
}
layer {
  name: "conv1645"
  type: "Convolution"
  bottom: "conv1642"
  top: "conv1645"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1646"
  type: "BatchNorm"
  bottom: "conv1645"
  top: "conv1645"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1646"
  type: "Scale"
  bottom: "conv1645"
  top: "conv1645"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1647"
  type: "ReLU"
  bottom: "conv1645"
  top: "conv1645"
}
layer {
  name: "slice1648"
  type: "Slice"
  bottom: "conv1645"
  top: "slice1648-0"
  top: "slice1648-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1649"
  type: "Eltwise"
  bottom: "slice1648-0"
  bottom: "slice1648-1"
  top: "add1649"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1650"
  type: "Pooling"
  bottom: "add1649"
  top: "pool1650"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1651"
  type: "Convolution"
  bottom: "pool1650"
  top: "conv1651"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1652"
  type: "BatchNorm"
  bottom: "conv1651"
  top: "conv1651"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1652"
  type: "Scale"
  bottom: "conv1651"
  top: "conv1651"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1653"
  type: "ReLU"
  bottom: "conv1651"
  top: "conv1651"
}
layer {
  name: "conv1654"
  type: "Convolution"
  bottom: "conv1651"
  top: "conv1654"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1656"
  type: "Reshape"
  bottom: "conv1654"
  top: "reshape1656"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1657"
  type: "Permute"
  bottom: "reshape1656"
  top: "perm1657"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1658"
  type: "Softmax"
  bottom: "perm1657"
  top: "softmax1658"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1660"
  type: "Reshape"
  bottom: "softmax1658"
  top: "reshape1660"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1661"
  type: "Slice"
  bottom: "reshape1660"
  top: "slice1661-0"
  top: "slice1661-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1662"
  type: "Scale"
  bottom: "slice1648-0"
  bottom: "slice1661-0"
  top: "mul1662"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1663"
  type: "Scale"
  bottom: "slice1648-1"
  bottom: "slice1661-1"
  top: "mul1663"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1664"
  type: "Eltwise"
  bottom: "mul1662"
  bottom: "mul1663"
  top: "add1664"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1665"
  type: "Convolution"
  bottom: "add1664"
  top: "conv1665"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1666"
  type: "BatchNorm"
  bottom: "conv1665"
  top: "conv1665"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1666"
  type: "Scale"
  bottom: "conv1665"
  top: "conv1665"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1667"
  type: "Eltwise"
  bottom: "conv1665"
  bottom: "add1640"
  top: "add1667"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1668"
  type: "ReLU"
  bottom: "add1667"
  top: "add1667"
}
layer {
  name: "conv1669"
  type: "Convolution"
  bottom: "add1667"
  top: "conv1669"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1670"
  type: "BatchNorm"
  bottom: "conv1669"
  top: "conv1669"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1670"
  type: "Scale"
  bottom: "conv1669"
  top: "conv1669"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1671"
  type: "ReLU"
  bottom: "conv1669"
  top: "conv1669"
}
layer {
  name: "conv1672"
  type: "Convolution"
  bottom: "conv1669"
  top: "conv1672"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1673"
  type: "BatchNorm"
  bottom: "conv1672"
  top: "conv1672"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1673"
  type: "Scale"
  bottom: "conv1672"
  top: "conv1672"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1674"
  type: "ReLU"
  bottom: "conv1672"
  top: "conv1672"
}
layer {
  name: "slice1675"
  type: "Slice"
  bottom: "conv1672"
  top: "slice1675-0"
  top: "slice1675-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1676"
  type: "Eltwise"
  bottom: "slice1675-0"
  bottom: "slice1675-1"
  top: "add1676"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1677"
  type: "Pooling"
  bottom: "add1676"
  top: "pool1677"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1678"
  type: "Convolution"
  bottom: "pool1677"
  top: "conv1678"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1679"
  type: "BatchNorm"
  bottom: "conv1678"
  top: "conv1678"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1679"
  type: "Scale"
  bottom: "conv1678"
  top: "conv1678"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1680"
  type: "ReLU"
  bottom: "conv1678"
  top: "conv1678"
}
layer {
  name: "conv1681"
  type: "Convolution"
  bottom: "conv1678"
  top: "conv1681"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1683"
  type: "Reshape"
  bottom: "conv1681"
  top: "reshape1683"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1684"
  type: "Permute"
  bottom: "reshape1683"
  top: "perm1684"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1685"
  type: "Softmax"
  bottom: "perm1684"
  top: "softmax1685"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1687"
  type: "Reshape"
  bottom: "softmax1685"
  top: "reshape1687"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1688"
  type: "Slice"
  bottom: "reshape1687"
  top: "slice1688-0"
  top: "slice1688-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1689"
  type: "Scale"
  bottom: "slice1675-0"
  bottom: "slice1688-0"
  top: "mul1689"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1690"
  type: "Scale"
  bottom: "slice1675-1"
  bottom: "slice1688-1"
  top: "mul1690"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1691"
  type: "Eltwise"
  bottom: "mul1689"
  bottom: "mul1690"
  top: "add1691"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1692"
  type: "Convolution"
  bottom: "add1691"
  top: "conv1692"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1693"
  type: "BatchNorm"
  bottom: "conv1692"
  top: "conv1692"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1693"
  type: "Scale"
  bottom: "conv1692"
  top: "conv1692"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1694"
  type: "Eltwise"
  bottom: "conv1692"
  bottom: "add1667"
  top: "add1694"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1695"
  type: "ReLU"
  bottom: "add1694"
  top: "add1694"
}
layer {
  name: "conv1696"
  type: "Convolution"
  bottom: "add1694"
  top: "conv1696"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1697"
  type: "BatchNorm"
  bottom: "conv1696"
  top: "conv1696"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1697"
  type: "Scale"
  bottom: "conv1696"
  top: "conv1696"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1698"
  type: "ReLU"
  bottom: "conv1696"
  top: "conv1696"
}
layer {
  name: "conv1699"
  type: "Convolution"
  bottom: "conv1696"
  top: "conv1699"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1700"
  type: "BatchNorm"
  bottom: "conv1699"
  top: "conv1699"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1700"
  type: "Scale"
  bottom: "conv1699"
  top: "conv1699"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1701"
  type: "ReLU"
  bottom: "conv1699"
  top: "conv1699"
}
layer {
  name: "slice1702"
  type: "Slice"
  bottom: "conv1699"
  top: "slice1702-0"
  top: "slice1702-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1703"
  type: "Eltwise"
  bottom: "slice1702-0"
  bottom: "slice1702-1"
  top: "add1703"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1704"
  type: "Pooling"
  bottom: "add1703"
  top: "pool1704"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1705"
  type: "Convolution"
  bottom: "pool1704"
  top: "conv1705"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1706"
  type: "BatchNorm"
  bottom: "conv1705"
  top: "conv1705"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1706"
  type: "Scale"
  bottom: "conv1705"
  top: "conv1705"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1707"
  type: "ReLU"
  bottom: "conv1705"
  top: "conv1705"
}
layer {
  name: "conv1708"
  type: "Convolution"
  bottom: "conv1705"
  top: "conv1708"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1710"
  type: "Reshape"
  bottom: "conv1708"
  top: "reshape1710"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1711"
  type: "Permute"
  bottom: "reshape1710"
  top: "perm1711"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1712"
  type: "Softmax"
  bottom: "perm1711"
  top: "softmax1712"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1714"
  type: "Reshape"
  bottom: "softmax1712"
  top: "reshape1714"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1715"
  type: "Slice"
  bottom: "reshape1714"
  top: "slice1715-0"
  top: "slice1715-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1716"
  type: "Scale"
  bottom: "slice1702-0"
  bottom: "slice1715-0"
  top: "mul1716"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1717"
  type: "Scale"
  bottom: "slice1702-1"
  bottom: "slice1715-1"
  top: "mul1717"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1718"
  type: "Eltwise"
  bottom: "mul1716"
  bottom: "mul1717"
  top: "add1718"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1719"
  type: "Convolution"
  bottom: "add1718"
  top: "conv1719"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1720"
  type: "BatchNorm"
  bottom: "conv1719"
  top: "conv1719"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1720"
  type: "Scale"
  bottom: "conv1719"
  top: "conv1719"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1721"
  type: "Eltwise"
  bottom: "conv1719"
  bottom: "add1694"
  top: "add1721"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1722"
  type: "ReLU"
  bottom: "add1721"
  top: "add1721"
}
layer {
  name: "conv1723"
  type: "Convolution"
  bottom: "add1721"
  top: "conv1723"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1724"
  type: "BatchNorm"
  bottom: "conv1723"
  top: "conv1723"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1724"
  type: "Scale"
  bottom: "conv1723"
  top: "conv1723"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1725"
  type: "ReLU"
  bottom: "conv1723"
  top: "conv1723"
}
layer {
  name: "conv1726"
  type: "Convolution"
  bottom: "conv1723"
  top: "conv1726"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1727"
  type: "BatchNorm"
  bottom: "conv1726"
  top: "conv1726"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1727"
  type: "Scale"
  bottom: "conv1726"
  top: "conv1726"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1728"
  type: "ReLU"
  bottom: "conv1726"
  top: "conv1726"
}
layer {
  name: "slice1729"
  type: "Slice"
  bottom: "conv1726"
  top: "slice1729-0"
  top: "slice1729-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1730"
  type: "Eltwise"
  bottom: "slice1729-0"
  bottom: "slice1729-1"
  top: "add1730"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1731"
  type: "Pooling"
  bottom: "add1730"
  top: "pool1731"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1732"
  type: "Convolution"
  bottom: "pool1731"
  top: "conv1732"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1733"
  type: "BatchNorm"
  bottom: "conv1732"
  top: "conv1732"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1733"
  type: "Scale"
  bottom: "conv1732"
  top: "conv1732"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1734"
  type: "ReLU"
  bottom: "conv1732"
  top: "conv1732"
}
layer {
  name: "conv1735"
  type: "Convolution"
  bottom: "conv1732"
  top: "conv1735"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1737"
  type: "Reshape"
  bottom: "conv1735"
  top: "reshape1737"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1738"
  type: "Permute"
  bottom: "reshape1737"
  top: "perm1738"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1739"
  type: "Softmax"
  bottom: "perm1738"
  top: "softmax1739"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1741"
  type: "Reshape"
  bottom: "softmax1739"
  top: "reshape1741"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1742"
  type: "Slice"
  bottom: "reshape1741"
  top: "slice1742-0"
  top: "slice1742-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1743"
  type: "Scale"
  bottom: "slice1729-0"
  bottom: "slice1742-0"
  top: "mul1743"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1744"
  type: "Scale"
  bottom: "slice1729-1"
  bottom: "slice1742-1"
  top: "mul1744"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1745"
  type: "Eltwise"
  bottom: "mul1743"
  bottom: "mul1744"
  top: "add1745"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1746"
  type: "Convolution"
  bottom: "add1745"
  top: "conv1746"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1747"
  type: "BatchNorm"
  bottom: "conv1746"
  top: "conv1746"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1747"
  type: "Scale"
  bottom: "conv1746"
  top: "conv1746"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1748"
  type: "Eltwise"
  bottom: "conv1746"
  bottom: "add1721"
  top: "add1748"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1749"
  type: "ReLU"
  bottom: "add1748"
  top: "add1748"
}
layer {
  name: "conv1750"
  type: "Convolution"
  bottom: "add1748"
  top: "conv1750"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1751"
  type: "BatchNorm"
  bottom: "conv1750"
  top: "conv1750"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1751"
  type: "Scale"
  bottom: "conv1750"
  top: "conv1750"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1752"
  type: "ReLU"
  bottom: "conv1750"
  top: "conv1750"
}
layer {
  name: "conv1753"
  type: "Convolution"
  bottom: "conv1750"
  top: "conv1753"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1754"
  type: "BatchNorm"
  bottom: "conv1753"
  top: "conv1753"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1754"
  type: "Scale"
  bottom: "conv1753"
  top: "conv1753"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1755"
  type: "ReLU"
  bottom: "conv1753"
  top: "conv1753"
}
layer {
  name: "slice1756"
  type: "Slice"
  bottom: "conv1753"
  top: "slice1756-0"
  top: "slice1756-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1757"
  type: "Eltwise"
  bottom: "slice1756-0"
  bottom: "slice1756-1"
  top: "add1757"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1758"
  type: "Pooling"
  bottom: "add1757"
  top: "pool1758"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1759"
  type: "Convolution"
  bottom: "pool1758"
  top: "conv1759"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1760"
  type: "BatchNorm"
  bottom: "conv1759"
  top: "conv1759"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1760"
  type: "Scale"
  bottom: "conv1759"
  top: "conv1759"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1761"
  type: "ReLU"
  bottom: "conv1759"
  top: "conv1759"
}
layer {
  name: "conv1762"
  type: "Convolution"
  bottom: "conv1759"
  top: "conv1762"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1764"
  type: "Reshape"
  bottom: "conv1762"
  top: "reshape1764"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1765"
  type: "Permute"
  bottom: "reshape1764"
  top: "perm1765"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1766"
  type: "Softmax"
  bottom: "perm1765"
  top: "softmax1766"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1768"
  type: "Reshape"
  bottom: "softmax1766"
  top: "reshape1768"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1769"
  type: "Slice"
  bottom: "reshape1768"
  top: "slice1769-0"
  top: "slice1769-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1770"
  type: "Scale"
  bottom: "slice1756-0"
  bottom: "slice1769-0"
  top: "mul1770"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1771"
  type: "Scale"
  bottom: "slice1756-1"
  bottom: "slice1769-1"
  top: "mul1771"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1772"
  type: "Eltwise"
  bottom: "mul1770"
  bottom: "mul1771"
  top: "add1772"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1773"
  type: "Convolution"
  bottom: "add1772"
  top: "conv1773"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1774"
  type: "BatchNorm"
  bottom: "conv1773"
  top: "conv1773"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1774"
  type: "Scale"
  bottom: "conv1773"
  top: "conv1773"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1775"
  type: "Eltwise"
  bottom: "conv1773"
  bottom: "add1748"
  top: "add1775"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1776"
  type: "ReLU"
  bottom: "add1775"
  top: "add1775"
}
layer {
  name: "conv1777"
  type: "Convolution"
  bottom: "add1775"
  top: "conv1777"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1778"
  type: "BatchNorm"
  bottom: "conv1777"
  top: "conv1777"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1778"
  type: "Scale"
  bottom: "conv1777"
  top: "conv1777"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1779"
  type: "ReLU"
  bottom: "conv1777"
  top: "conv1777"
}
layer {
  name: "conv1780"
  type: "Convolution"
  bottom: "conv1777"
  top: "conv1780"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1781"
  type: "BatchNorm"
  bottom: "conv1780"
  top: "conv1780"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1781"
  type: "Scale"
  bottom: "conv1780"
  top: "conv1780"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1782"
  type: "ReLU"
  bottom: "conv1780"
  top: "conv1780"
}
layer {
  name: "slice1783"
  type: "Slice"
  bottom: "conv1780"
  top: "slice1783-0"
  top: "slice1783-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1784"
  type: "Eltwise"
  bottom: "slice1783-0"
  bottom: "slice1783-1"
  top: "add1784"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1785"
  type: "Pooling"
  bottom: "add1784"
  top: "pool1785"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1786"
  type: "Convolution"
  bottom: "pool1785"
  top: "conv1786"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1787"
  type: "BatchNorm"
  bottom: "conv1786"
  top: "conv1786"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1787"
  type: "Scale"
  bottom: "conv1786"
  top: "conv1786"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1788"
  type: "ReLU"
  bottom: "conv1786"
  top: "conv1786"
}
layer {
  name: "conv1789"
  type: "Convolution"
  bottom: "conv1786"
  top: "conv1789"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1791"
  type: "Reshape"
  bottom: "conv1789"
  top: "reshape1791"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1792"
  type: "Permute"
  bottom: "reshape1791"
  top: "perm1792"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1793"
  type: "Softmax"
  bottom: "perm1792"
  top: "softmax1793"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1795"
  type: "Reshape"
  bottom: "softmax1793"
  top: "reshape1795"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1796"
  type: "Slice"
  bottom: "reshape1795"
  top: "slice1796-0"
  top: "slice1796-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1797"
  type: "Scale"
  bottom: "slice1783-0"
  bottom: "slice1796-0"
  top: "mul1797"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1798"
  type: "Scale"
  bottom: "slice1783-1"
  bottom: "slice1796-1"
  top: "mul1798"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1799"
  type: "Eltwise"
  bottom: "mul1797"
  bottom: "mul1798"
  top: "add1799"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1800"
  type: "Convolution"
  bottom: "add1799"
  top: "conv1800"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1801"
  type: "BatchNorm"
  bottom: "conv1800"
  top: "conv1800"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1801"
  type: "Scale"
  bottom: "conv1800"
  top: "conv1800"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1802"
  type: "Eltwise"
  bottom: "conv1800"
  bottom: "add1775"
  top: "add1802"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1803"
  type: "ReLU"
  bottom: "add1802"
  top: "add1802"
}
layer {
  name: "conv1804"
  type: "Convolution"
  bottom: "add1802"
  top: "conv1804"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1805"
  type: "BatchNorm"
  bottom: "conv1804"
  top: "conv1804"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1805"
  type: "Scale"
  bottom: "conv1804"
  top: "conv1804"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1806"
  type: "ReLU"
  bottom: "conv1804"
  top: "conv1804"
}
layer {
  name: "conv1807"
  type: "Convolution"
  bottom: "conv1804"
  top: "conv1807"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1808"
  type: "BatchNorm"
  bottom: "conv1807"
  top: "conv1807"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1808"
  type: "Scale"
  bottom: "conv1807"
  top: "conv1807"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1809"
  type: "ReLU"
  bottom: "conv1807"
  top: "conv1807"
}
layer {
  name: "slice1810"
  type: "Slice"
  bottom: "conv1807"
  top: "slice1810-0"
  top: "slice1810-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1811"
  type: "Eltwise"
  bottom: "slice1810-0"
  bottom: "slice1810-1"
  top: "add1811"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1812"
  type: "Pooling"
  bottom: "add1811"
  top: "pool1812"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1813"
  type: "Convolution"
  bottom: "pool1812"
  top: "conv1813"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1814"
  type: "BatchNorm"
  bottom: "conv1813"
  top: "conv1813"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1814"
  type: "Scale"
  bottom: "conv1813"
  top: "conv1813"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1815"
  type: "ReLU"
  bottom: "conv1813"
  top: "conv1813"
}
layer {
  name: "conv1816"
  type: "Convolution"
  bottom: "conv1813"
  top: "conv1816"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1818"
  type: "Reshape"
  bottom: "conv1816"
  top: "reshape1818"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1819"
  type: "Permute"
  bottom: "reshape1818"
  top: "perm1819"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1820"
  type: "Softmax"
  bottom: "perm1819"
  top: "softmax1820"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1822"
  type: "Reshape"
  bottom: "softmax1820"
  top: "reshape1822"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1823"
  type: "Slice"
  bottom: "reshape1822"
  top: "slice1823-0"
  top: "slice1823-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1824"
  type: "Scale"
  bottom: "slice1810-0"
  bottom: "slice1823-0"
  top: "mul1824"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1825"
  type: "Scale"
  bottom: "slice1810-1"
  bottom: "slice1823-1"
  top: "mul1825"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1826"
  type: "Eltwise"
  bottom: "mul1824"
  bottom: "mul1825"
  top: "add1826"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1827"
  type: "Convolution"
  bottom: "add1826"
  top: "conv1827"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1828"
  type: "BatchNorm"
  bottom: "conv1827"
  top: "conv1827"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1828"
  type: "Scale"
  bottom: "conv1827"
  top: "conv1827"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1829"
  type: "Eltwise"
  bottom: "conv1827"
  bottom: "add1802"
  top: "add1829"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1830"
  type: "ReLU"
  bottom: "add1829"
  top: "add1829"
}
layer {
  name: "conv1831"
  type: "Convolution"
  bottom: "add1829"
  top: "conv1831"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1832"
  type: "BatchNorm"
  bottom: "conv1831"
  top: "conv1831"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1832"
  type: "Scale"
  bottom: "conv1831"
  top: "conv1831"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1833"
  type: "ReLU"
  bottom: "conv1831"
  top: "conv1831"
}
layer {
  name: "conv1834"
  type: "Convolution"
  bottom: "conv1831"
  top: "conv1834"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1835"
  type: "BatchNorm"
  bottom: "conv1834"
  top: "conv1834"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1835"
  type: "Scale"
  bottom: "conv1834"
  top: "conv1834"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1836"
  type: "ReLU"
  bottom: "conv1834"
  top: "conv1834"
}
layer {
  name: "slice1837"
  type: "Slice"
  bottom: "conv1834"
  top: "slice1837-0"
  top: "slice1837-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1838"
  type: "Eltwise"
  bottom: "slice1837-0"
  bottom: "slice1837-1"
  top: "add1838"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1839"
  type: "Pooling"
  bottom: "add1838"
  top: "pool1839"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1840"
  type: "Convolution"
  bottom: "pool1839"
  top: "conv1840"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1841"
  type: "BatchNorm"
  bottom: "conv1840"
  top: "conv1840"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1841"
  type: "Scale"
  bottom: "conv1840"
  top: "conv1840"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1842"
  type: "ReLU"
  bottom: "conv1840"
  top: "conv1840"
}
layer {
  name: "conv1843"
  type: "Convolution"
  bottom: "conv1840"
  top: "conv1843"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1845"
  type: "Reshape"
  bottom: "conv1843"
  top: "reshape1845"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1846"
  type: "Permute"
  bottom: "reshape1845"
  top: "perm1846"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1847"
  type: "Softmax"
  bottom: "perm1846"
  top: "softmax1847"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1849"
  type: "Reshape"
  bottom: "softmax1847"
  top: "reshape1849"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1850"
  type: "Slice"
  bottom: "reshape1849"
  top: "slice1850-0"
  top: "slice1850-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1851"
  type: "Scale"
  bottom: "slice1837-0"
  bottom: "slice1850-0"
  top: "mul1851"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1852"
  type: "Scale"
  bottom: "slice1837-1"
  bottom: "slice1850-1"
  top: "mul1852"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1853"
  type: "Eltwise"
  bottom: "mul1851"
  bottom: "mul1852"
  top: "add1853"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1854"
  type: "Convolution"
  bottom: "add1853"
  top: "conv1854"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1855"
  type: "BatchNorm"
  bottom: "conv1854"
  top: "conv1854"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1855"
  type: "Scale"
  bottom: "conv1854"
  top: "conv1854"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1856"
  type: "Eltwise"
  bottom: "conv1854"
  bottom: "add1829"
  top: "add1856"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1857"
  type: "ReLU"
  bottom: "add1856"
  top: "add1856"
}
layer {
  name: "conv1858"
  type: "Convolution"
  bottom: "add1856"
  top: "conv1858"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1859"
  type: "BatchNorm"
  bottom: "conv1858"
  top: "conv1858"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1859"
  type: "Scale"
  bottom: "conv1858"
  top: "conv1858"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1860"
  type: "ReLU"
  bottom: "conv1858"
  top: "conv1858"
}
layer {
  name: "conv1861"
  type: "Convolution"
  bottom: "conv1858"
  top: "conv1861"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1862"
  type: "BatchNorm"
  bottom: "conv1861"
  top: "conv1861"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1862"
  type: "Scale"
  bottom: "conv1861"
  top: "conv1861"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1863"
  type: "ReLU"
  bottom: "conv1861"
  top: "conv1861"
}
layer {
  name: "slice1864"
  type: "Slice"
  bottom: "conv1861"
  top: "slice1864-0"
  top: "slice1864-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1865"
  type: "Eltwise"
  bottom: "slice1864-0"
  bottom: "slice1864-1"
  top: "add1865"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1866"
  type: "Pooling"
  bottom: "add1865"
  top: "pool1866"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1867"
  type: "Convolution"
  bottom: "pool1866"
  top: "conv1867"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1868"
  type: "BatchNorm"
  bottom: "conv1867"
  top: "conv1867"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1868"
  type: "Scale"
  bottom: "conv1867"
  top: "conv1867"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1869"
  type: "ReLU"
  bottom: "conv1867"
  top: "conv1867"
}
layer {
  name: "conv1870"
  type: "Convolution"
  bottom: "conv1867"
  top: "conv1870"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1872"
  type: "Reshape"
  bottom: "conv1870"
  top: "reshape1872"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1873"
  type: "Permute"
  bottom: "reshape1872"
  top: "perm1873"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1874"
  type: "Softmax"
  bottom: "perm1873"
  top: "softmax1874"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1876"
  type: "Reshape"
  bottom: "softmax1874"
  top: "reshape1876"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1877"
  type: "Slice"
  bottom: "reshape1876"
  top: "slice1877-0"
  top: "slice1877-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1878"
  type: "Scale"
  bottom: "slice1864-0"
  bottom: "slice1877-0"
  top: "mul1878"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1879"
  type: "Scale"
  bottom: "slice1864-1"
  bottom: "slice1877-1"
  top: "mul1879"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1880"
  type: "Eltwise"
  bottom: "mul1878"
  bottom: "mul1879"
  top: "add1880"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1881"
  type: "Convolution"
  bottom: "add1880"
  top: "conv1881"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1882"
  type: "BatchNorm"
  bottom: "conv1881"
  top: "conv1881"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1882"
  type: "Scale"
  bottom: "conv1881"
  top: "conv1881"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1883"
  type: "Eltwise"
  bottom: "conv1881"
  bottom: "add1856"
  top: "add1883"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1884"
  type: "ReLU"
  bottom: "add1883"
  top: "add1883"
}
layer {
  name: "conv1885"
  type: "Convolution"
  bottom: "add1883"
  top: "conv1885"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1886"
  type: "BatchNorm"
  bottom: "conv1885"
  top: "conv1885"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1886"
  type: "Scale"
  bottom: "conv1885"
  top: "conv1885"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1887"
  type: "ReLU"
  bottom: "conv1885"
  top: "conv1885"
}
layer {
  name: "conv1888"
  type: "Convolution"
  bottom: "conv1885"
  top: "conv1888"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1889"
  type: "BatchNorm"
  bottom: "conv1888"
  top: "conv1888"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1889"
  type: "Scale"
  bottom: "conv1888"
  top: "conv1888"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1890"
  type: "ReLU"
  bottom: "conv1888"
  top: "conv1888"
}
layer {
  name: "slice1891"
  type: "Slice"
  bottom: "conv1888"
  top: "slice1891-0"
  top: "slice1891-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1892"
  type: "Eltwise"
  bottom: "slice1891-0"
  bottom: "slice1891-1"
  top: "add1892"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1893"
  type: "Pooling"
  bottom: "add1892"
  top: "pool1893"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1894"
  type: "Convolution"
  bottom: "pool1893"
  top: "conv1894"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1895"
  type: "BatchNorm"
  bottom: "conv1894"
  top: "conv1894"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1895"
  type: "Scale"
  bottom: "conv1894"
  top: "conv1894"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1896"
  type: "ReLU"
  bottom: "conv1894"
  top: "conv1894"
}
layer {
  name: "conv1897"
  type: "Convolution"
  bottom: "conv1894"
  top: "conv1897"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1899"
  type: "Reshape"
  bottom: "conv1897"
  top: "reshape1899"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1900"
  type: "Permute"
  bottom: "reshape1899"
  top: "perm1900"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1901"
  type: "Softmax"
  bottom: "perm1900"
  top: "softmax1901"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1903"
  type: "Reshape"
  bottom: "softmax1901"
  top: "reshape1903"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1904"
  type: "Slice"
  bottom: "reshape1903"
  top: "slice1904-0"
  top: "slice1904-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1905"
  type: "Scale"
  bottom: "slice1891-0"
  bottom: "slice1904-0"
  top: "mul1905"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1906"
  type: "Scale"
  bottom: "slice1891-1"
  bottom: "slice1904-1"
  top: "mul1906"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1907"
  type: "Eltwise"
  bottom: "mul1905"
  bottom: "mul1906"
  top: "add1907"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1908"
  type: "Convolution"
  bottom: "add1907"
  top: "conv1908"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1909"
  type: "BatchNorm"
  bottom: "conv1908"
  top: "conv1908"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1909"
  type: "Scale"
  bottom: "conv1908"
  top: "conv1908"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1910"
  type: "Eltwise"
  bottom: "conv1908"
  bottom: "add1883"
  top: "add1910"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1911"
  type: "ReLU"
  bottom: "add1910"
  top: "add1910"
}
layer {
  name: "conv1912"
  type: "Convolution"
  bottom: "add1910"
  top: "conv1912"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1913"
  type: "BatchNorm"
  bottom: "conv1912"
  top: "conv1912"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1913"
  type: "Scale"
  bottom: "conv1912"
  top: "conv1912"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1914"
  type: "ReLU"
  bottom: "conv1912"
  top: "conv1912"
}
layer {
  name: "conv1915"
  type: "Convolution"
  bottom: "conv1912"
  top: "conv1915"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1916"
  type: "BatchNorm"
  bottom: "conv1915"
  top: "conv1915"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1916"
  type: "Scale"
  bottom: "conv1915"
  top: "conv1915"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1917"
  type: "ReLU"
  bottom: "conv1915"
  top: "conv1915"
}
layer {
  name: "slice1918"
  type: "Slice"
  bottom: "conv1915"
  top: "slice1918-0"
  top: "slice1918-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1919"
  type: "Eltwise"
  bottom: "slice1918-0"
  bottom: "slice1918-1"
  top: "add1919"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1920"
  type: "Pooling"
  bottom: "add1919"
  top: "pool1920"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1921"
  type: "Convolution"
  bottom: "pool1920"
  top: "conv1921"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1922"
  type: "BatchNorm"
  bottom: "conv1921"
  top: "conv1921"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1922"
  type: "Scale"
  bottom: "conv1921"
  top: "conv1921"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1923"
  type: "ReLU"
  bottom: "conv1921"
  top: "conv1921"
}
layer {
  name: "conv1924"
  type: "Convolution"
  bottom: "conv1921"
  top: "conv1924"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1926"
  type: "Reshape"
  bottom: "conv1924"
  top: "reshape1926"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1927"
  type: "Permute"
  bottom: "reshape1926"
  top: "perm1927"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1928"
  type: "Softmax"
  bottom: "perm1927"
  top: "softmax1928"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1930"
  type: "Reshape"
  bottom: "softmax1928"
  top: "reshape1930"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1931"
  type: "Slice"
  bottom: "reshape1930"
  top: "slice1931-0"
  top: "slice1931-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1932"
  type: "Scale"
  bottom: "slice1918-0"
  bottom: "slice1931-0"
  top: "mul1932"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1933"
  type: "Scale"
  bottom: "slice1918-1"
  bottom: "slice1931-1"
  top: "mul1933"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1934"
  type: "Eltwise"
  bottom: "mul1932"
  bottom: "mul1933"
  top: "add1934"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1935"
  type: "Convolution"
  bottom: "add1934"
  top: "conv1935"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1936"
  type: "BatchNorm"
  bottom: "conv1935"
  top: "conv1935"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1936"
  type: "Scale"
  bottom: "conv1935"
  top: "conv1935"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1937"
  type: "Eltwise"
  bottom: "conv1935"
  bottom: "add1910"
  top: "add1937"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1938"
  type: "ReLU"
  bottom: "add1937"
  top: "add1937"
}
layer {
  name: "conv1939"
  type: "Convolution"
  bottom: "add1937"
  top: "conv1939"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1940"
  type: "BatchNorm"
  bottom: "conv1939"
  top: "conv1939"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1940"
  type: "Scale"
  bottom: "conv1939"
  top: "conv1939"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1941"
  type: "ReLU"
  bottom: "conv1939"
  top: "conv1939"
}
layer {
  name: "conv1942"
  type: "Convolution"
  bottom: "conv1939"
  top: "conv1942"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1943"
  type: "BatchNorm"
  bottom: "conv1942"
  top: "conv1942"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1943"
  type: "Scale"
  bottom: "conv1942"
  top: "conv1942"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1944"
  type: "ReLU"
  bottom: "conv1942"
  top: "conv1942"
}
layer {
  name: "slice1945"
  type: "Slice"
  bottom: "conv1942"
  top: "slice1945-0"
  top: "slice1945-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1946"
  type: "Eltwise"
  bottom: "slice1945-0"
  bottom: "slice1945-1"
  top: "add1946"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1947"
  type: "Pooling"
  bottom: "add1946"
  top: "pool1947"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1948"
  type: "Convolution"
  bottom: "pool1947"
  top: "conv1948"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1949"
  type: "BatchNorm"
  bottom: "conv1948"
  top: "conv1948"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1949"
  type: "Scale"
  bottom: "conv1948"
  top: "conv1948"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1950"
  type: "ReLU"
  bottom: "conv1948"
  top: "conv1948"
}
layer {
  name: "conv1951"
  type: "Convolution"
  bottom: "conv1948"
  top: "conv1951"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1953"
  type: "Reshape"
  bottom: "conv1951"
  top: "reshape1953"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1954"
  type: "Permute"
  bottom: "reshape1953"
  top: "perm1954"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1955"
  type: "Softmax"
  bottom: "perm1954"
  top: "softmax1955"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1957"
  type: "Reshape"
  bottom: "softmax1955"
  top: "reshape1957"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1958"
  type: "Slice"
  bottom: "reshape1957"
  top: "slice1958-0"
  top: "slice1958-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1959"
  type: "Scale"
  bottom: "slice1945-0"
  bottom: "slice1958-0"
  top: "mul1959"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1960"
  type: "Scale"
  bottom: "slice1945-1"
  bottom: "slice1958-1"
  top: "mul1960"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1961"
  type: "Eltwise"
  bottom: "mul1959"
  bottom: "mul1960"
  top: "add1961"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1962"
  type: "Convolution"
  bottom: "add1961"
  top: "conv1962"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1963"
  type: "BatchNorm"
  bottom: "conv1962"
  top: "conv1962"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1963"
  type: "Scale"
  bottom: "conv1962"
  top: "conv1962"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1964"
  type: "Eltwise"
  bottom: "conv1962"
  bottom: "add1937"
  top: "add1964"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1965"
  type: "ReLU"
  bottom: "add1964"
  top: "add1964"
}
layer {
  name: "conv1966"
  type: "Convolution"
  bottom: "add1964"
  top: "conv1966"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1967"
  type: "BatchNorm"
  bottom: "conv1966"
  top: "conv1966"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1967"
  type: "Scale"
  bottom: "conv1966"
  top: "conv1966"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1968"
  type: "ReLU"
  bottom: "conv1966"
  top: "conv1966"
}
layer {
  name: "conv1969"
  type: "Convolution"
  bottom: "conv1966"
  top: "conv1969"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1970"
  type: "BatchNorm"
  bottom: "conv1969"
  top: "conv1969"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1970"
  type: "Scale"
  bottom: "conv1969"
  top: "conv1969"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1971"
  type: "ReLU"
  bottom: "conv1969"
  top: "conv1969"
}
layer {
  name: "slice1972"
  type: "Slice"
  bottom: "conv1969"
  top: "slice1972-0"
  top: "slice1972-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add1973"
  type: "Eltwise"
  bottom: "slice1972-0"
  bottom: "slice1972-1"
  top: "add1973"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool1974"
  type: "Pooling"
  bottom: "add1973"
  top: "pool1974"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv1975"
  type: "Convolution"
  bottom: "pool1974"
  top: "conv1975"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1976"
  type: "BatchNorm"
  bottom: "conv1975"
  top: "conv1975"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1976"
  type: "Scale"
  bottom: "conv1975"
  top: "conv1975"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1977"
  type: "ReLU"
  bottom: "conv1975"
  top: "conv1975"
}
layer {
  name: "conv1978"
  type: "Convolution"
  bottom: "conv1975"
  top: "conv1978"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape1980"
  type: "Reshape"
  bottom: "conv1978"
  top: "reshape1980"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm1981"
  type: "Permute"
  bottom: "reshape1980"
  top: "perm1981"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax1982"
  type: "Softmax"
  bottom: "perm1981"
  top: "softmax1982"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape1984"
  type: "Reshape"
  bottom: "softmax1982"
  top: "reshape1984"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice1985"
  type: "Slice"
  bottom: "reshape1984"
  top: "slice1985-0"
  top: "slice1985-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul1986"
  type: "Scale"
  bottom: "slice1972-0"
  bottom: "slice1985-0"
  top: "mul1986"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul1987"
  type: "Scale"
  bottom: "slice1972-1"
  bottom: "slice1985-1"
  top: "mul1987"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add1988"
  type: "Eltwise"
  bottom: "mul1986"
  bottom: "mul1987"
  top: "add1988"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv1989"
  type: "Convolution"
  bottom: "add1988"
  top: "conv1989"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1990"
  type: "BatchNorm"
  bottom: "conv1989"
  top: "conv1989"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1990"
  type: "Scale"
  bottom: "conv1989"
  top: "conv1989"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1991"
  type: "Eltwise"
  bottom: "conv1989"
  bottom: "add1964"
  top: "add1991"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu1992"
  type: "ReLU"
  bottom: "add1991"
  top: "add1991"
}
layer {
  name: "conv1993"
  type: "Convolution"
  bottom: "add1991"
  top: "conv1993"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1994"
  type: "BatchNorm"
  bottom: "conv1993"
  top: "conv1993"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1994"
  type: "Scale"
  bottom: "conv1993"
  top: "conv1993"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1995"
  type: "ReLU"
  bottom: "conv1993"
  top: "conv1993"
}
layer {
  name: "conv1996"
  type: "Convolution"
  bottom: "conv1993"
  top: "conv1996"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn1997"
  type: "BatchNorm"
  bottom: "conv1996"
  top: "conv1996"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale1997"
  type: "Scale"
  bottom: "conv1996"
  top: "conv1996"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1998"
  type: "ReLU"
  bottom: "conv1996"
  top: "conv1996"
}
layer {
  name: "slice1999"
  type: "Slice"
  bottom: "conv1996"
  top: "slice1999-0"
  top: "slice1999-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add2000"
  type: "Eltwise"
  bottom: "slice1999-0"
  bottom: "slice1999-1"
  top: "add2000"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2001"
  type: "Pooling"
  bottom: "add2000"
  top: "pool2001"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2002"
  type: "Convolution"
  bottom: "pool2001"
  top: "conv2002"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2003"
  type: "BatchNorm"
  bottom: "conv2002"
  top: "conv2002"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2003"
  type: "Scale"
  bottom: "conv2002"
  top: "conv2002"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2004"
  type: "ReLU"
  bottom: "conv2002"
  top: "conv2002"
}
layer {
  name: "conv2005"
  type: "Convolution"
  bottom: "conv2002"
  top: "conv2005"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2007"
  type: "Reshape"
  bottom: "conv2005"
  top: "reshape2007"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2008"
  type: "Permute"
  bottom: "reshape2007"
  top: "perm2008"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2009"
  type: "Softmax"
  bottom: "perm2008"
  top: "softmax2009"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2011"
  type: "Reshape"
  bottom: "softmax2009"
  top: "reshape2011"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2012"
  type: "Slice"
  bottom: "reshape2011"
  top: "slice2012-0"
  top: "slice2012-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul2013"
  type: "Scale"
  bottom: "slice1999-0"
  bottom: "slice2012-0"
  top: "mul2013"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2014"
  type: "Scale"
  bottom: "slice1999-1"
  bottom: "slice2012-1"
  top: "mul2014"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2015"
  type: "Eltwise"
  bottom: "mul2013"
  bottom: "mul2014"
  top: "add2015"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2016"
  type: "Convolution"
  bottom: "add2015"
  top: "conv2016"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2017"
  type: "BatchNorm"
  bottom: "conv2016"
  top: "conv2016"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2017"
  type: "Scale"
  bottom: "conv2016"
  top: "conv2016"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2018"
  type: "Eltwise"
  bottom: "conv2016"
  bottom: "add1991"
  top: "add2018"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2019"
  type: "ReLU"
  bottom: "add2018"
  top: "add2018"
}
layer {
  name: "conv2020"
  type: "Convolution"
  bottom: "add2018"
  top: "conv2020"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2021"
  type: "BatchNorm"
  bottom: "conv2020"
  top: "conv2020"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2021"
  type: "Scale"
  bottom: "conv2020"
  top: "conv2020"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2022"
  type: "ReLU"
  bottom: "conv2020"
  top: "conv2020"
}
layer {
  name: "conv2023"
  type: "Convolution"
  bottom: "conv2020"
  top: "conv2023"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2024"
  type: "BatchNorm"
  bottom: "conv2023"
  top: "conv2023"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2024"
  type: "Scale"
  bottom: "conv2023"
  top: "conv2023"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2025"
  type: "ReLU"
  bottom: "conv2023"
  top: "conv2023"
}
layer {
  name: "slice2026"
  type: "Slice"
  bottom: "conv2023"
  top: "slice2026-0"
  top: "slice2026-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add2027"
  type: "Eltwise"
  bottom: "slice2026-0"
  bottom: "slice2026-1"
  top: "add2027"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2028"
  type: "Pooling"
  bottom: "add2027"
  top: "pool2028"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2029"
  type: "Convolution"
  bottom: "pool2028"
  top: "conv2029"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2030"
  type: "BatchNorm"
  bottom: "conv2029"
  top: "conv2029"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2030"
  type: "Scale"
  bottom: "conv2029"
  top: "conv2029"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2031"
  type: "ReLU"
  bottom: "conv2029"
  top: "conv2029"
}
layer {
  name: "conv2032"
  type: "Convolution"
  bottom: "conv2029"
  top: "conv2032"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2034"
  type: "Reshape"
  bottom: "conv2032"
  top: "reshape2034"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2035"
  type: "Permute"
  bottom: "reshape2034"
  top: "perm2035"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2036"
  type: "Softmax"
  bottom: "perm2035"
  top: "softmax2036"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2038"
  type: "Reshape"
  bottom: "softmax2036"
  top: "reshape2038"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2039"
  type: "Slice"
  bottom: "reshape2038"
  top: "slice2039-0"
  top: "slice2039-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul2040"
  type: "Scale"
  bottom: "slice2026-0"
  bottom: "slice2039-0"
  top: "mul2040"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2041"
  type: "Scale"
  bottom: "slice2026-1"
  bottom: "slice2039-1"
  top: "mul2041"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2042"
  type: "Eltwise"
  bottom: "mul2040"
  bottom: "mul2041"
  top: "add2042"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2043"
  type: "Convolution"
  bottom: "add2042"
  top: "conv2043"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2044"
  type: "BatchNorm"
  bottom: "conv2043"
  top: "conv2043"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2044"
  type: "Scale"
  bottom: "conv2043"
  top: "conv2043"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2045"
  type: "Eltwise"
  bottom: "conv2043"
  bottom: "add2018"
  top: "add2045"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2046"
  type: "ReLU"
  bottom: "add2045"
  top: "add2045"
}
layer {
  name: "conv2047"
  type: "Convolution"
  bottom: "add2045"
  top: "conv2047"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2048"
  type: "BatchNorm"
  bottom: "conv2047"
  top: "conv2047"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2048"
  type: "Scale"
  bottom: "conv2047"
  top: "conv2047"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2049"
  type: "ReLU"
  bottom: "conv2047"
  top: "conv2047"
}
layer {
  name: "conv2050"
  type: "Convolution"
  bottom: "conv2047"
  top: "conv2050"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2051"
  type: "BatchNorm"
  bottom: "conv2050"
  top: "conv2050"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2051"
  type: "Scale"
  bottom: "conv2050"
  top: "conv2050"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2052"
  type: "ReLU"
  bottom: "conv2050"
  top: "conv2050"
}
layer {
  name: "slice2053"
  type: "Slice"
  bottom: "conv2050"
  top: "slice2053-0"
  top: "slice2053-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add2054"
  type: "Eltwise"
  bottom: "slice2053-0"
  bottom: "slice2053-1"
  top: "add2054"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2055"
  type: "Pooling"
  bottom: "add2054"
  top: "pool2055"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2056"
  type: "Convolution"
  bottom: "pool2055"
  top: "conv2056"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2057"
  type: "BatchNorm"
  bottom: "conv2056"
  top: "conv2056"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2057"
  type: "Scale"
  bottom: "conv2056"
  top: "conv2056"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2058"
  type: "ReLU"
  bottom: "conv2056"
  top: "conv2056"
}
layer {
  name: "conv2059"
  type: "Convolution"
  bottom: "conv2056"
  top: "conv2059"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2061"
  type: "Reshape"
  bottom: "conv2059"
  top: "reshape2061"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2062"
  type: "Permute"
  bottom: "reshape2061"
  top: "perm2062"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2063"
  type: "Softmax"
  bottom: "perm2062"
  top: "softmax2063"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2065"
  type: "Reshape"
  bottom: "softmax2063"
  top: "reshape2065"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2066"
  type: "Slice"
  bottom: "reshape2065"
  top: "slice2066-0"
  top: "slice2066-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul2067"
  type: "Scale"
  bottom: "slice2053-0"
  bottom: "slice2066-0"
  top: "mul2067"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2068"
  type: "Scale"
  bottom: "slice2053-1"
  bottom: "slice2066-1"
  top: "mul2068"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2069"
  type: "Eltwise"
  bottom: "mul2067"
  bottom: "mul2068"
  top: "add2069"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2070"
  type: "Convolution"
  bottom: "add2069"
  top: "conv2070"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2071"
  type: "BatchNorm"
  bottom: "conv2070"
  top: "conv2070"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2071"
  type: "Scale"
  bottom: "conv2070"
  top: "conv2070"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2072"
  type: "Eltwise"
  bottom: "conv2070"
  bottom: "add2045"
  top: "add2072"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2073"
  type: "ReLU"
  bottom: "add2072"
  top: "add2072"
}
layer {
  name: "conv2074"
  type: "Convolution"
  bottom: "add2072"
  top: "conv2074"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2075"
  type: "BatchNorm"
  bottom: "conv2074"
  top: "conv2074"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2075"
  type: "Scale"
  bottom: "conv2074"
  top: "conv2074"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2076"
  type: "ReLU"
  bottom: "conv2074"
  top: "conv2074"
}
layer {
  name: "conv2077"
  type: "Convolution"
  bottom: "conv2074"
  top: "conv2077"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2078"
  type: "BatchNorm"
  bottom: "conv2077"
  top: "conv2077"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2078"
  type: "Scale"
  bottom: "conv2077"
  top: "conv2077"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2079"
  type: "ReLU"
  bottom: "conv2077"
  top: "conv2077"
}
layer {
  name: "slice2080"
  type: "Slice"
  bottom: "conv2077"
  top: "slice2080-0"
  top: "slice2080-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add2081"
  type: "Eltwise"
  bottom: "slice2080-0"
  bottom: "slice2080-1"
  top: "add2081"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2082"
  type: "Pooling"
  bottom: "add2081"
  top: "pool2082"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2083"
  type: "Convolution"
  bottom: "pool2082"
  top: "conv2083"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2084"
  type: "BatchNorm"
  bottom: "conv2083"
  top: "conv2083"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2084"
  type: "Scale"
  bottom: "conv2083"
  top: "conv2083"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2085"
  type: "ReLU"
  bottom: "conv2083"
  top: "conv2083"
}
layer {
  name: "conv2086"
  type: "Convolution"
  bottom: "conv2083"
  top: "conv2086"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2088"
  type: "Reshape"
  bottom: "conv2086"
  top: "reshape2088"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2089"
  type: "Permute"
  bottom: "reshape2088"
  top: "perm2089"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2090"
  type: "Softmax"
  bottom: "perm2089"
  top: "softmax2090"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2092"
  type: "Reshape"
  bottom: "softmax2090"
  top: "reshape2092"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2093"
  type: "Slice"
  bottom: "reshape2092"
  top: "slice2093-0"
  top: "slice2093-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul2094"
  type: "Scale"
  bottom: "slice2080-0"
  bottom: "slice2093-0"
  top: "mul2094"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2095"
  type: "Scale"
  bottom: "slice2080-1"
  bottom: "slice2093-1"
  top: "mul2095"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2096"
  type: "Eltwise"
  bottom: "mul2094"
  bottom: "mul2095"
  top: "add2096"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2097"
  type: "Convolution"
  bottom: "add2096"
  top: "conv2097"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2098"
  type: "BatchNorm"
  bottom: "conv2097"
  top: "conv2097"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2098"
  type: "Scale"
  bottom: "conv2097"
  top: "conv2097"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2099"
  type: "Eltwise"
  bottom: "conv2097"
  bottom: "add2072"
  top: "add2099"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2100"
  type: "ReLU"
  bottom: "add2099"
  top: "add2099"
}
layer {
  name: "conv2101"
  type: "Convolution"
  bottom: "add2099"
  top: "conv2101"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2102"
  type: "BatchNorm"
  bottom: "conv2101"
  top: "conv2101"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2102"
  type: "Scale"
  bottom: "conv2101"
  top: "conv2101"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2103"
  type: "ReLU"
  bottom: "conv2101"
  top: "conv2101"
}
layer {
  name: "conv2104"
  type: "Convolution"
  bottom: "conv2101"
  top: "conv2104"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2105"
  type: "BatchNorm"
  bottom: "conv2104"
  top: "conv2104"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2105"
  type: "Scale"
  bottom: "conv2104"
  top: "conv2104"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2106"
  type: "ReLU"
  bottom: "conv2104"
  top: "conv2104"
}
layer {
  name: "slice2107"
  type: "Slice"
  bottom: "conv2104"
  top: "slice2107-0"
  top: "slice2107-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add2108"
  type: "Eltwise"
  bottom: "slice2107-0"
  bottom: "slice2107-1"
  top: "add2108"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2109"
  type: "Pooling"
  bottom: "add2108"
  top: "pool2109"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2110"
  type: "Convolution"
  bottom: "pool2109"
  top: "conv2110"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2111"
  type: "BatchNorm"
  bottom: "conv2110"
  top: "conv2110"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2111"
  type: "Scale"
  bottom: "conv2110"
  top: "conv2110"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2112"
  type: "ReLU"
  bottom: "conv2110"
  top: "conv2110"
}
layer {
  name: "conv2113"
  type: "Convolution"
  bottom: "conv2110"
  top: "conv2113"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2115"
  type: "Reshape"
  bottom: "conv2113"
  top: "reshape2115"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2116"
  type: "Permute"
  bottom: "reshape2115"
  top: "perm2116"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2117"
  type: "Softmax"
  bottom: "perm2116"
  top: "softmax2117"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2119"
  type: "Reshape"
  bottom: "softmax2117"
  top: "reshape2119"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2120"
  type: "Slice"
  bottom: "reshape2119"
  top: "slice2120-0"
  top: "slice2120-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul2121"
  type: "Scale"
  bottom: "slice2107-0"
  bottom: "slice2120-0"
  top: "mul2121"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2122"
  type: "Scale"
  bottom: "slice2107-1"
  bottom: "slice2120-1"
  top: "mul2122"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2123"
  type: "Eltwise"
  bottom: "mul2121"
  bottom: "mul2122"
  top: "add2123"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2124"
  type: "Convolution"
  bottom: "add2123"
  top: "conv2124"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2125"
  type: "BatchNorm"
  bottom: "conv2124"
  top: "conv2124"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2125"
  type: "Scale"
  bottom: "conv2124"
  top: "conv2124"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2126"
  type: "Eltwise"
  bottom: "conv2124"
  bottom: "add2099"
  top: "add2126"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2127"
  type: "ReLU"
  bottom: "add2126"
  top: "add2126"
}
layer {
  name: "conv2128"
  type: "Convolution"
  bottom: "add2126"
  top: "conv2128"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2129"
  type: "BatchNorm"
  bottom: "conv2128"
  top: "conv2128"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2129"
  type: "Scale"
  bottom: "conv2128"
  top: "conv2128"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2130"
  type: "ReLU"
  bottom: "conv2128"
  top: "conv2128"
}
layer {
  name: "conv2131"
  type: "Convolution"
  bottom: "conv2128"
  top: "conv2131"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2132"
  type: "BatchNorm"
  bottom: "conv2131"
  top: "conv2131"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2132"
  type: "Scale"
  bottom: "conv2131"
  top: "conv2131"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2133"
  type: "ReLU"
  bottom: "conv2131"
  top: "conv2131"
}
layer {
  name: "slice2134"
  type: "Slice"
  bottom: "conv2131"
  top: "slice2134-0"
  top: "slice2134-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add2135"
  type: "Eltwise"
  bottom: "slice2134-0"
  bottom: "slice2134-1"
  top: "add2135"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2136"
  type: "Pooling"
  bottom: "add2135"
  top: "pool2136"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2137"
  type: "Convolution"
  bottom: "pool2136"
  top: "conv2137"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2138"
  type: "BatchNorm"
  bottom: "conv2137"
  top: "conv2137"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2138"
  type: "Scale"
  bottom: "conv2137"
  top: "conv2137"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2139"
  type: "ReLU"
  bottom: "conv2137"
  top: "conv2137"
}
layer {
  name: "conv2140"
  type: "Convolution"
  bottom: "conv2137"
  top: "conv2140"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2142"
  type: "Reshape"
  bottom: "conv2140"
  top: "reshape2142"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2143"
  type: "Permute"
  bottom: "reshape2142"
  top: "perm2143"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2144"
  type: "Softmax"
  bottom: "perm2143"
  top: "softmax2144"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2146"
  type: "Reshape"
  bottom: "softmax2144"
  top: "reshape2146"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2147"
  type: "Slice"
  bottom: "reshape2146"
  top: "slice2147-0"
  top: "slice2147-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul2148"
  type: "Scale"
  bottom: "slice2134-0"
  bottom: "slice2147-0"
  top: "mul2148"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2149"
  type: "Scale"
  bottom: "slice2134-1"
  bottom: "slice2147-1"
  top: "mul2149"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2150"
  type: "Eltwise"
  bottom: "mul2148"
  bottom: "mul2149"
  top: "add2150"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2151"
  type: "Convolution"
  bottom: "add2150"
  top: "conv2151"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2152"
  type: "BatchNorm"
  bottom: "conv2151"
  top: "conv2151"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2152"
  type: "Scale"
  bottom: "conv2151"
  top: "conv2151"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2153"
  type: "Eltwise"
  bottom: "conv2151"
  bottom: "add2126"
  top: "add2153"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2154"
  type: "ReLU"
  bottom: "add2153"
  top: "add2153"
}
layer {
  name: "conv2155"
  type: "Convolution"
  bottom: "add2153"
  top: "conv2155"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2156"
  type: "BatchNorm"
  bottom: "conv2155"
  top: "conv2155"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2156"
  type: "Scale"
  bottom: "conv2155"
  top: "conv2155"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2157"
  type: "ReLU"
  bottom: "conv2155"
  top: "conv2155"
}
layer {
  name: "conv2158"
  type: "Convolution"
  bottom: "conv2155"
  top: "conv2158"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2159"
  type: "BatchNorm"
  bottom: "conv2158"
  top: "conv2158"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2159"
  type: "Scale"
  bottom: "conv2158"
  top: "conv2158"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2160"
  type: "ReLU"
  bottom: "conv2158"
  top: "conv2158"
}
layer {
  name: "slice2161"
  type: "Slice"
  bottom: "conv2158"
  top: "slice2161-0"
  top: "slice2161-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add2162"
  type: "Eltwise"
  bottom: "slice2161-0"
  bottom: "slice2161-1"
  top: "add2162"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2163"
  type: "Pooling"
  bottom: "add2162"
  top: "pool2163"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2164"
  type: "Convolution"
  bottom: "pool2163"
  top: "conv2164"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2165"
  type: "BatchNorm"
  bottom: "conv2164"
  top: "conv2164"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2165"
  type: "Scale"
  bottom: "conv2164"
  top: "conv2164"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2166"
  type: "ReLU"
  bottom: "conv2164"
  top: "conv2164"
}
layer {
  name: "conv2167"
  type: "Convolution"
  bottom: "conv2164"
  top: "conv2167"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2169"
  type: "Reshape"
  bottom: "conv2167"
  top: "reshape2169"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2170"
  type: "Permute"
  bottom: "reshape2169"
  top: "perm2170"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2171"
  type: "Softmax"
  bottom: "perm2170"
  top: "softmax2171"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2173"
  type: "Reshape"
  bottom: "softmax2171"
  top: "reshape2173"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2174"
  type: "Slice"
  bottom: "reshape2173"
  top: "slice2174-0"
  top: "slice2174-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul2175"
  type: "Scale"
  bottom: "slice2161-0"
  bottom: "slice2174-0"
  top: "mul2175"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2176"
  type: "Scale"
  bottom: "slice2161-1"
  bottom: "slice2174-1"
  top: "mul2176"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2177"
  type: "Eltwise"
  bottom: "mul2175"
  bottom: "mul2176"
  top: "add2177"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2178"
  type: "Convolution"
  bottom: "add2177"
  top: "conv2178"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2179"
  type: "BatchNorm"
  bottom: "conv2178"
  top: "conv2178"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2179"
  type: "Scale"
  bottom: "conv2178"
  top: "conv2178"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2180"
  type: "Eltwise"
  bottom: "conv2178"
  bottom: "add2153"
  top: "add2180"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2181"
  type: "ReLU"
  bottom: "add2180"
  top: "add2180"
}
layer {
  name: "conv2182"
  type: "Convolution"
  bottom: "add2180"
  top: "conv2182"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2183"
  type: "BatchNorm"
  bottom: "conv2182"
  top: "conv2182"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2183"
  type: "Scale"
  bottom: "conv2182"
  top: "conv2182"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2184"
  type: "ReLU"
  bottom: "conv2182"
  top: "conv2182"
}
layer {
  name: "conv2185"
  type: "Convolution"
  bottom: "conv2182"
  top: "conv2185"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2186"
  type: "BatchNorm"
  bottom: "conv2185"
  top: "conv2185"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2186"
  type: "Scale"
  bottom: "conv2185"
  top: "conv2185"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2187"
  type: "ReLU"
  bottom: "conv2185"
  top: "conv2185"
}
layer {
  name: "slice2188"
  type: "Slice"
  bottom: "conv2185"
  top: "slice2188-0"
  top: "slice2188-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "add2189"
  type: "Eltwise"
  bottom: "slice2188-0"
  bottom: "slice2188-1"
  top: "add2189"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2190"
  type: "Pooling"
  bottom: "add2189"
  top: "pool2190"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2191"
  type: "Convolution"
  bottom: "pool2190"
  top: "conv2191"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2192"
  type: "BatchNorm"
  bottom: "conv2191"
  top: "conv2191"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2192"
  type: "Scale"
  bottom: "conv2191"
  top: "conv2191"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2193"
  type: "ReLU"
  bottom: "conv2191"
  top: "conv2191"
}
layer {
  name: "conv2194"
  type: "Convolution"
  bottom: "conv2191"
  top: "conv2194"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2196"
  type: "Reshape"
  bottom: "conv2194"
  top: "reshape2196"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2197"
  type: "Permute"
  bottom: "reshape2196"
  top: "perm2197"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2198"
  type: "Softmax"
  bottom: "perm2197"
  top: "softmax2198"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2200"
  type: "Reshape"
  bottom: "softmax2198"
  top: "reshape2200"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2201"
  type: "Slice"
  bottom: "reshape2200"
  top: "slice2201-0"
  top: "slice2201-1"
  slice_param {
    slice_point: 256
    axis: 1
  }
}
layer {
  name: "mul2202"
  type: "Scale"
  bottom: "slice2188-0"
  bottom: "slice2201-0"
  top: "mul2202"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2203"
  type: "Scale"
  bottom: "slice2188-1"
  bottom: "slice2201-1"
  top: "mul2203"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2204"
  type: "Eltwise"
  bottom: "mul2202"
  bottom: "mul2203"
  top: "add2204"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2205"
  type: "Convolution"
  bottom: "add2204"
  top: "conv2205"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2206"
  type: "BatchNorm"
  bottom: "conv2205"
  top: "conv2205"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2206"
  type: "Scale"
  bottom: "conv2205"
  top: "conv2205"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2207"
  type: "Eltwise"
  bottom: "conv2205"
  bottom: "add2180"
  top: "add2207"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2208"
  type: "ReLU"
  bottom: "add2207"
  top: "add2207"
}
layer {
  name: "conv2209"
  type: "Convolution"
  bottom: "add2207"
  top: "conv2209"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2210"
  type: "BatchNorm"
  bottom: "conv2209"
  top: "conv2209"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2210"
  type: "Scale"
  bottom: "conv2209"
  top: "conv2209"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2211"
  type: "ReLU"
  bottom: "conv2209"
  top: "conv2209"
}
layer {
  name: "conv2212"
  type: "Convolution"
  bottom: "conv2209"
  top: "conv2212"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2213"
  type: "BatchNorm"
  bottom: "conv2212"
  top: "conv2212"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2213"
  type: "Scale"
  bottom: "conv2212"
  top: "conv2212"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2214"
  type: "ReLU"
  bottom: "conv2212"
  top: "conv2212"
}
layer {
  name: "slice2215"
  type: "Slice"
  bottom: "conv2212"
  top: "slice2215-0"
  top: "slice2215-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add2216"
  type: "Eltwise"
  bottom: "slice2215-0"
  bottom: "slice2215-1"
  top: "add2216"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2217"
  type: "Pooling"
  bottom: "add2216"
  top: "pool2217"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2218"
  type: "Convolution"
  bottom: "pool2217"
  top: "conv2218"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2219"
  type: "BatchNorm"
  bottom: "conv2218"
  top: "conv2218"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2219"
  type: "Scale"
  bottom: "conv2218"
  top: "conv2218"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2220"
  type: "ReLU"
  bottom: "conv2218"
  top: "conv2218"
}
layer {
  name: "conv2221"
  type: "Convolution"
  bottom: "conv2218"
  top: "conv2221"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2223"
  type: "Reshape"
  bottom: "conv2221"
  top: "reshape2223"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2224"
  type: "Permute"
  bottom: "reshape2223"
  top: "perm2224"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2225"
  type: "Softmax"
  bottom: "perm2224"
  top: "softmax2225"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2227"
  type: "Reshape"
  bottom: "softmax2225"
  top: "reshape2227"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2228"
  type: "Slice"
  bottom: "reshape2227"
  top: "slice2228-0"
  top: "slice2228-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul2229"
  type: "Scale"
  bottom: "slice2215-0"
  bottom: "slice2228-0"
  top: "mul2229"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2230"
  type: "Scale"
  bottom: "slice2215-1"
  bottom: "slice2228-1"
  top: "mul2230"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2231"
  type: "Eltwise"
  bottom: "mul2229"
  bottom: "mul2230"
  top: "add2231"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2232"
  type: "Pooling"
  bottom: "add2231"
  top: "pool2232"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
    pad: 1
    round_mode: FLOOR
  }
}
layer {
  name: "conv2233"
  type: "Convolution"
  bottom: "pool2232"
  top: "conv2233"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2234"
  type: "BatchNorm"
  bottom: "conv2233"
  top: "conv2233"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2234"
  type: "Scale"
  bottom: "conv2233"
  top: "conv2233"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "pool2235"
  type: "Pooling"
  bottom: "add2207"
  top: "pool2235"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv2236"
  type: "Convolution"
  bottom: "pool2235"
  top: "conv2236"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2237"
  type: "BatchNorm"
  bottom: "conv2236"
  top: "conv2236"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2237"
  type: "Scale"
  bottom: "conv2236"
  top: "conv2236"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2238"
  type: "Eltwise"
  bottom: "conv2233"
  bottom: "conv2236"
  top: "add2238"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2239"
  type: "ReLU"
  bottom: "add2238"
  top: "add2238"
}
layer {
  name: "conv2240"
  type: "Convolution"
  bottom: "add2238"
  top: "conv2240"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2241"
  type: "BatchNorm"
  bottom: "conv2240"
  top: "conv2240"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2241"
  type: "Scale"
  bottom: "conv2240"
  top: "conv2240"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2242"
  type: "ReLU"
  bottom: "conv2240"
  top: "conv2240"
}
layer {
  name: "conv2243"
  type: "Convolution"
  bottom: "conv2240"
  top: "conv2243"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2244"
  type: "BatchNorm"
  bottom: "conv2243"
  top: "conv2243"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2244"
  type: "Scale"
  bottom: "conv2243"
  top: "conv2243"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2245"
  type: "ReLU"
  bottom: "conv2243"
  top: "conv2243"
}
layer {
  name: "slice2246"
  type: "Slice"
  bottom: "conv2243"
  top: "slice2246-0"
  top: "slice2246-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add2247"
  type: "Eltwise"
  bottom: "slice2246-0"
  bottom: "slice2246-1"
  top: "add2247"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2248"
  type: "Pooling"
  bottom: "add2247"
  top: "pool2248"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2249"
  type: "Convolution"
  bottom: "pool2248"
  top: "conv2249"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2250"
  type: "BatchNorm"
  bottom: "conv2249"
  top: "conv2249"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2250"
  type: "Scale"
  bottom: "conv2249"
  top: "conv2249"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2251"
  type: "ReLU"
  bottom: "conv2249"
  top: "conv2249"
}
layer {
  name: "conv2252"
  type: "Convolution"
  bottom: "conv2249"
  top: "conv2252"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2254"
  type: "Reshape"
  bottom: "conv2252"
  top: "reshape2254"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2255"
  type: "Permute"
  bottom: "reshape2254"
  top: "perm2255"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2256"
  type: "Softmax"
  bottom: "perm2255"
  top: "softmax2256"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2258"
  type: "Reshape"
  bottom: "softmax2256"
  top: "reshape2258"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2259"
  type: "Slice"
  bottom: "reshape2258"
  top: "slice2259-0"
  top: "slice2259-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul2260"
  type: "Scale"
  bottom: "slice2246-0"
  bottom: "slice2259-0"
  top: "mul2260"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2261"
  type: "Scale"
  bottom: "slice2246-1"
  bottom: "slice2259-1"
  top: "mul2261"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2262"
  type: "Eltwise"
  bottom: "mul2260"
  bottom: "mul2261"
  top: "add2262"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2263"
  type: "Convolution"
  bottom: "add2262"
  top: "conv2263"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2264"
  type: "BatchNorm"
  bottom: "conv2263"
  top: "conv2263"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2264"
  type: "Scale"
  bottom: "conv2263"
  top: "conv2263"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2265"
  type: "Eltwise"
  bottom: "conv2263"
  bottom: "add2238"
  top: "add2265"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2266"
  type: "ReLU"
  bottom: "add2265"
  top: "add2265"
}
layer {
  name: "conv2267"
  type: "Convolution"
  bottom: "add2265"
  top: "conv2267"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2268"
  type: "BatchNorm"
  bottom: "conv2267"
  top: "conv2267"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2268"
  type: "Scale"
  bottom: "conv2267"
  top: "conv2267"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2269"
  type: "ReLU"
  bottom: "conv2267"
  top: "conv2267"
}
layer {
  name: "conv2270"
  type: "Convolution"
  bottom: "conv2267"
  top: "conv2270"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2271"
  type: "BatchNorm"
  bottom: "conv2270"
  top: "conv2270"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2271"
  type: "Scale"
  bottom: "conv2270"
  top: "conv2270"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2272"
  type: "ReLU"
  bottom: "conv2270"
  top: "conv2270"
}
layer {
  name: "slice2273"
  type: "Slice"
  bottom: "conv2270"
  top: "slice2273-0"
  top: "slice2273-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add2274"
  type: "Eltwise"
  bottom: "slice2273-0"
  bottom: "slice2273-1"
  top: "add2274"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2275"
  type: "Pooling"
  bottom: "add2274"
  top: "pool2275"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2276"
  type: "Convolution"
  bottom: "pool2275"
  top: "conv2276"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2277"
  type: "BatchNorm"
  bottom: "conv2276"
  top: "conv2276"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2277"
  type: "Scale"
  bottom: "conv2276"
  top: "conv2276"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2278"
  type: "ReLU"
  bottom: "conv2276"
  top: "conv2276"
}
layer {
  name: "conv2279"
  type: "Convolution"
  bottom: "conv2276"
  top: "conv2279"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2281"
  type: "Reshape"
  bottom: "conv2279"
  top: "reshape2281"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2282"
  type: "Permute"
  bottom: "reshape2281"
  top: "perm2282"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2283"
  type: "Softmax"
  bottom: "perm2282"
  top: "softmax2283"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2285"
  type: "Reshape"
  bottom: "softmax2283"
  top: "reshape2285"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2286"
  type: "Slice"
  bottom: "reshape2285"
  top: "slice2286-0"
  top: "slice2286-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul2287"
  type: "Scale"
  bottom: "slice2273-0"
  bottom: "slice2286-0"
  top: "mul2287"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2288"
  type: "Scale"
  bottom: "slice2273-1"
  bottom: "slice2286-1"
  top: "mul2288"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2289"
  type: "Eltwise"
  bottom: "mul2287"
  bottom: "mul2288"
  top: "add2289"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2290"
  type: "Convolution"
  bottom: "add2289"
  top: "conv2290"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2291"
  type: "BatchNorm"
  bottom: "conv2290"
  top: "conv2290"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2291"
  type: "Scale"
  bottom: "conv2290"
  top: "conv2290"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2292"
  type: "Eltwise"
  bottom: "conv2290"
  bottom: "add2265"
  top: "add2292"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2293"
  type: "ReLU"
  bottom: "add2292"
  top: "add2292"
}
layer {
  name: "conv2294"
  type: "Convolution"
  bottom: "add2292"
  top: "conv2294"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2295"
  type: "BatchNorm"
  bottom: "conv2294"
  top: "conv2294"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2295"
  type: "Scale"
  bottom: "conv2294"
  top: "conv2294"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2296"
  type: "ReLU"
  bottom: "conv2294"
  top: "conv2294"
}
layer {
  name: "conv2297"
  type: "Convolution"
  bottom: "conv2294"
  top: "conv2297"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2298"
  type: "BatchNorm"
  bottom: "conv2297"
  top: "conv2297"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2298"
  type: "Scale"
  bottom: "conv2297"
  top: "conv2297"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2299"
  type: "ReLU"
  bottom: "conv2297"
  top: "conv2297"
}
layer {
  name: "slice2300"
  type: "Slice"
  bottom: "conv2297"
  top: "slice2300-0"
  top: "slice2300-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add2301"
  type: "Eltwise"
  bottom: "slice2300-0"
  bottom: "slice2300-1"
  top: "add2301"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2302"
  type: "Pooling"
  bottom: "add2301"
  top: "pool2302"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2303"
  type: "Convolution"
  bottom: "pool2302"
  top: "conv2303"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2304"
  type: "BatchNorm"
  bottom: "conv2303"
  top: "conv2303"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2304"
  type: "Scale"
  bottom: "conv2303"
  top: "conv2303"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2305"
  type: "ReLU"
  bottom: "conv2303"
  top: "conv2303"
}
layer {
  name: "conv2306"
  type: "Convolution"
  bottom: "conv2303"
  top: "conv2306"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2308"
  type: "Reshape"
  bottom: "conv2306"
  top: "reshape2308"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2309"
  type: "Permute"
  bottom: "reshape2308"
  top: "perm2309"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2310"
  type: "Softmax"
  bottom: "perm2309"
  top: "softmax2310"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2312"
  type: "Reshape"
  bottom: "softmax2310"
  top: "reshape2312"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2313"
  type: "Slice"
  bottom: "reshape2312"
  top: "slice2313-0"
  top: "slice2313-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul2314"
  type: "Scale"
  bottom: "slice2300-0"
  bottom: "slice2313-0"
  top: "mul2314"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2315"
  type: "Scale"
  bottom: "slice2300-1"
  bottom: "slice2313-1"
  top: "mul2315"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2316"
  type: "Eltwise"
  bottom: "mul2314"
  bottom: "mul2315"
  top: "add2316"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2317"
  type: "Convolution"
  bottom: "add2316"
  top: "conv2317"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2318"
  type: "BatchNorm"
  bottom: "conv2317"
  top: "conv2317"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2318"
  type: "Scale"
  bottom: "conv2317"
  top: "conv2317"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2319"
  type: "Eltwise"
  bottom: "conv2317"
  bottom: "add2292"
  top: "add2319"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2320"
  type: "ReLU"
  bottom: "add2319"
  top: "add2319"
}
layer {
  name: "conv2321"
  type: "Convolution"
  bottom: "add2319"
  top: "conv2321"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2322"
  type: "BatchNorm"
  bottom: "conv2321"
  top: "conv2321"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2322"
  type: "Scale"
  bottom: "conv2321"
  top: "conv2321"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2323"
  type: "ReLU"
  bottom: "conv2321"
  top: "conv2321"
}
layer {
  name: "conv2324"
  type: "Convolution"
  bottom: "conv2321"
  top: "conv2324"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2325"
  type: "BatchNorm"
  bottom: "conv2324"
  top: "conv2324"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2325"
  type: "Scale"
  bottom: "conv2324"
  top: "conv2324"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2326"
  type: "ReLU"
  bottom: "conv2324"
  top: "conv2324"
}
layer {
  name: "slice2327"
  type: "Slice"
  bottom: "conv2324"
  top: "slice2327-0"
  top: "slice2327-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add2328"
  type: "Eltwise"
  bottom: "slice2327-0"
  bottom: "slice2327-1"
  top: "add2328"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2329"
  type: "Pooling"
  bottom: "add2328"
  top: "pool2329"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2330"
  type: "Convolution"
  bottom: "pool2329"
  top: "conv2330"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2331"
  type: "BatchNorm"
  bottom: "conv2330"
  top: "conv2330"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2331"
  type: "Scale"
  bottom: "conv2330"
  top: "conv2330"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2332"
  type: "ReLU"
  bottom: "conv2330"
  top: "conv2330"
}
layer {
  name: "conv2333"
  type: "Convolution"
  bottom: "conv2330"
  top: "conv2333"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2335"
  type: "Reshape"
  bottom: "conv2333"
  top: "reshape2335"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2336"
  type: "Permute"
  bottom: "reshape2335"
  top: "perm2336"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2337"
  type: "Softmax"
  bottom: "perm2336"
  top: "softmax2337"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2339"
  type: "Reshape"
  bottom: "softmax2337"
  top: "reshape2339"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2340"
  type: "Slice"
  bottom: "reshape2339"
  top: "slice2340-0"
  top: "slice2340-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul2341"
  type: "Scale"
  bottom: "slice2327-0"
  bottom: "slice2340-0"
  top: "mul2341"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2342"
  type: "Scale"
  bottom: "slice2327-1"
  bottom: "slice2340-1"
  top: "mul2342"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2343"
  type: "Eltwise"
  bottom: "mul2341"
  bottom: "mul2342"
  top: "add2343"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2344"
  type: "Convolution"
  bottom: "add2343"
  top: "conv2344"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2345"
  type: "BatchNorm"
  bottom: "conv2344"
  top: "conv2344"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2345"
  type: "Scale"
  bottom: "conv2344"
  top: "conv2344"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2346"
  type: "Eltwise"
  bottom: "conv2344"
  bottom: "add2319"
  top: "add2346"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2347"
  type: "ReLU"
  bottom: "add2346"
  top: "add2346"
}
layer {
  name: "conv2348"
  type: "Convolution"
  bottom: "add2346"
  top: "conv2348"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2349"
  type: "BatchNorm"
  bottom: "conv2348"
  top: "conv2348"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2349"
  type: "Scale"
  bottom: "conv2348"
  top: "conv2348"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2350"
  type: "ReLU"
  bottom: "conv2348"
  top: "conv2348"
}
layer {
  name: "conv2351"
  type: "Convolution"
  bottom: "conv2348"
  top: "conv2351"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2352"
  type: "BatchNorm"
  bottom: "conv2351"
  top: "conv2351"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2352"
  type: "Scale"
  bottom: "conv2351"
  top: "conv2351"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2353"
  type: "ReLU"
  bottom: "conv2351"
  top: "conv2351"
}
layer {
  name: "slice2354"
  type: "Slice"
  bottom: "conv2351"
  top: "slice2354-0"
  top: "slice2354-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add2355"
  type: "Eltwise"
  bottom: "slice2354-0"
  bottom: "slice2354-1"
  top: "add2355"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2356"
  type: "Pooling"
  bottom: "add2355"
  top: "pool2356"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2357"
  type: "Convolution"
  bottom: "pool2356"
  top: "conv2357"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2358"
  type: "BatchNorm"
  bottom: "conv2357"
  top: "conv2357"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2358"
  type: "Scale"
  bottom: "conv2357"
  top: "conv2357"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2359"
  type: "ReLU"
  bottom: "conv2357"
  top: "conv2357"
}
layer {
  name: "conv2360"
  type: "Convolution"
  bottom: "conv2357"
  top: "conv2360"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2362"
  type: "Reshape"
  bottom: "conv2360"
  top: "reshape2362"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2363"
  type: "Permute"
  bottom: "reshape2362"
  top: "perm2363"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2364"
  type: "Softmax"
  bottom: "perm2363"
  top: "softmax2364"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2366"
  type: "Reshape"
  bottom: "softmax2364"
  top: "reshape2366"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2367"
  type: "Slice"
  bottom: "reshape2366"
  top: "slice2367-0"
  top: "slice2367-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul2368"
  type: "Scale"
  bottom: "slice2354-0"
  bottom: "slice2367-0"
  top: "mul2368"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2369"
  type: "Scale"
  bottom: "slice2354-1"
  bottom: "slice2367-1"
  top: "mul2369"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2370"
  type: "Eltwise"
  bottom: "mul2368"
  bottom: "mul2369"
  top: "add2370"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2371"
  type: "Convolution"
  bottom: "add2370"
  top: "conv2371"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2372"
  type: "BatchNorm"
  bottom: "conv2371"
  top: "conv2371"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2372"
  type: "Scale"
  bottom: "conv2371"
  top: "conv2371"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2373"
  type: "Eltwise"
  bottom: "conv2371"
  bottom: "add2346"
  top: "add2373"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2374"
  type: "ReLU"
  bottom: "add2373"
  top: "add2373"
}
layer {
  name: "conv2375"
  type: "Convolution"
  bottom: "add2373"
  top: "conv2375"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2376"
  type: "BatchNorm"
  bottom: "conv2375"
  top: "conv2375"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2376"
  type: "Scale"
  bottom: "conv2375"
  top: "conv2375"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2377"
  type: "ReLU"
  bottom: "conv2375"
  top: "conv2375"
}
layer {
  name: "conv2378"
  type: "Convolution"
  bottom: "conv2375"
  top: "conv2378"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2379"
  type: "BatchNorm"
  bottom: "conv2378"
  top: "conv2378"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2379"
  type: "Scale"
  bottom: "conv2378"
  top: "conv2378"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2380"
  type: "ReLU"
  bottom: "conv2378"
  top: "conv2378"
}
layer {
  name: "slice2381"
  type: "Slice"
  bottom: "conv2378"
  top: "slice2381-0"
  top: "slice2381-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add2382"
  type: "Eltwise"
  bottom: "slice2381-0"
  bottom: "slice2381-1"
  top: "add2382"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2383"
  type: "Pooling"
  bottom: "add2382"
  top: "pool2383"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2384"
  type: "Convolution"
  bottom: "pool2383"
  top: "conv2384"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2385"
  type: "BatchNorm"
  bottom: "conv2384"
  top: "conv2384"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2385"
  type: "Scale"
  bottom: "conv2384"
  top: "conv2384"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2386"
  type: "ReLU"
  bottom: "conv2384"
  top: "conv2384"
}
layer {
  name: "conv2387"
  type: "Convolution"
  bottom: "conv2384"
  top: "conv2387"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2389"
  type: "Reshape"
  bottom: "conv2387"
  top: "reshape2389"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2390"
  type: "Permute"
  bottom: "reshape2389"
  top: "perm2390"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2391"
  type: "Softmax"
  bottom: "perm2390"
  top: "softmax2391"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2393"
  type: "Reshape"
  bottom: "softmax2391"
  top: "reshape2393"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2394"
  type: "Slice"
  bottom: "reshape2393"
  top: "slice2394-0"
  top: "slice2394-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul2395"
  type: "Scale"
  bottom: "slice2381-0"
  bottom: "slice2394-0"
  top: "mul2395"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2396"
  type: "Scale"
  bottom: "slice2381-1"
  bottom: "slice2394-1"
  top: "mul2396"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2397"
  type: "Eltwise"
  bottom: "mul2395"
  bottom: "mul2396"
  top: "add2397"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2398"
  type: "Convolution"
  bottom: "add2397"
  top: "conv2398"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2399"
  type: "BatchNorm"
  bottom: "conv2398"
  top: "conv2398"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2399"
  type: "Scale"
  bottom: "conv2398"
  top: "conv2398"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2400"
  type: "Eltwise"
  bottom: "conv2398"
  bottom: "add2373"
  top: "add2400"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2401"
  type: "ReLU"
  bottom: "add2400"
  top: "add2400"
}
layer {
  name: "conv2402"
  type: "Convolution"
  bottom: "add2400"
  top: "conv2402"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2403"
  type: "BatchNorm"
  bottom: "conv2402"
  top: "conv2402"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2403"
  type: "Scale"
  bottom: "conv2402"
  top: "conv2402"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2404"
  type: "ReLU"
  bottom: "conv2402"
  top: "conv2402"
}
layer {
  name: "conv2405"
  type: "Convolution"
  bottom: "conv2402"
  top: "conv2405"
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
  }
}
layer {
  name: "bn2406"
  type: "BatchNorm"
  bottom: "conv2405"
  top: "conv2405"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2406"
  type: "Scale"
  bottom: "conv2405"
  top: "conv2405"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2407"
  type: "ReLU"
  bottom: "conv2405"
  top: "conv2405"
}
layer {
  name: "slice2408"
  type: "Slice"
  bottom: "conv2405"
  top: "slice2408-0"
  top: "slice2408-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "add2409"
  type: "Eltwise"
  bottom: "slice2408-0"
  bottom: "slice2408-1"
  top: "add2409"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "pool2410"
  type: "Pooling"
  bottom: "add2409"
  top: "pool2410"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv2411"
  type: "Convolution"
  bottom: "pool2410"
  top: "conv2411"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2412"
  type: "BatchNorm"
  bottom: "conv2411"
  top: "conv2411"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2412"
  type: "Scale"
  bottom: "conv2411"
  top: "conv2411"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2413"
  type: "ReLU"
  bottom: "conv2411"
  top: "conv2411"
}
layer {
  name: "conv2414"
  type: "Convolution"
  bottom: "conv2411"
  top: "conv2414"
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "reshape2416"
  type: "Reshape"
  bottom: "conv2414"
  top: "reshape2416"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 2
      dim: -1
    }
  }
}
layer {
  name: "perm2417"
  type: "Permute"
  bottom: "reshape2416"
  top: "perm2417"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "softmax2418"
  type: "Softmax"
  bottom: "perm2417"
  top: "softmax2418"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "reshape2420"
  type: "Reshape"
  bottom: "softmax2418"
  top: "reshape2420"
  reshape_param {
    shape {
      dim: 0
      dim: -1
    }
  }
}
layer {
  name: "slice2421"
  type: "Slice"
  bottom: "reshape2420"
  top: "slice2421-0"
  top: "slice2421-1"
  slice_param {
    slice_point: 512
    axis: 1
  }
}
layer {
  name: "mul2422"
  type: "Scale"
  bottom: "slice2408-0"
  bottom: "slice2421-0"
  top: "mul2422"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "mul2423"
  type: "Scale"
  bottom: "slice2408-1"
  bottom: "slice2421-1"
  top: "mul2423"
  scale_param {
    axis: 0
    bias_term: false
  }
}
layer {
  name: "add2424"
  type: "Eltwise"
  bottom: "mul2422"
  bottom: "mul2423"
  top: "add2424"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2425"
  type: "Convolution"
  bottom: "add2424"
  top: "conv2425"
  convolution_param {
    num_output: 2048
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2426"
  type: "BatchNorm"
  bottom: "conv2425"
  top: "conv2425"
  batch_norm_param {
    moving_average_fraction: 0.899999976158
    eps: 9.99999974738e-06
  }
}
layer {
  name: "scale2426"
  type: "Scale"
  bottom: "conv2425"
  top: "conv2425"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2427"
  type: "Eltwise"
  bottom: "conv2425"
  bottom: "add2400"
  top: "add2427"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "relu2428"
  type: "ReLU"
  bottom: "add2427"
  top: "add2427"
}
layer {
  name: "pool2429"
  type: "Pooling"
  bottom: "add2427"
  top: "pool2429"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc2434"
  type: "InnerProduct"
  bottom: "pool2429"
  top: "fc2434"
  inner_product_param {
    num_output: 1000
    bias_term: true
  }
}
